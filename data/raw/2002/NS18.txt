Hidden Markov Model of Cortical Synaptic Plasticity: Derivation of the Learning Rule

Michael Eisele W. M. Keck Center for Integrative Neuroscience San Francisco, CA 94143-0444 eisele@phy.ucsf.edu Kenneth D. Miller W. M. Keck Center for Integrative Neuroscience San Francisco, CA 94143-0444 ken@phy.ucsf.edu

Abstract Cortical synaptic plasticity depends on the relative timing of pre- and postsynaptic spikes and also on the temporal pattern of presynaptic spikes and of postsynaptic spikes. We study the hypothesis that cortical synaptic plasticity does not associate individual spikes, but rather whole firing episodes, and depends only on when these episodes start and how long they last, but as little as possible on the timing of individual spikes. Here we present the mathematical background for such a study. Standard methods from hidden Markov models are used to define what "firing episodes" are. Estimating the probability of being in such an episode requires not only the knowledge of past spikes, but also of future spikes. We show how to construct a causal learning rule, which depends only on past spikes, but associates pre- and postsynaptic firing episodes as if it also knew future spikes. We also show that this learning rule agrees with some features of synaptic plasticity in superficial layers of rat visual cortex (Froemke and Dan, Nature 416:433, 2002). 1 Introduction Cortical synaptic plasticity agrees with the Hebbian learning principle: Neurons that fire together, wire together. But many features of cortical plasticity go beyond this simple principle, such as the dependence on spike-timing or the nonlinear dependence on spike frequency (see [1] or [2] for review). Studying these features may produce a better understanding of which neurons wire together in the neocortex. Previous models of cortical synaptic plasticity [3]-[5] differed in their details, but they agreed that nonlinear learning rules are needed to model cortical plasticity. In linear learning rules, the weight change induced by a presynatic spike would depend only on the postsynaptic spikes, but not on all the other presynaptic spikes. In the cortex, by contrast, the contribution from a presynaptic spike is stronger when it occurs alone than when it occurs right after another presynaptic spike [5]. Similar results hold for postsynaptic spikes. Consequently, the weight change depends in a complex way on the whole temporal pattern of pre- and postsynaptic spikes. Even though this nonlinear dependence can be modeled phenomenologically [3]-[5], its biological function remains unknown. We will not propose such a function here, but reduce this complex dependence to a few principles, whose


A pre post D

a12= 1 LTP LTD LTP or LTD 2

1 - a20 e2(1)> 0

B spikes firing 1 e1(1) = 1 a20

episodes

C pre post a01 1 - a01 0 e (1) = 0 0

LTP LTD LTP time

Figure 1: A: Usually, models of cortical synaptic plasticity associate pre- and postsynaptic spikes directly. They produce long-term potentiation (LTP) when the presynaptic spike (pre) precedes the postsynaptic spike (post), and long-term depression (LTD) if the order is reversed. When several pre- and postsynaptic spikes are interleaved in time, the outcome depends in a complicated way on the whole spike pattern (LTP or LTD). B: In our model, pre- and postsynaptic spikes are paired only indirectly. Each spike train is used to estimate when firing episodes start and end. C: These firing episodes are then associated, with LTP being induced if the presynaptic firing episode starts before the postsynaptic one and LTD if the order is reversed and if the episodes are short. D: Hidden Markov model used to estimate when firing episodes occur.

function may be easier to understand in future studies.

2 Basic learning principle The basic principle behind our model is illustrated in fig. 1. We propose that the learning rule does not associate pre- and postsynaptic spikes directly, but rather uses them to estimate whether the pre- or postsynaptic neuron is currently in a period of rapid firing ('firing episode') or a period of little or no firing. It then associates the firing episodes. When the per- and postsynaptic firing episodes overlap, the synapse is strengthened or weakened depending on which one started first, but independent of the precise temporal patterns of spikes within a firing episode. As a consequence, the contribution of each spike to synaptic plasticity will depend on whether it occurs alone, or surrounded by other spikes, and the learning rule will be nonlinear. For the right parameter choice, the nonlinear features of this rule will agree well with nonlinear features of cortical synaptic plasticity. Implementation of this rule will be done in two steps. Firstly, we will define what "firing episodes" are. Secondly, we will associate the pre- and postsynaptic firing episodes. The first step uses standard methods from hidden Markov models (see e.g. [6]). The pre- and postsynaptic neuron will each be described by a Markov model with three states (fig. 1D),

which correspond to firing episodes (state 2; firing probability

between responses (state 0; firing probability

firing episode (state 1; firing probability

 £¤¦

 £¤¦!"¤

 ¢¡¢£¥¤§¦©¨

), to the silence

), and to the first spike of a new

; duration = 1 time step). As usual,

the parameters of the Markov model are the transition probabilities #%$'& , which determine how long firing episodes and silent periods are expected to last, and the emission rates

  £)(102¦ &

, which determine the firing rates.

(30

at spikes and

and &

(1078

is the binary observable at time step 4 ((3056¤

  £@¦AB¤DCE  £¤¦

parameters &

  £)(3¦

&

otherwise), &   £¥¤¦ is the firing probability per time step in state 9 ,

. In general, the pre- and postsynaptic neuron will have different

and # $F& .


Once the Markov model is defined, one can use standard algorithms (forward and backward algorithm) to estimate, for any given spike sequence, the state probabilities over time. To model cortical synaptic plasticity, we will increase the synaptic weight whenever the preand the postsynaptic neuron have simultaneous firing episodes (both in state 2), and decrease the weight whenever the postsynaptic firing episode starts first (pre in state 1 while post already in state 2):

¤£¦¥¨§© £¦¥  0 0

£¦¥¨§© &%  £¦¥ '% £¦¥¨§©  £¦¥ '%

0  0 

0  ¤ 0  £ ¦ 

"!$#!)(

C for for

where

 ¢¡ !0# !)(

and

(1)

otherwise

are the amplitudes of synaptic potentiation and depression. In general,

the states are not known with certainty, only their probabilities are, and the actual weight change is therefore defined as:

1243  5¡ 76£  98¨@E£A£¦¥¨§B© '6DC1( ¥¨§© E8@GF¨£¦¥

9 ¦ 0  ¦ 0  IH9

&

H

(

¥QP

(2)

where the sum is over all possible pre- and postsynaptic states and

given the whole spike sequence ( ( ¡ (   WV  RSRTR.

@ QRSRTRUC(1¦ £ is the probability

As fig. 2 shows, this straightforward learning

rule produces weight changes that are similar to those seen in cortex [5]. (One can show that this particular Markov model¡ depends on the parameters # and¡ only through the two `Y4acb ed   Y4a

where  is the X

34ms,

combinations

X

 £   ¡ £¤¦

#  C  ¦ #

and

f

 ¡ £¥¤§¦

# #  ¦

time step. To fit the data on spike pairs and triplets [5], we set

f 

20ms,

f 

70ms,

!$# 

96Hz , and

!)(  ¤ ¥¨§© ¥ 8Yga

GYgaE8  cb¥¨§©£ 815ms,

4Rih

X 

.)

¥c

This learning rule is, however, not biologically plausible, because it violates causality. The estimates of state probabilities depend not only on past, but also on future observables, while real synaptic plasticity can depend only on past spikes. To solve this causality problem, we will rewrite the learning rule, essentially deriving a new algorithm in place of the familiar hidden Markov algorithms. We will derive this causal learning rule not only for this specific 3-state model, but for general Markov models. 3 General form of the learning rule 3.1 Learning goal To derive the general form of the learning rule for arbitrary pre- and postsynaptic Markov models, we assume that the transition probabilities # $'& and emission probabilities &   £)(10 ¦ are given and that the weight change is some function

 ¢¡ £30

F£¦¥¨§B©  £¦¥  P

0 0 4 (3)

of the pre- and postsynaptic states

¡

and

be the initial weight

naptic state sequences

¡

£ ¥¨§© £ ¥atwere

time 4 and the time 4 itself. If the pre- and postsy-

known, the weight

0 at time 4 would simply ¡

plus all the previous weight changes:

Wp£0 ¥¨§B©  £ ¥¨§B©cq  ¡  d 1 rcs

0

 5¡ F£¦¥¨§B© £¦¥ P r  r 7t (4)

In the current context,( the state sequences are unknown and have to be estimated from the

spike trains ( and

¡

expectation value of

Ideally, we would like to set the weight( at time 4 equal to the

given the spike trains

¥¨§© ¥

these spike trains are( known( at0 time 4 . Of the sequence

the past values

v¥¨§© w¥¨§B© v¥A§B©( , ¡

... ( , which we will call

(

and . But only part of

v¥¨§©(

¥¨§©(

(

the synapse has already seen

v¥¨§B© 0

¥A§B©

Wp£0¥cu¥¨§B©.  £ ¥ q,

, and the present value

(

. But


2/1 triplets; phen. model 2/1 triplets; hidden Markov model 2/1 triplets; linear rule

dw

1 0.5 0 -0.5 25

dw

1 0.5 0 -0.5 25

dw

1 0.5 0 -0.5 25

examples of 2/1 triplets

5 5 5

0 -5 -25

25 5 t1

0 -5 -25 0 -5 -25

25 5 t1

0 -5 -25 0 -5 -25 (ms)

25 5 t1

0 -5 -25 t2

25 5 0 -5 -25

t2 (ms) (ms) t2 (ms) (ms) t2 (ms) (ms)

25 5 0 -5 -25

t1 (ms)

1/2 triplets; phen. model 1/2 triplets; hidden Markov model 1/2 triplets; linear rule

dw

1 0.5 0 -0.5 -25 -5

dw

1 0.5 0 -0.5 -25 -5

dw

1 0.5 0 -0.5 -25 -5

examples of 1/2 triplets

(ms)

t2

0 25 0 25 0

-25 -5 0 5 25

5 25

-25-5t1

0 5 5 25

-25-5t1

0 5 5 25

-25-5t1

0 5 25

-25 -5 0 5 25

t2 (ms) (ms) t2 (ms) (ms) t2 (ms) (ms)

t1 (ms)

Figure 2: Weight change produced by spike triplets in various models. Our learning rule (second column), which depends on the timing of firing episodes but only weakly on the timing of individual spikes, and which was implemented using hidden Markov models, agrees well with the phenomenological model (first column) that was used in [5, fig 3b] to fit data from superficial layers in rat visual cortex. It certainly agrees better than a purely linear rule (third column). Parameters were set so that all three models produce the same results for spike pairs (1 presynaptic and 1 postsynaptic spike). Upper row: Weight change produced by 2 presynaptic and 1 postsynaptic spikes (2/1 triplet). Lower row: 1 presynaptic and 2 postsynaptic spikes (1/2 triplet). and are the times between preand postsynaptic spikes. The small boxes on the right show examples of spike patterns for

aF¤ aQ%

a a¥¡

positive and negative and

it has not yet seen the future sequence

¡

and correct

(

do is to make0 some assumption about what the future spikes will be, set

¥¨§©# w¥¨§©#

0 , ( 0 ¡ , ..., which we will call

v¥¨§B© #¡

(

0 . All one can accordingly,

in the future, when the real spike sequence becomes known. Our algorithm

assumes no future spikes and sets the weight at time 4 equal to:

¡

¡ ¡£¢ ¡

0  £ ( RTRSRC¦¥

0

p£ ¥¨§©  £ ¥¨§© q C3(w¥¨§B©  w¥¨§©  w¥¨§B©(  v¥¨ (v¥¨  v¥c

#   ( 0 ( ( #   ( 0 (

( ¤

where is the expectation value given the spike sequences . The condition that

(5)

all future spikes are 0 is written as

(

assumptions about the future spikes, but all these assumptions would affect only when the weight changes, but not how much it changes in the long run. This is because the expectation value of a past weight change:

¡ ¢  5¡ F £¦¥¨§B©  £¦¥ 7t P v¥¨§©  w¥¨§B©  w¥¨§B©(  v¥c  w¥  v¥¨ r r

HH¥¨§©# ( 0

(

w¥

(

# ( 0 ( ( ¤ (6)

¥¨§B© #

 

and

w¥ #

(  

. One could make other

will depend little on the future spikes

(

#

( and

(

# t

, if the time is much earlier than the

time 4 . As 4 grows, most weight changes will lie in the distant past and depend only weakly on our assumptions about future spikes. Next we will show how to compute the expectation value in eq. (5) without having to store

the past spike trains

(

(

. To simplify the notation, we will regard each pair of pre- and


postsynaptic states

F£¦¥¨§B© £¦¥ P r  r as a state £ r of a combined pre- and postsynaptic Markov

model. We will also combine the pre- and postsynaptic spikes

can take the two values 0 or 1, to a single observable desired weight is then equal to:

¡ ¡¡  ¡

0  0 p£ q C1( #   ( 0 (   ¥

( ¡ with 0

(

r p£ q

F@(w¥¨§© w¥ P r  r (

, each of which

, which can take 4 values. The 0



¡



d 1 rcs  ¢¡ ¤££ r4t

¦ (7)

3.2 Running estimate of state probabilities

¡

To compute 0 , it is helpful to first compute the probabilities

¢

& 4 £ ¦ 

@ ££

%0  9

C1(

#

  (%0 ( ¦

(   (8)

of the states given the past and present spikes and assuming that there are no future spikes.

The & 4 can be computed recursively, in terms of $ 4

forward algorithm for hidden Markov models). Write

¢ 1

& 4 £ ¦   0 

9

 £ ¤£ C1(

0

(  #

£ ¦ £ C ¤§¦

¢

as:

(this is similar to the familiar

¢ ¢

1 $

@E£A£ @E£)(

  ( 0 ( ¦

(

 £%0( ¥£  §¦9@

 ( ¦ E£ (

(

 

#   (10 10 

  £ 9 #

(%0

  (%0 ( ¦

(   (9) (10)

$

Because of the Markov property, future and present spikes

present state or on

but not on

@E£

(

#

(

(

but not on the past state

(

(

(

£10,

 

)C¦£

. Thus the enumerator of the last expression is equal to:

0  9

98¦ @

£ ( 0

C¦£

0  9

98¦ @ ££

0  9

C £ ¨£ I8@ £ ¥£ 

0  ¦ £ 0 

© E8¦

& 4 £ with

(

   £)(%0 ¦

© &

& 4 £ ¦ 

£30(

. Similarly,

# £%0

and

( ¦

depend only on the

depends only on

( ( ¦ (

£10(

(11) (12) (13)

©

98 8 @E£¤£%0)C( ¨£ 

# $F&

@



£ (

#

The probabilities & 4 of having no future spikes after state 9 can be computed by the

backward algorithm:

© 1 2

& 4 £ ¦ 

@E£

2 2 2

(

#    £ &6DC £ 0 #  0  ¦  9 1 2 © d 98 98 £ 4

¤§¦   £@¦ # &

£ ¦

  %0  ¦ 9

£ (

(14)

This is a linear equation with constant coefficients. As long as the end of the Markov chain is far enough£ in the,future, this equation reduces to an eigenvalue problem with the solution and the eigenvector will be unique up to a constant factor (except for quite exceptional, disconnected Markov chains, in which it may depend on the choice of end state). The

© ¥ ©8 d

& 4 and £ ¦  ©

& 4 ¤§¦ 

where is the largest eigenvalue of the matrix with elements



  £@¦

48# &

is the corresponding eigenvector. As the matrix elements are positive, will be real,

last£ unknown factor in eq. (12) is

@E£¤£ ¤£ 

0

( 

$ 4 C ¤¦ :

( ¦ 

(

¨¢ I@E£)(

$ 4 £ CD¤¦

¢ @ £30( ¥£ 

£ 

#

( ¦

(

, which can be expressed in terms of

2 2

  ( 0   ( ¦ E£ (

  ¦9@ ( #   ( 0   

)C¦£ ¥£ 0

( 

¦

(15)

where the Markov property was used again. Putting everything together, one gets the update

rule for & 4 : £ ¦

¢ 1

& 4 £ ¦ 



$F& £)( 0 ( ¦ $ 4 £ C ¤¦ (16)

¢

$

@E£)( ( I8¦ £)(%0

#

 I8¢ (

with

 $F&  (

£ (10 ( ¦ 

£)( 0

((

¦ 

  (& 0   ( ¦ E£)(  (   £ (%02¦

I8 ©8 cb¦ ©

# ¦9@& ( $'& £ 4

# $ 4 £ C ¤§¦   ( 0 ( ¦   ( (17) (18)


£ the eigenvalue The ratio & 4

pre- or postsynaptic spike at time 4 ((



to 1, and

© cb¦©

$ 4 £ C¤¦ 

© b¦ D8 © & 4 £ £ $ 4 does not really depend on 4 but only on £ ¦ ¦

and the relative size of the elements of the eigenvector£)( .0 If there is no 0   ¦

is equal

(

), the normalization factor

(

 ( ©

$F& no longer depends on 4 or

with constant coefficients, which can be integrated analytically from one spike to0 the next,

thereby speeding up the numerical simulation. At pre- or postsynaptic spikes ((

can be computed by summing eq. (16) over 9 and using ¢

A£ ( (%0 £¤ ( ¦ 

1 3

& $

¢ $ 4 £ C ¤¦   £ (%02¦ & 98

&

¢

& 4 £ ¦  ¤

:

I8 ©8 cb¦ © # $'& & 4 £

(

¡  ),

. In this case, eq. (16) is a linear equation



(

$ 4 £ C ¤§¦¦¥§ (19)

3.3 Running estimate of weights Using the knowledge of the probabilities & 4 , one can now compute the weight

¢ £ ¦

¡ 0 



¡¡ ¡¡  ¡¡ ¡¡  ¡

Wp£0 q C3(

0

(

p£ q C3(#

0

  (%0 (   (%0 (

#

 ( ¥ d

(

  ¥

1  5¡ £ ¦ 9 4  8 ¢

The expectation value changes as:

& 4 £ ¦

¡ 0

(20) (21) , if there is

no pre- or postsynaptic spike at time 4 ((

¡ ¡

0  0

( d

( p£ q C1( ¥

&

in this equation will be equal to

0  

1

). In between spikes, the weight therefore

 5¡

£ ¦ 9 4

 98 ¢

& 4 £ ¦ (22)

(

&

At the time of spikes, the weight change is more complex, because earlier weight changes have to be modified according to the new state information given by the spikes. To compute it, let us introduce the quantities

¨ £ ¦  & 4

¤¢ I8¦

& 4 £

¡   ¡

0

p£ q C1(

#   (10 10 

  £

9

 ¥

(

( (23) ¨

The weight is equal to the sum of these :

¡

0 

1 ¨ £ ¦ & 4

(24)

&

and, as we will see next, the & 4 can be computed in a recursive way, even in the presence of spikes. Start with:

¨ £ ¦ & 4  #

  (%0 10 

#

  £

9

 ¥

( §¦

9

(

( ¦

(25)



¢ 5¡&£498¦£9498¦  d

£

 5¡

¢ d @E£A£(%0( ¤£ C1( 1

& 4 £ ¦

8

¡¡  ¡



$ 0

(

p£ q C (

#

£ ¦ 9 4

¡¡  ¡

0

Ep£ q C1(

  (%0 10 

0  9

  £

¨ £ ¦

E8 ¢ 98¦ & 4 £

 £ ¨£  ¥

0

(

 (

(

(

  ( 0   £

 8¢ '@ A£$

b ¢

(

Because of the (Markov property, the last expectation value depends only on

not on

0

(

( 0

@E£A£ ¤£ C1( , 9 , or  #

, and it is thus equal to $ 4

  ( 0

  £

0 

9

¨ £ C ¤¦

£ C ¤¦ 4

# ( ¦ £ ¦  E£ 0 

( & 4 9

 £.0( ¥£ C3(

The other two factors



#

  ( 0 ( ¦

(

(27)

 

(

and , but

£

(26)

combine to give the same expression that already occurred in equation (9). As shown above (eq. (16)), this expression is equal to





$F& £@(%0 ( ¦

 I8 ¢ (

$ 4 £ C ¤¦

(28)

with the same $'& as before. Puttingeverythingtogether,one gets the updaterulefor & 4 :

¨ £ ¦  & 4

 5¡

£ ¦ 9 4

 8 ¢ ed

& 4 £ ¦

1 

$'& £ (%0 ( ¦ ©¨ £ C ¤§¦ $ 4 (29)

$

 I8 (

¨ £ ¦


Together with eqs. (16), (17), (19), and (24) this constitutes our learning rule. It is causal, because it depends only on past, not on future signals, but in the long run it will give the same weight change as the standard hidden Markov rule (2). In between spikes, the in according to the simple rule (22). These simplifications are a consequence of assuming, in , that there are no0 future spikes. Other( assumptions are possible: One occur with the rate predicted by the Markov model, and one could also derive a causal

¢

eq. (16) and the ¨

in eq. (29) evolve according to linear rules, and the weight changes

¡

the definition of 0

¡ ¡ ¡¡  ¡

could, for example, set

0 equal to  0

p£ q C1(10  ¥ (

, assuming that future spikes

¡ ¢

learning rule for this

0

(not shown), but then the evolution of

¡

and

¨

between spikes

¡

would be nonlinear and the evolution of would also be more complex. plus some weight change. Our rule can also be written in this form, if the ¡

This learning rule still has a rather unusual form. Usually, one writes 0 as the sum of

by:

Y ¡ & 4 £ ¦ 

¨ £ ¦ C

&£ 4¦ & 4

£

0

¨

are replaced

(

¢ ¡¡ ¢ ¡£ & 4 98¦ 0

£ ¦

#

9

 ¥ (

(

¡¡  ¡

Y #   ¥ (

(30)

 Wp£0 q C (   (%0 10   £ C 0 p£ q C¥(   (10 ( ¦(31)

& 4 is ameasureforhowmuchtheweightshouldbechangedifonesuddenlylearned,with

certainty, that the neurons are in state 9 . By definition, the

¨ £ ¦

YY

£sum ¦

to zero: ¢

&

Y

& 4 £ ¦  

.

Inserting the update rule for & 4 gives the update rule for & 4 :

Y ¡ 1

& 4 £ ¦  £

£ ¦ C 9 4 £ ¦ C 9 4





0 ¦ £ ¦ & 4

¢ d 

$F&

 £

 5¡  5¡

£ (10 ( ¦ £ £ C ¤§¦

1 1 3

$

$ &



( ( 98Y $ 4 £ ( 0

$'& ( ¦

$F& £)(%0 ( ¦  98 Y (

Y d ¢ $ 4 £ C ¤§¦ 0 ¦ ( ¡

¡ ¡ 0 d 98¦ ¢ ed¦ & 4 £

0 : ¡

$

0

( $ 4 £ C ¤¦

(32) (33)

Summing over 9 gives the update rule for

¡ ¡

0  0

(

d 1  5¡

£ ¦ 9 4

 98 ¢ d

& 4 £ ¦



&

$ 4 £ C ¤¦ (34)

The last, -dependent sum is nonzero only if spikes arrive. It occurs because a new spike changes the probability estimates of previous states, and thereby the desired weight. 3.4 Summary of the learning algorithm To simplify notation, we combined the pre- and postsynaptic Markov models into a single one. How does the learning rule look in terms of the original pre- and postsynaptic param-

eters? If the presynaptic model has  

combined model has  

the weight

£

0

but  

¡ ¥¨§© 8 ¥cu 

 

£

¥A§B© 8 ¥¨

¥¨§© states and the postsynaptic one  

Y

¥

, then the

Y¢¡

Y

denotes the presynaptic and

¥¨§B© d ¥c

signal traces , which we will now write as

states. At each time step, we have to update£ not only ¦ $ 4 , where

the postsynaptic state. However, one needs to update only

 

¢ ¨¢of¡¥¨§©the£498¦ ¢¥cu

¡ £ ¦  $ 4

¤ Initialization (4

 

signal traces , because they factorize into a pre- and a postsynaptic

$

£ ¦ 4 . The learning algorithm is then given by:

: Define the states and the parameter   and # of the pre- and   ¦

¢

part:

postsynaptic Markov model. Find the leading eigenvector of both Markov chains in the absence of spikes:

Define the weight change

© 0 0

4 for all possible state pairs.

¨¥A§B©$ 98¦ ¥¨§© 8 ©¥¨§B©

£  & $ $

"¦¥

¢ #  ¤

 ¥¨§© 8 ©¥¨§B©&

¡ ¡ ( 



1

  (35)

 5¡

F7£¦¥¨§©  £¦¥¨  P

$

Initialize

¡ , , and Y ¢ 

;

Y for arbitrary start state and 0

otherwise)


¤ Recursion 4 £  ¤

 ¥¨§B© D¥¨§B©$'& ¢ ¥¨§B©

&



 %  RSRTR¦

 

1

:

¢¥¨§B©$ 8 ¨¥A§B©& v¥¨§©0 98¦ ¥¨§©$'& 8 ©¥¨§B©& b  ¥¨§© 8 ©¥¨§B©$

  £)(

#

£ ¦¢¡

(



1 ¥¨§B©$'& 8¥¨§©$'&¨¥¨§©& w¥¨§©0 I8¦ ¥¨§©$'& 8 ©¥¨§B©& b  ¥¨§© ©8 ¥A§B©$

  £ (

8 ¢ ¥¨§B©

$

 ¥¨ 2 ¥¨,

# £

$ £

¦

(36) (37) (38)

and analogous equations for

Y 2¡



1243

£

 ¢¡

£

& £

¡

£

¡

 5¡& d Y

76£   Y I8¦ ¢ ¥¨§B© 8 ¢ ¥c d&  ¥¨§©2 8  ¥ 8 Y ¡

1 3

¡

$

¡

9 4

¦ C

& ¡ $'&

¡

$

6   98¦ ¢¥¨§© 82¢¥ d

9 4 &

and

¢ ¥. 1243 1 3

2  ¥¨§©¡ 8 D¥ 8Y

$'& ¡

Y ¡

$ (39) $ (40) (41)

¤

Terminate at the end of the spike sequences (

¥¨§© and ( ¥ .

4 Conclusion This demonstrates that the basic principle of associating not individual spikes, but whole firing episodes, can be implemented in a causal learning rule, which depends only on past signals. This rule does not have to store the time of all past spikes, but only a few signal it agrees well with some nonlinear features of cortical synaptic plasticity (fig. 2). This does not imply that actual synaptic plasticity follows the same rule, but only that these particular features are consistent with our basic principle. Based on the predictions of this rule, one could design more precise experimental tests of whether cortical synaptic plasticity associates individual spikes or whole firing episodes. Acknowledgments This work was supported by R01-EY11001. We thank T. Sejnowski for his comments on a similar type of learning rules, which he suggested to call "hidden Hebbian learning". The second author (KM) would like to emphasize that his contribution to this paper was limited to assistance in writing. References [1] G.-Q. Bi and M.-M. Poo Synaptic modification by correlated activity: Hebb's postulate revisited. Ann. Rev. Neurosci., 24:139­166, 2001. [2] O. Paulsen and T. J. Sejnowski. Natural patterns of activity and long-term synaptic plasticity. Curr Opin Neurobiol., 10:172­179, 2000. [3] W. Senn, H. Markram, and M. Tsodyks. An algorithm for modifying neurotransmitter release probability based on pre- and postsynaptic spike timing. Neural Comput., 13:35­67, 2001. [4] P. J. Sjostrom, Turrigiano G. G., and S. B. Nelson. Rate, timing, and cooperativity jointly determine cortical synaptic plasticity. Neuron, 32:1149­1164, 2001. [5] R. C. Froemke and Y. Dan. Spike-timing-dependent synaptic modification induced by natural spike trains. Nature, 416:433­438, 2002. [6] L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77:257­286, 1989.

¢ Y and , and may thus be biologically plausible. For the right parameter choice, traces


