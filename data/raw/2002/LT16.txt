Fractional Belief Propagation

Wim Wiegerinck and Tom Heskes SNN, University of Nijmegen Geert Grooteplein 21, 6525 EZ, Nijmegen, the Netherlands wimw,tom @snn.kun.nl

 

¡

Abstract We consider loopy belief propagation for approximate inference in probabilistic graphical models. A limitation of the standard algorithm is that clique marginals are computed as if there were no loops in the graph. To overcome this limitation, we introduce fractional belief propagation. Fractional belief propagation is formulated in terms of a family of approximate free energies, which includes the Bethe free energy and the naive mean-field free as special cases. Using the linear response correction of the clique marginals, the scale parameters can be tuned. Simulation results illustrate the potential merits of the approach.

1 Introduction Probabilistic graphical models are powerful tools for learning and reasoning in domains with uncertainty. Unfortunately, inference in large, complex graphical models is computationally intractable. Therefore, approximate inference methods are needed. Basically, one can distinguish between to types of methods, stochastic sampling methods and deterministic methods. One of methods in the latter class is Pearl's loopy belief propagation [1]. This method is increasingly gaining interest since its successful applications to turbo-codes. Until recently, a disadvantage of the method was its heuristic character, and the absence of a converge guarantee. Often, the algorithm gives good solutions, but sometimes the algorithm fails to converge. However, Yedidia et al. [2] showed that the fixed points of loopy belief propagation are actually stationary points of the Bethe free energy from statistical physics. This does not only give the algorithm a firm theoretical basis, but it also solves the convergence problem by the existence of an objective function which can be minimized directly [3]. Belief propagation is generalized in several directions. Minka's expectation propagation [4] is a generalization that makes the method applicable to Bayesian learning. Yedidia et al. [2] introduced the Kikuchi free energy in the graphical models community, which can be considered as a higher order truncation of a systematic expansion of the exact free energy using larger clusters. They also developed an associated generalized belief propagation algorithm. In this paper, we propose another direction which yields possibilities to improve upon loopy belief propagation, without resorting to larger clusters. This paper is organized as follows. In section 2 we define the inference problem. In section 3 we shortly review approximate inference by loopy belief propagation and discuss an inherent limitation of this method. This motivates us to generalize upon loopy belief propagation. We do so by formulating a new class of approximate free energies in section 4. In


section 5 we consider the fixed point equations and formulate the fractional belief propagation algorithm. In section 6 we will use linear response estimates to tune the parameters in the method. Simulation results are presented in section 7. In section 8 we end with the conclusion. 2 Inference in graphical models

Our starting point is a probabilistic model

in a finite domain. The joint distribution

of clique potentials

 ¡  

on a set of discrete variables

¡£¢¤¡¦¥¨§©©©§¡

is assumed to be proportional to a product

 ¡"!$#&%$' (¡ )§ % % (1)

where each

0

refers to a subset of the

1

nodes in the model. A typical example that we will

consider later in the paper is the Boltzmann machine with binary units (

 (¡8!@9BADC¦EF2GHPIRQ 2SH ¡ 2¡ HUT E¨VXW ¡  § V V

where the sum is over connected pairs of potentials

¡23¢5476

),

(2)

' 2dH (¡ 2SH e¢f9ADC¦Q 2SH ¡ 2¡ HgT(Y`§bacFihp3qrh¥ W 2¡ 2¦T

. The right hand side can be viewed as product

I

W H ¡ H P,

where

u 2

is the set of

¡ wR¡2 ¡

Y

hptsh¥

edges that contain node . The typical task that we try to perform is to compute the marginal

single node distributions

remaining variables

2v.

Basically, the computation requires the summation over all

. In small networks, this summation can be performed explicitly.

In large networks, the complexity of computation depends on the underlying graphical structure of the model, and is exponential in the maximal clique size of the triangulated

moralized graph [5]. This may lead to intractable models, even if the clusters When the model is intractable, one has to resort to approximate methods. 3 Loopy belief propagation in Boltzmann machines

¡ %

are small.

A nowadays popular approximate method is loopy belief propagation. In this section, we will shortly review of this method. Next we will discuss one of its inherent limitations, which motivates us to propose a possible way to overcome this limitation. For simplicity, we restrict this section to Boltzmann machines.

The goal is to compute pair marginals tion computes approximating pair marginals

 (¡ 2SH x

of connected nodes. Loopy belief propaga-

2SH ¡ 2dH 

by applying the belief propagation

algorithm for trees to loopy graphs, i.e., it computes messages according to

y



2H (¡ H !E 9ADC¦Q 2SH ¡ 2¡ H  2dH (¡ 2§ q (3)

in which

2dH

are the incoming messages to node except from node ,



qv

y

H

e2 (¡ 2©

Y 2SH (¡ 2 ¢@9ADCW 2¡ 2 V#p

V

a

(4)

If the procedure converges (which is not guaranteed in loopy graphs), the resulting approximating pair marginals are

x 2dH (¡ 2SH 8!9AcCtQ 2dH ¡ 2¡ H  2SH (¡ 2  HP2 ¡ H U©   2SH ¡ 2SH !9BADCQ 2SHb ¡ 2¡ H  2SH ¡ 2 HP2 (¡ H §  

In general, the exact pair marginals will be of the form

(5)

(6)


which has an effective interaction

Q 2SHb

. In the case of a tree,

2dH Q

2SH Q

2dHb

Q 2SHb ¢ 2dH

. With loops in the

graph, however, the loops will contribute to

from

Q

, and the result will in general be different

Q

. If we compare (6) with (5), we see that loopy belief propagation assumes

Q

2dHb

Q

2SHb ¢

Now suppose we would know

, ignoring contributions from loops.

in advance, then a better approximation could be ex-

pected if we could model approximate pair marginals of the form

x 2SH ¡2dHR8! 9BADC ¡2(¡ H  2SH ¡2b  HP2`(¡DH U§

Q¡

. The



2dH

are to be determined by some propagation algorithm.

 

In the next sections, we generalize upon the above idea and introduce fractional belief propagation¡ as a family of loopy belief propagation-like algorithms parameterized by scale

parameters £ ¢

%

 

¡ . The resulting approximating clique marginals will be of the form

x ¡ 8!' ¡  #  2`¡2v§

2 p ¨

¥¥¤§¦©¨  % % % %

¡

(8)

2SH ¢ 2dH 2dHb Q Q

¢

2SH2SH (7)

¡ where

u

%

where is the set of nodes in clique . The issue of how to set the parameters £ is subject

0 ¡

of section 6.

4 A family of approximate free energies The new class of approximating methods will be formulated via a new class of approximating free energies. The exact free energy of a model with clique potentials

¥ ¨

 

i e E  ¡  E %!#"%$ ' (¡  T ER  ¡   (¡© &"'$

% % '

%

¡

is

(9)

It is well known that the joint distribution

energy

  ¢)(10

 (¡g¢ 6

  can be recovered by minimization of the free

8 $'243#5

7 6 ¨%

 e (10)

under the constraint 9

A@CBDBFEHG©I

.

ergy

of

 

xe



. The idea is now to construct an approximate free en-

and compute its minimum

x

. Then

x

is interpreted as an approximation

A popular approximate free energy is based on the Bethe assumption, which basically states

that

x

is approximately tree-like,

x(¡8¢ # % x (¡  # x 2`¡2b

2

are the cliques

0

% % ¥QP hp q h §

(11)

in which

u 2

that contain . This assumption is exact if the factor graph [6]

Y

of the model is a tree. Substitution of the tree-assumption into the free energy leads to the well-known Bethe free energy

ARW

TSVU

¨ 

 x § x 2 R¢ E % E x ¡  ' (¡  T E % E x ¡  x¡  T E r6X`Yu 2§Y E x 2P¡2v x¡2v§   #"%$ ¡

% % ¨ &"'$ %

¨

2

q

&"'$

 %

% % % % %

(12)

9

 q x 2 ¡ 28¢ 6  q x ¡ ¢$xx 2 (¡ 2 Ydc£uand%

% %

¡ ¢ 6

for

which is to be minimized under normalization constraints 9

and the marginalization constraints 9 ¨ba

¨

.


It can be shown that minima of the Bethe free energy are fixed points of the loopy belief propagation algorithm [2]. In our proposal, we generalize upon the Bethe assumption, and make the parameterized assumption

x ¡¢ #r% x ¡  # x 2 ¡ 2  ¦©¨

2

by a factor

x ¡q .¦

¡

%

% %p %

¨

% % ¥QPC¦q hp q h

§ (13)

' ¡ 

% % ¡ 2¢ 6 u72¥YW9

¢ Y

in which

each

The intuition behind this assumption is that we replace . The term with single node marginals is constructed to

deal with overcounted terms. Substitution of (13) into the free energy leads to the approximate free energy

¡ W¦



¨ 

 x §%x 2 ¢% E%% E x ¡  ' (¡ 

 

#"%$ ¡

¨

% % % % %

T E % E x ¡  x ¡  T E r6X 2§Yu72WY E x 2(¡2& x 2P¡2v§ ¡ &"'$ ¡

¨

2 q &"'$

%

(14)

which is also parameterized by £ . This class of free energies trivially contains the Bethe

free energy (¡

£¢¥¤ %  ¦

variational mean field free energy, con-

2 x 2 ' T 2 x 2 x 2

9 9 &"'$ as a limiting

% 

ventionally written as

¡

case for

¢

¡

%

¢ 6 ¨§©

). In addition, it includes the#"%$

¢

9 9

¨

q

%

¡

(implying an effective interaction of strength zero). If this limit is

taken in (14), terms linear in

¡

will dominate and act as a penalty term for non-factorial

entropies. Consequently, the distributions will be constrained to be completely factorized,

x ¢ 2 x 2.

¨

representation of

Under these constraints, the remaining terms reduce to the conventional

. Thirdly, it contains the recently derived free energy to upper bound

¢¥¤

% ¦ 

p

the log partition function [7]. This one is recovered if, for pair-wise cliques, the

¡

2SH

's are set

to the edge appearance probabilities in the so-called spanning tree polytope of the graph.

These requirements imply that

 2SH 56 ¡ 

.

5 Fractional belief propagation In this section we will use the fixed point equations to generalize Pearl's algorithm to much about guaranteed convergence. If convergence is a problem, one can always resort

fractional belief propagation as a heuristic to minimize ¦

 . Here, we do not worry too



 

to direct minimization of

¦

using, e.g., Yuille's CCCP algorithm [3]. If standard belief R

TSU

propagation converges, its solution is guaranteed to be a local minimum of



expect a similar situation for

 Fixed point equations from

¦

¦

 

 .

are derived in the same way as in [2]. We obtain

[8]. We

x ¡  !' (¡  # # % 2 ¡ 2 2 ¡ 2 

x 2`¡2b ! # % 2`¡2b§

%

2`¡2b% ¢

% xx (¡2& %

2 (¡ 2  y

y

% 2 p  p3q ¨

% % % % ¥W¤8¦©¨ y  y % ¥§P¥¥¤§¦©¨

§ (15)

(16)

y

x (¡ 

%

2¡2&U©

'

%

and we notice that has indeed the functional dependency of

(17) as desired in (8).

Inspired by Pearl's loopy belief propagation algorithm, we use the above equations to formulate fractional belief propagation (see Algorithm 1) . 1

1

 "!$#, !

  8£¡ 

i.e. with all

%'&¨(

, is equivalent to standard loopy belief propagation


Algorithm 1 Fractional Belief Propagation

1: initialize( 2: repeat

3: 4: 5: 6: 7:

2 §`x 2 ! p q 2

)

y % ¦ y % 7 8£¡  

for all update update update end for

0 %%

do

yxxe2,Ydc 2accordingaccording

, dc

Y£u u% % to (15). by marginalization of

x % x %

to (17) using the new

.

and the old

x 2.

8: until convergence criterion is met (or maximum number of iterations is exceeded) 9: return (or failure)

 

¡

% x §`x 2

As a theoretical footnote we mention a different (generally more greedy) £ -algorithm,

which has the same fixed points as

that (1) the update of

x

% 7 8£¡ . 

This algorithm is similar to Algorithm 1, except

%

line 4) is to be taken with

¡

¡

the divergence D

¥W¤§¦©¨ ix § 2 xe2i

¨

%(in¦ 

p

x 2

¢ 6

, as in in standard belief prop-

agation and (2) the update of the marginals (in line 6) is to be performed by minimizing

¡ 6X  ¡

6

where ¢

6X E   ¡  x¡   

D  with the limiting cases

D

¥ ( § xe8¢5E¨  (¡

B( § xe¢

¥QP £ ¥¤ § (18)

&"'$

 ¡ x¡  and D¦

i §`xe"¢$E  x¡  &"'$

x ¡  (¡ § (19)

rather than by marginalization (which corresponds to minimizing D , which is the equal to

the usual §©¨ divergence). The D  's are known as the -divergences [9] where

and 

6  0  6

. The minimization of the

x 2's

0 ¡ ¢ (0 T 6  

using D¦ leads to the well known mean

¥

¥

field equations.

6 Tuning  using linear response theory  Now the question is, how do we set the parameters £ ? The idea is as follows, if we could

have access to the true marginals for example, 

  (¡ ¢  ¡ , % % % ¡

we could optimize £ by minimizing, ¡

8£¡ ¢E % gi  §`x $E % E   ¡  § ¨

¨

in which we labeled

x

% %¦  % %

#"%$

%% x ¡%¦  (¡ 

© (20)

by £ to emphasize its dependency on the scale parameters. Unfor¡

tunately, we do not have access to the true pair marginals, but if we would have estimates

  %¦ . %¦ 

that improve upon

x

, we can compute new parameters £ such that "!¡

However, with the new parameters the estimates

 %$#¦ 

x

is closer to

will be changed as well, and this

%¦ 

%¦  %$#¦ 

procedure should be iterated.

In this paper, we use the linear response theory [10] to improve upon

x

. For simplicity,

we restrict ourselves to Boltzmann machines with binary units. Applying linear response the pair marginals,

theory to

  §£¡ 

in Boltzmann machines yields the following linear response estimates for

x 2dH¦ &%(' (¡ 2SH ¢$x 2¦  ¡ 2 Px H¦  ¡ H  T P

¡)10H x 2¦ WH(¡ 2 

0

© (21)


Algorithm 2 Tuning £ by linear response

1: initialize(  2: repeat

3: 4: 5: 6:

)¢X6 § ¢ 6 ¡

)

¡ ¢¡£ ¡

set step-size £

compute the linear response estimates

compute £ ¦¡¨§ set © 

¢  T 6

¡

¥

as in (22).

x 2SH¥¤¦ ©P &%(' as in (21)

7: until convergence criterion is met 

8: return

¦ ¤

x 2SH¦ ¤ § x 2 

In [10], it is argued that if

estimate is 

¡ .

 x (¡2SHR

¦

  is correct up to 

¡ ,

the error in the linear response

Linear response theory has been applied previously to improve upon

pair marginals (or correlations) in the naive mean field approximation [11] and in loopy belief propagation [12]. To iteratively compute new scaling parameters from the linear response corrections we use a gradient descent like algorithm

¡£ ¡¨§ ¥ ¢!£¡ ¡

£

%('  ¡ ¦   E ix F2SHPI § ¨

2SH¥¤¦  §`x 2SH¦  

P (22)

with a time dependent step-size parameter £ . ¡ By iteratively computing the linear response marginals, and adapting the scale parameters in the gradient descent direction, we can optimize £ , see Algorithm 2. Each linear response

¡

estimate can be computed numerically by applying

parameters

with parameters £



(u  T  



Q §W ¡ Q¡ §PW T W H .

and

  8£¡ 

to a Boltzmann machine with

Partial derivatives with respect to

¡

2SH

, required for the

gradient in (22), can be computed numerically by rerunning fractional belief propagation

T 2SH

. In this procedure the computation cost to update £ requires

¡

is the number of nodes and  is the times the cost of

7 8£¡ , 

where

u

number of edges. 7 Numerical results

We applied the method to a Boltzmann machine in which the nodes are connected according to a !#"$! square grid with periodic boundary conditions. The weights in the model were

 

drawn from the binary distribution

were drawn according to ('0)

W 2  §Q  ©6 c

2dH



 ©&%D§' ©&%

with equal probability. Thresholds



networks, and compared results

¡

)

We generated

of standard loopy belief propagation to results obtained by fractional belief propagation where the scale parameters were obtained by Algorithm 2.

In the experiment the step size was¢ set to be £

stopped if the maximum change in

exceeded  

¢ 6  

6 2SH

¡

¡

was less than

¢ 66 6 T  

¢

&"'$ 21 P



. The iterations were , or if the number of iterations

. Throughout the procedure, fractional belief propagations were ran

with convergence criterion of maximal difference of

6 

43 P

between messages in successive

iterations (one iteration is one cycle over all weights). In our experiment, all (fractional) belief propagation runs converged. The number of updates of £ ranged between 20 and ¡

80. After optimization we found (inverse) scale parameters ranging from

6 2SH ¢ ¡

5 .

¢

)

6 2SH65  ©&% ¡

 to

Results are plotted in figure 1. In the left panel, it can be seen that the procedure can lead to significant improvements. In these experiments, the solutions obtained by optimized

  §£¡  are consistently 10 to 100 times better in averaged §©¨ , than the ones obtained by


0

10 1

BP(1) BP(C) BP(1) BP(C)

>) 0.5

c

ij || 10 Q

-2

ij approx > 0 P i

<X KL(

< -0.5

-4

10

-4

10 -2

10 < KL( P || Q1 ) > ij 0 10 -1 -1 -0.5

ij

0 <X > i ex 0.5 1

Figure 1: Left: Scatter plots of averaged § ¨ between exact and approximated pair

marginals obtained by the optimized fractional belief propagation (

obtained by standard belief propagation (

7 r6). 

7 8£¡ ) 

versus the ones

Each point in the plot is the result of

one instantiation of the network. Right: approximated single-node means for

optimized

  6

highest

7 8£¡  

  6

and

against the exact single node means. This plot is for the network where

had the worst performance (i.e. corresponding to the point in the left panel with

  §©¨g( 32SH §`x 2dH ¢¡

).

¥

standard

  6 . The averaged §©¨ is defined as

£

§©¨

gi  2SH §`x 2SH ¥¤¢ EF2dHPI (  2dH § x 2dH 3© § ¨ 

6 (23)

In the right panel, approximations of single-node means are plotted for the case where

  6

had the worst performance. Here we see that procedure can lead to quite precise

estimates of the means, even if the quality of solutions by obtained

  6

is very poor.

Here, it should be noticed that the linear response correction does not alter the estimated means [12]. In other words, the improvementin quality of the means is a result of optimized

¡£

, and not of the linear response correction.

8 Conclusions In this paper, we introduced fractional belief propagation as a family of approximating inference methods that generalize upon loopy belief propagation without resorting to larger clusters. The approximations are parameterized by scale parameters , which are motivated to better model the effective interactions due to the effect of loops in the graph. The approximations are formulated in terms of approximating free energies. This family of approximating free energies includes as special cases the Bethe free energy, the mean field free energy, and also the free energy approximation that provides an upper bound on the log partition function, developed in [7]. In order to apply fractional belief propagation, the scale parameters have to be tuned. In this paper, we demonstrated in toy problems for Boltzmann machines that it is possible to tune the scale parameters using linear response theory. Results show that considerable improvements can be obtained, even if standard loopy belief propagation is of poor quality. In principle, the method is applicable to larger and more general graphical models. However,

% ¡


how to make the tuning of scale parameters practically feasible in such models is still to be explored. Acknowledgements We thank Bert Kappen for helpful comments and the Dutch Technology Foundation STW for support. References [1] J. Pearl. Probabilistic Reasoning in Intelligent systems: Networks of Plausible Inference. Morgan Kaufmann Publishers, Inc., 1988. [2] J. Yedidia, W. Freeman, and Y. Weiss. Generalized belief propagation. In NIPS 13. [3] A. Yuille. CCCP algorithms to minimize the Bethe and Kikuchi free energies: Convergent alternatives to belief propagation. Neural Computation, July 2002. [4] T. Minka. A family of algorithms for approximate Bayesian inference. PhD thesis, MIT Media Lab, 2001. [5] S.L. Lauritzen and D.J. Spiegelhalter. Local computations with probabilties on graphical structures and their application to expert systems. J. Royal Statistical society B, 50:154­227, 1988. [6] F. Kschischang, B. Frey, and H. Loeliger. Factor graphs and the sum-product algorithm. IEEE Transactions on Information Theory, 47(2):498­519, 2001. [7] W. Wainwright, T. Jaakkola, and S. Willsky. A new class of upper bounds on the log partition function. In UAI-2002, pages 536­543. [8] T. Heskes. Stable fixed points of loopy belief propagation are minima of the Bethe free energy. In NIPS 15. [9] S. Amari, S. Ikeda, and H. Shimokawa. Information geometry of -projection in mean field approximation. In M. Opper and D. Saad, editors, Advanced Mean Field Methods, pages 241­ 258, Cambridge, MA, 2001. MIT press. [10] G. Parisi. Statistical Field Theory. Addison-Wesley, Redwood City, CA, 1988. [11] H.J. Kappen and F.B. Rodr´iguez. Efficient learning in Boltzmann Machines using linear response theory. Neural Computation, 10:1137­1156, 1998. [12] M. Welling and Y.W. Teh. Propagation rules for linear response estimates of joint pairwise probabilities. 2002. Submitted.

 


