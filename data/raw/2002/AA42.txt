Exact MAP Estimates by (Hyper)tree Agreement

Martin J. Wainwright, Department of EECS, UC Berkeley, Berkeley, CA 94720 martinw@eecs.berkeley.edu Tommi S. Jaakkola and Alan S. Willsky, Department of EECS, Massachusetts Institute of Technology, Cambridge, MA, 02139 tommi,willsky @mit.edu

 

¡

Abstract We describe a method for computing provably exact maximum a posteriori (MAP) estimates for a subclass of problems on graphs with cycles. The basic idea is to represent the original problem on the graph with cycles as a convex combination of tree-structured problems. A convexity argument then guarantees that the optimal value of the original problem (i.e., the log probability of the MAP assignment) is upper bounded by the combined optimal values of the tree problems. We prove that this upper bound is met with equality if and only if the tree problems share an optimal configuration in common. An important implication is that any such shared configuration must also be the MAP configuration for the original problem. Next we develop a tree-reweighted max-product algorithm for attempting to find convex combinations of tree-structured problems that share a common optimum. We give necessary and sufficient conditions for a fixed point to yield the exact MAP estimate. An attractive feature of our analysis is that it generalizes naturally to convex combinations of hypertree-structured distributions. 1 Introduction Integer programming problems arise in various fields, including machine learning, statistical physics, communication theory, and error-correcting coding. In many cases, such problems can be formulated in terms of undirected graphical models [e.g., 1], in which the cost function corresponds to a graph-structured probability distribution, and the problem of interest is to find the maximum a posteriori (MAP) configuration. In previous work [2], we have shown how to use convex combinations of tree-structured distributions in order to upper bound the log partition function. In this paper, we apply similar ideas to upper bound the log probability of the MAP configuration. As we show, this upper bound is met with equality whenever there is a configuration that is optimal for all trees, in which case it must also be a MAP configuration for the original problem. The work described here also makes connections with the max-product algorithm [e.g., 3, 4, 5], a well-known method for attempting to compute the MAP configuration, one which is exact for trees but approximate for graphs with cycles. In the context of coding problems, Frey and Koetter [4] developed an attenuated version of max-product, which is guaranteed to find the MAP codeword if it converges. One contribution of this paper is to develop a tree-reweighted max-product algorithm that attempts to find a collection of


tree-structured problems that share a common optimum. This algorithm, though similar to both the standard and attenuated max-product updates [4], differs in key ways. The remainder of this paper is organized as follows. The next two subsections provide background on exponential families and convex combinations. In Section 2, we introduce the basic form of the upper bounds on the log probability of the MAP assignment, and then develop necessary and sufficient conditions for it to tight (i.e., met with equality). In Section 3, we develop tree-reweighted max-product algorithms for attempting to find a convex combination of trees that yields a tight bound. We prove that for positive compatibility functions, the algorithm always has at least one fixed point; moreover, if a key uniqueness condition is satisfied, the configuration specified by a fixed point must be MAP optimal. We also illustrate how the algorithm, like the standard max-productalgorithm [5], can fail if the uniqueness condition is not satisfied. We conclude in Section 4 with pointers to related work, and extensions of the current work. 1.1 Notation and set-up

Consider an undirected (simple) graph random variable taking values in the discrete space

letters

 

@U

. For each vertex

.

 

¥ 

, let be a

¡¡ A7'§98¥BAA.C3¥VW£@

 ¢¡¤£¦¥¨§©!"¡

$#

§&%'§&(&()(0§213546%

to denote particular elements of the sample space

a`be3¡

takes values in the Cartesian product space

.

¡

EDF¡GIHQPSR)R&RTP"

¡

. We use the

D

The overall random vector

, where

We make use of the following exponential representation of a graph-structured

Afcdenotebe gX

 

distribution For some index set , we let

Vh£@pie'¨qsrutdvw5x e £e &

X

potential functions defined on the cliques of

 

, and let

YF¡ Adc 3Xb

 

real-valued weights on these potential functions. The exponential family determined by

is the collection of distributions .

 

In a minimal exponential representation, the functions ¡

$#

example, one minimal representation of a binary process (i.e.,

byaa`bb`bare@I¡affinely§&%independent.

¡

a collection of

a vector of

Y

¡

 

Y¡  A ¥  0 A £§2©

¡

for all ) using



For

pairwise potential functions is the usual Ising model, in which the collection of potentials

X¡¥d©

 

a`b

 

. In this case, the index set is given by ¡ ¡

. In most of our analysis, we use an overcomplete representation, in which

 

there are linear dependencies among the potentials

i

functions as potentials:

`

where the indicator function

case, the index set

edge indices



X!£¦©S¨¡X £¦)i7s8 A £'§2253© £r7'§T8p3pwPxi7s,Aandtu¥zeroi

is equal to one if

 

consists of the union of

 

. ¡

y' E @pi@

l¦ef9m`£n2ef£g§ h¡i2efi£g2ef£g oi¦emi£gX!£¦¥!¡

¡

. In particular, we use indicator

h¡ i2ef £g 0§hj¥u§¨£¦'§2pq© ¡67i

£¦@zp{|

7k3

Of interest to us is the maximum a posteriori configuration

£r7'§98I  P  (1a) (1b)

otherwise. In this

with the

¡

7v!y'x

Equivalently, we can express this MAP configuration as the solution of the integer program



£@pie'h¡ ge§fY"£ 2¡y f e2ef` 2ef'£g)  fm el¦ef9m l¦ef9m£na§2

where

9gy

`

£ge'¨¡sk}t  £ e',

Note that the function

y ¡s}~¨t}t Vh£@pie'.

(2)

£ne'

is the maximum of a collection of linear functions, and hence

is convex [6] as a function of , which is a key property for our subsequent development.



1.2 Convex combinations of trees

Let

ey

be a particular parameter vector for which we are interested in computing

e

this section, we show how to derive upper bounds via the convexity of



. Let

£e'y

. In

denote


a particular spanning tree of For each spanning tree

dimension as set

© £¦©

£¦¤£©e e£n¨e 

 ¢  e£¦ be

  , and let , let ¡ ¡ £n j

denote the set of all spanning trees.

an exponential parameter vector of the same

. To be explicit, if is defined by an edge that respects the structure of

, then



must have zeros in all elements corresponding to edges not in

. However, given an edge

£n¦$.



¥e£n

belonging to two trees

¡ e£nS A,the  corresponding

and quantity

 

 H §¦



©¨e £n H

can be different than For compactness, let ¡ denote the

to full collection, where the notation

spanning tree .

%y 

specifies those subelements of

In order to define a convex combination, we require a probability distribution

 

set of spanning trees -- that is, a vector



For any distribution

$#x £nS¡ %. 

¡

, we define its support, denoted by

5

  ¡ £nu§     A £¦"!

#

&('such

over the

vvQ£)that,



to be the set of trees to which it assigns strictly positive probability. In the sequel, we will also be interested in the probability appears in of edge appearance probabilities, which must belong to the spanning tree polytope [see 2]. A convex combination of exponential parameter vectors is defined via the weighted sum

¡ ¨ A ¥C3©

 

#

 

a spanning tree



that a given edge

¡

¡

chosen randomly under . We let represent a vector

We say that a distribution



(or the vector is valid if

¨87

for every edge

¥j3©

.

$#x

%y 

£nSoe£nt,

which we denote compactly as

28@e£n BA

. Of particular importance are

collections of exponential parameters

¨!¡$063)1~2)¥S343



¥ ©

ey

C £ey D981¡ wB£E£ p$F 98124@£ e£¦BA¡ ey .

for which there exists a convex combination that

es.

is equal to . Accordingly, we define the set valid distribution , it can be seen that there exist pairs



ii y

FC

For any

Example 1 (Single cycle). To illustrate these definitions, consider a binary distribution

VW£@pie¡ r&tsv  HG¦ jFG¦&GH# jFGH)PIu¥PI$. H 4 jF

y

 

(

e¡y

The

 

distribution in the minimal Ising form

%u%d%u%RA,

Q@#d#u#d#; £esy

for all nodes ) defined by a single cycle on 4 nodes. Consider a target

e¡

¡

$# 5w¡ §&%  d¥

¡

otherwise stated, the target distribution is specified by the minimal parameter

where the zeros represent the fact that for all

bc bc

y

ST VW X ST ST

VW VW U a

Y` Y` Y` bc d

Figure 1. A convex combination of four distributions

ning tree

t)v egfihqpsrfutwvyxx

, is used to approximate the target distribution

efihp(rx , each defined by a spanon the single-cycle graph.

 v¡ P A ¡%§)(&(&(&§

 

four possible spanning trees ¡ on a single cycle on four nodes are

 

illustrated in Figure 1. We define a set of associated exponential parameters

 # ## #G##G#

# %F%F%# A %F% A%

¡ e£n 

¡

as follows:

e£ne£n H ¡ @ ¦a ¡ @#

¨I¡ 

Finally, we choose

we have



e£ne£nIHh¡ @

9412@ef£nA¡. ey,

ah¡ @#F#F# % %G%RA  #F#F# #G# # #

% %G%RA

E£  pC £e.

With this uniform distribution over trees,

so that

i y  £n§!¡% § I 

for all

for each edge, and




2 Optimal upper bounds With the set-up of the previous section, the basic form of the upper bounds follows by applying Jensen's inequality [6]. In particular, for any pair

 ¡

upper bound

£ey 94124@ £gef£nBA.

i E£  t C £esy

, we have the

The goal of this section is to examine this bound, and

understand when it is met with equality. In more explicit terms, the upper bound can be

# £n @y £ge£¦2v¡that@y#also£¦SBk}ty'  ne£n 0§fYB£@ 2



written as:



£esy ¡

  

Now suppose that there exists an

each tree

  &'vvh£) .

important implication is that the configuration

(3)

 kD

attains the maximum defining

£ne£n 2

for

In this case, it is clear that the bound (3) is met with equality. An

attains the maximum defining ,

 £ey

so that it is an optimal solution to the original problem.



In fact, as we show below, the converse to this statement also holds. More formally, for any

exponential parameter vector let ¤£ be the collection of configurations that attain the maximum defining , defined as follows:

0¢ "£ne£nt2 ¡ 3 D A ne£n 0§fY"£@§¦ gef£nu§fYB£@ ©¨'~k}0@§¦C£EBD

@

¥£  

e£n ,£ge£¦20¢ B£ne£n 2¡

@

With this notation, the critical property is that the intersection ¢ ¥£ 

¥£ # 0¢ "£ne£n 2

¡

(4)

¡

of configurations optimal for all tree-structured problems is non-empty.

We thus have the following result: Proposition 1 (Tightness of bound). The bound of equation (3) is tight if and only if there



exists a configuration

£ge£¦2. @y

In other words,

£ 

 kD¢ @y

i

0that¤£B£forBBeach

.

 &('vvQ£) 

achieves the maximum defining

Proof. Consider some pair

imum defining

follows:

¡ 

#



# £¦ £gef£nB4 £esy ¡¡ # £n £ne£n 2B46e§fY"£gy 





  &('vvQ£) , 

# £n "! £ge£¦ 4 ne£n 0§fY"£ny@ 2#

e'y

E£  "C £ey y

. Let

@ be a configuration that attains the max-

. We write the difference of the RHS and the LHS of equation (3) as



   

y @

@y @y

and only if achieves the maximum defining

0¢ B£gef£nt2.Therefore,for ¤£

£ge£¦24ugef£nt0§fY"£¦y@ 2

£ge£¦2

Now for each the term is non-negative, and equal

to zero only when belongs to the bound is met with equality if

all trees

Proposition 1 motivates the following strategy: given a spanning tree distribution





 

a collection of exponential parameters

(a) Admissibility: The pair '$

The intersection If (for a fixed



¤£ "$

satisfies

# 0¢ B£geB££¦i

# £noe&$£n5¡ ey. %$F¡x e&$£n 

  &('vvQ£) .

, find

¡

such that the following holds:

(b) Mutual agreement:

of tree-optimal configurations is non-empty.

) we are able to find a collection

achieve the maximum defining





$ satisfying these two proper-

ties, then Proposition 1 guarantees that all configurations in the (non-empty) intersection



¥£ &$

. As discussed above, assuming that

assigns strictly positive probability to every edge in the graph, satisfying the admissibil-

# 0¢ "£ne '£n 2 £ey

ity condition is not difficult. It is the second condition of mutual optimality on all trees that poses the challenge.


3 Mutual agreement via equal max-marginals We now develop an algorithm that attempts to find, for a given spanning tree distribution , is related to the ordinary max-product algorithm [3, 5], but differs in several key ways. While this algorithm can be formulated in terms of reparameterization [e.g., 5], here we present a set of message-passing updates. 3.1 Max-marginals

a collection

'$!¡ e&$£n   

satisfying both of these properties. Interestingly, this algorithm ¡

Vh£The@pie£¦ foundation of our development is the fact [1] that any tree-structured distribution , the corresponding single node max-marginal is defined as follows:

can be factored in terms of its max-marginals. In particular, for each node

a£g& ¡ k}t VW£@ ef£n i

 

¡

£¢¥¤§¦¨¢©¦© ¦

(5)

C3¥

rations

@ w 5¦ a£nuis.

 

with element

 

,

fixed to  

In words, for each is defined analogously as ¦

the maximum probability over the subset of configu-

l£g § ¨¡6k}t  ¦¢ ¦ VW£ e£¦.

For each¡ edge ¢ ¤ ¦ ¢©

 ¦© @ i

, the pairwise max-marginal

¦

With these

£¦'§2253©

definitions, the max-marginal tree factorization [1] is given by:

VW£@pie£nt2 q

y   

a£n&

9gy # a£nu 0£n2    

 

l£n  §  (6)

One interpretation of the ordinary max-product algorithm for trees, as shown in our related work [5], is as computing this alternative representation.

Suppose moreover that for each node

Uniqueness Condition: For each

 

In this case, the vector distribution [see 5].

@ !¡$  $ A C ¥

C3¥j3¥,

, the following uniqueness condition holds:

the max-marginal



has a unique optimum

§$.

¡

is the MAP configuration for the tree-structured

3.2 Tree-reweighted max-product The tree-reweighted max-product method is a message-passing algorithm, with fixed points

 

that specify a collection of tree exponential parameters

Vh£missibility @pie&$

a given tree

share a common set  $

   

¡

'£¦S2condition.£

the subcollection 

The defining feature of %$  is that the associated tree distributions

¡

egfihqpBr!fut4xx#"e"set%$ fihqp'&(x0)

allwith#edge)$ © £¦S 

 

¡ $ AC3¥¡ x l$f Ax£¦'§22p©D £¦is6@

, the distribution

 

 

¡

'£nS

4 6EFCG79H G

$

$

132546798A@ CB 6 6

In particular, for specified compactly by

as follows:

fCB x@ fCB x

6'F 6PI F B

F

fCB6 xF

¡

$§ l$Vh£@piofemax-marginals.

D

@

%$t¡ e&$£¦

satisfying the ad-

$ ,impliesthat $ isalsotheMAPconfigurationfor

¡Vh£@pie"$$£nA ¥@

(7)

where Q is a constant1 independent of . As long as  $ satisfies the Uniqueness Condition, the configuration $ must be the MAP configuration for each treestructured distribution mutual agreement on trees, in conjunction with

2.@This

¡

 



the admissibility of

For each valid

 3,

Vh£@piey

.

@

the requisite set  $ of max-marginals via a sequence of message-passing operations. For

each edge a vector of length

1

£¦'§23©13,, vna£nu

let R

7G!. £g e

be the message passed from node



to node . It is

`

with one element for each state We use

iy

as a

there exists a tree-reweighted max-product algorithm designed to find

We use this notation throughout the paper, where the value of 2 may change from line to line.


shorthand for the messages  

6 6

fCB x

@

x f¡e2efy 2ef£gutof

R

l`

, with the quantity

`

 

iy

¡

specify a set of functions   

¡£¢¥¤§¦©¨ CB



$§similarlyfollows:   defined. We use as ¡ l

1 6 6 6

pr x

$

 4  6

!7  6 G D

fCB x u£g§2¡© elo 

6

© "! (8a)

@

fCB x

6'F 6 I F B

lu£ga§2fie'¨¡srutdv u£g§2ifCBeloQx £n e0Q ea` £gffCB eao 1 # 6'F 6 I F B 4 © 

3

H ` F 6 6 y y

` ©  ©

#

fCB prx

D !7 % 6 G'& F 

 

¨6D'(0) 6©

fCB x

 G © $ "!

iy y iyx D £7  F G'&6 

where 2

  6'F F  F D'(0)

fCB x

F © G





1!

(8b)

For each tree

bution lowing: Lemma 1 (Admissibility). Given any collection

9128@'VV £@piS BA,and

## @pi

£ 



, the subcollection 

05 .

£S

can be used to define a tree-structured distri-

in a manner analogous to equation (7). By expanding the expectation

   

making use of the definitions of

     

and , we can prove the fol-

$ l$

as in equations (8a) and (8b), the convex combination

to  up to an additive constant.

We now need to ensure that  edgewise consistency condition

each tree-distribution

# @pi V £ S

VW£@piesy

§x l#

¡

defined #a@piset

£¦"QVby £ S

of messages  

is equivalent

k}t¡

 

   

¦ ¢

y'§

ll0£na§

¡

are a consistent set of max-marginals for

. It is sufficient [1, 5] to impose, for each edge

  Q  

condition, we update the messages in the following manner:

¦ ¡ a£g&. £¦'§22,

the

In order to enforce this

Algorithm 1 (Tree reweighted max-product).

1. Initialize the messages  76 2. For iterations 9 £@

BADC F 6 (

fCB x1

6 FEHGI¢ P  7Q £R ¢ ¡£¢¥¤TSVU ¨ W 6'F

 

#

R86 with arbitrary positive real numbers.

¡

 

¡ §&%'§§&(&()(w¡,

Using the definitions of

$ l$   and

l

update the messages as follows: $

6'F 6 I F 6 F BYX

fCB pr x fCB pr x

a`b¨ F F F YX dc

D !7 % FCG'& 6 

 A  F

6'FA fCB x

X F ©

D'(0)

fCB x

XF ©©G





 !

e (9)

ing result can be proved:

, as well as the message update equation (9), the follow-

Lemma 2 (Edgewise consistency). Let   $ be a fixed point of the message update equatively. Then the edgewise consistency condition is satisfied. The message update equation (9) is similar to the standard max-product algorithm [3, 5]. in which case equation (9) is precisely equivalent to the ordinary max-product update. so that the updates in equation (9) differ from ordinary max-product in some key ways.

tion (9), and let 

j¡$ $§  l$

    be defined via   $ as in equations (8a) and (8b) respec-

¡

 Indeed, if   is actually a tree, then we must have

l ¡ % for every edge for every edge £¦'§22  © £§2w© , ,

However, if

 

has cycles, then it is impossible to have

l

`

lp¡ %

First of all, the weight appearance probability

ely%

onlthe ! %.

potential function is scaled by the (inverse of the) edge

Secondly, for each neighbor f bg £h , the incoming

3 ¨£g2

message Rpi is scaled by the corresponding edge appearance probability i

lvn  

 %.

¡

Third

of all, in sharp contrast to standard [3] and attenuated [4] max-product updates, the update

of message R message R

-- that is, from to along edge

from to

-- depends on the reverse direction

along the same edge. Despite these differences, the messages

  £¦'§22

can be updated synchronously as in ordinary max-product. It also possible to perform reparameterization updates over spanning trees, analogous to but distinct from those for ordinary max-product [5]. Such tree-based updates can be terminated once the trees agree on a common configuration, which may happen prior to message convergence [7].


3.3 Analysis of fixed points In related work [5], we established the existence of fixed points for the ordinary maxproduct algorithm for positive compatibility functions on an arbitrary graph. The same proof can be adapted to show that the tree-reweighted max-product algorithm also has at least one fixed point   $ . Any such fixed point   $ defines pseudo-max-marginals  $ via equations (8a) and (8b), which (by design of the algorithm) have the following property: Theorem 1 (Exact MAP). If  $ satisfies the Uniqueness Condition, then the configuration

@ $ withelements $ y' ¦ ¢© ©  

£n  ¦

is a MAP configuration for

VW£@piey

.

0¢ B£ge"$'£nS

¤£

£VW£  ¡ $ A C3¥Vh£@pixe $. A £§253© £nS

@pie&$

  ¡}~pk}t

'£¦S2

via equation (7). By Lemma 2, the elements of  $ are edgewise

¡£¦¥¨§©$ £n,

Proof. For each spanning tree

#

distribution

the fixed point  $ defines a tree-structured

consistent. By the equivalence of edgewise and global consistency for trees [1], the subcol-

lection  $

 

£¦2 

 

@

are exact max-marginals for the

 

$ As a consequence, the configuration $ must be-

VW£@piey

, so that admissibility is

¡

tree-structured distribution

long to

98124@hVh£@pi e&$£n@ 2BA

¡

for each tree , so that mutual agreement is satisfied. By Lemma 1,

is equal to 

the convex combination

satisfied. Proposition 1 then implies that $ is a MAP configuration for

Vh£@pie'y

.

3.4 Failures of tree-reweighted max-product In all of our experiments so far, the message updates of equation (9), if suitably relaxed, have always converged.2 Rather than convergence problems, the breakdown of the algorithm appears to stem primarily from failure of the Uniqueness Condition. If this assumption is not satisfied, we are no longer guaranteed that the mutual agreement condition is

@ may be empty). Indeed, a configuration $ belongs to

for every

¦ ¦

satisfied (i.e.,

0¢ "£B'$& ¥£ 0¢ B£E'$) ¤£

if and only if the following conditions hold: Node optimality: The element $ must achieve Edge optimality: The pair must achieve

 £g§$ §2 $ t}tk}t¦¢©¦¨¢©$¦£n¢¦ $

 

For a given fixed point  $ that fails the Uniqueness Condition, it may or may not be possible to satisfy these conditions, as the following example illustrates. Example 2. Consider the single cycle on three vertices, as illustrated in Figure 2. We symmetry of this construction ensures that  $ satisfies the edgewise consistency condition

define a distribution

Vh£@piey

in an indirect manner, by first defining a set of pseudo-max-

marginals  $ in panel (a). Here

  @# §)%RA

is a parameter to be specified. Observe that the

(Lemma 2) for any

v  @# §&%A.

For each of the three spanning trees of this graph, the collec-

tion  $ defines a tree-structured distribution underlying distribution via 

distribution (weight and

In the case

7  (£,

 £2% 

'Vh£@pies5¡y 912@VQV# £@pi A¢¡ £@pi# 

 $ as in equation (7). We define the

$

, where is the uniform



£n §  £¦'§2253©

.

for all

C ¥

.

the other hand, when

@#v#v#A @%v%v%# Aillustrated#

on each tree).

in panel (b), it can be seen that two configurations -- namely -- satisfy the node and edgewise optimality conditions. Therefore,

each of these configurations are global maxima for the cost function

 ¥¤ (¦£

, as illustrated in panel (c), any configuration

impossible, so that the fixed point  $ cannot be used to specify a MAP assignment. Of course, it should be recognized that this example was contrived to break down the algorithm. It should also be noted that, as shown in our related work [5], the standard max-



2 In a relaxed message update, we take an -step towards the new (log) message, where

© © f

I

§$¨§¡ $ £'§22p©

for all

9128@VW£@pi@$ A

$ . On

that is

. This is clearly edgewise optimal for all three edges must satisfy

is the step size parameter. To date, we have not been able to prove that relaxed updates will always converge.

U


@

6 6'F 1 

 ¢¡ ¥£ U

U

(a)

U

@

¡ ¡§¦¡  ¤£

U 1

" # ¨

 !



(b)

!©

'()0()1 $ ()1()032'()0()1% '"()0()1 ()1()042

&

(c)

()1()032

Figure 2. Cases where the Uniqueness Condition fails. (a) Specification of pseudo-maxmarginals & . (b) For , both and are node and edgewise optimal. (c)

For

C79

, no configurations are node and edgewise optimal on the full graph.

U U U

¡BA

¡65

879 @   @

 

product algorithm can also break down when this Uniqueness Condition is not satisfied. 4 Discussion This paper demonstrated the utility of convex combinations of tree-structured distributions in upper bounding the log probability of the MAP configuration. We developed a family of tree-reweighted max-product algorithms for computing optimal upper bounds. In certain cases, the optimal upper bound is met with equality, and hence yields an exact MAP configuration for the original problem on the graph with cycles. An important open question is to characterize the range of problems for which the upper bound is tight. For problems involving a binary-valued random vector, we have isolated a class of problems for which the upper bound is guaranteed to be tight. We have also investigated the Lagrangian dual associated with the upper bound (3). The dual has a natural interpretation as a tree-relaxed linear program, and has been applied to turbo decoding [7]. Finally, the analysis and upper bounds of this paper can be extended in a straightforward manner to hypertrees of of higher width. In this context, hypertree-reweighted forms of generalized max-product updates [see 5] can again be used to find optimal upper bounds, which (when they are tight) again yield exact MAP configurations. References [1] R. G. Cowell, A. P. Dawid, S. L. Lauritzen, and D. J. Spiegelhalter. Probablistic Networks and Expert Systems. Statistics for Engineering and Information Science. Springer-Verlag, 1999. [2] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky. A new class of upper bounds on the log partition function. In Proc. Uncertainty in Artificial Intelligence, volume 18, pages 536­543, August 2002. [3] W. T. Freeman and Y. Weiss. On the optimality of solutions of the max-product belief propagation algorithm in arbitrary graphs. IEEE Trans. Info. Theory, 47:736­744, 2001. [4] B. J. Frey and R. Koetter. Exact inference using the attenuated max-product algorithm. In Advanced mean field methods: Theory and Practice. MIT Press, 2000. [5] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky. Tree consistency and bounds on the maxproduct algorithm and its generalizations. LIDS Tech. report P-2554, MIT; Available online at http://www.eecs.berkeley.edu/ martinw, July 2002.

D

[6] D.P. Bertsekas. Nonlinear programming. Athena Scientific, Belmont, MA, 1995. [7] J. Feldman, M. J. Wainwright, and D. R. Karger. Linear programming-based decoding and its relation to iterative approaches. In Proc. Allerton Conf. Comm. Control and Computing, October 2002.


