Rational Kernels

Corinna Cortes Patrick Haffner Mehryar Mohri

AT&T Labs ­ Research 180 Park Avenue, Florham Park, NJ 07932, USA corinna, haffner, mohri @research.att.com

 

¡

Abstract We introduce a general family of kernels based on weighted transducers or rational relations, rational kernels, that can be used for analysis of variable-length sequences or more generally weighted automata, in applications such as computational biology or speech recognition. We show that rational kernels can be computed efficiently using a general algorithm of composition of weighted transducers and a general single-source shortest-distance algorithm. We also describe several general families of positive definite symmetric rational kernels. These general kernels can be combined with Support Vector Machines to form efficient and powerful techniques for spoken-dialog classification: highly complex kernels become easy to design and implement and lead to substantial improvements in the classification accuracy. We also show that the string kernels considered in applications to computational biology are all specific instances of rational kernels. 1 Introduction In many applications such as speech recognition and computational biology, the objects to study and classify are not just fixed-length vectors, but variable-length sequences, or even large sets of alternative sequences and their probabilities. Consider for example the problem that originally motivated the present work, that of classifying speech recognition outputs in a large spoken-dialog application. For a given speech utterance, the output of a large-vocabulary speech recognition system is a weighted automaton called a word lattice compactly representing the possible sentences and their respective probabilities based on the models used. Such lattices, while containing sometimes just a few thousand transitions, may contain hundreds of millions of paths each labeled with a distinct sentence. The application of discriminant classification algorithms to word lattices, or more generally weighted automata, raises two issues: that of handling variable-length sequences, and that of applying a classifier to a distribution of alternative sequences. We describe a general technique that solves both of these problems. Kernel methods are widely used in statistical learning techniques such as Support Vector Machines (SVMs) [18] due to their computational efficiency in high-dimensional feature spaces. This motivates the introduction and study of kernels for weighted automata. We present a general family of kernels based on weighted transducers or rational relations, rational kernels which apply to weighted automata. We show that rational kernels can be computed efficiently using a general algorithm of composition of weighted transducers and a general single-source shortest-distance algorithm. We also briefly describe some specific rational kernels and their applications to spokendialog classification. These kernels are symmetric and positive definite and can thus be combined with SVMs to form efficient and powerful classifiers. An important benefit of


SEMIRING Boolean Probability Log Tropical

SET

¢¥¤¦£

© 

¡

  ¡

 

© ©&  

 



§ ¨

¢ ¢¢



£ ££

¤'¤  ¡  "!#%$  (0)21 

¡

 ¢¢

Table 1: Semiring examples.  3!#%$ is defined by: 45 6! #%$708 @9BADC¥EGFDHPI  FDHPQSR

.

our approach is its generality and its simplicity: the same efficient algorithm can be used to compute arbitrarily complex rational kernels. This makes highly complex kernels easy to use and helps us achieve substantial improvements in classification accuracy. 2 Weighted automata and transducers In this section, we present the algebraic definitions and notation necessary to introduce

rational kernels. Definition 1 ([7]) A system

EGT EWT

R ¤' U¤ ¢ is a commutative

monoid with identity element ¢ ;

R ¤EWT U¤'¡U¤ ¢V¤R £ is a semiring if:

¤ ¡U¤ £ isamonoidwithidentityelement £ ; ¡ distributes

over   ; and ¢ is an annihilator for ¡ : for all X`Y

T ¤%X0¡ ¢38 ¢a¡bX58 ¢ .

Thus, a semiring is a ring that may lack negation. Table 2 lists some familiar examples of semirings. In addition to the Boolean semiring and the probability semiring used to combine probabilities, two semirings often used in applications are the log semiring which is isomorphic to the probability semiring via a morphism, and the tropical semiring which is derived from the log semiring using the Viterbi approximation.

92AC

Definition 2 A weighted finite-state transducer c over a semiring Efe

¤ gh¤%i0¤%p¥¤%qr¤tsu¤ vw¤tx where: R

e

T

is an 8-tuple cd8

is the finite input alphabet of the transducer; g is the

finite output alphabet; i is a finite set of states; pyi the set of initial states; qyi the

set of final states; sdyi

qv&¥pT to .

T

Ee



 R

 g E

 R T

 T i a finite set of transitions;

   

the initial weight function; and x¥q ¡ ¡ the final weight function mapping

Weighted automata can be formally defined in a similar way by simply omitting the input or the output labels. Given a transition Ys , we denote by F its origin or previous state and dF its destination state or next state, and e3 its weight. A path f8 is an element of s0m to paths by defining the weight of a path as the ¡ -product of the weights of its constituent

F

with consecutive transitions: d

by setting: df 8xd 

Fk

and f 8o . The weight function e can also be extended

FDnFH g 

Fhgjii¦itFlk

8oFSnp , q68srt¤u¦uuv¤%w . We extend d and  to paths Fgt

transitions: e3f 8se3 z {

to and by y

EWz

¤~4¤~7P¤

 F g  ii¦i z

z { R

¡

¡e3F . We denote by y

z z {

k  EGz z|{}R ¤

the set of paths from

the set of paths from to

with input label 4&Y

e

m and output

{ yi , by:

label 7 (transducer case). These definitions can be extended to subsets U¤%

y 5¤t4V¤~7P¤% E

{ R

8 j~Gy

EGz

¤~4¤~7P¤ . z { R

A transducer c is regulated if the output weight associated by c to any pair of input-output string 4¤~7 by: E R

 c 4V¤t7 8

is well-defined and in .  c

E R

E T R

v f ¡e3f ¡xPdf E R  2

(1)

  2¦I Q w

4 8 ¢ when y p¥¤t4V¤~7P¤%q 8x . In the following, we will

E R

assume that all the transducers considered are regulated. Weighted transducers are closed under   , ¡ and Kleene-closure. In particular, the   -sum and ¡ -multiplications of two

transducers c and cw are defined for each pair 4¤~7 by:

g R 8  c g%E

4V¤t7  cP 4V¤~7

R E

g

E E

R 8

IwIlI QvwQvQ%   c

g  c  c 4V¤t7  c ¡c 4V¤t7

E

R g%E g gvR

R

4 ¤t7 ¡c 4¤t7

E R (2) (3)


3 Rational kernels This section introduces rational kernels, presents a general algorithm for computing them efficiently and describes several examples of rational kernels. 3.1 Definition

Definition 3 A kernel Efe

 

is rational if there exist a weighted transducer c

¤ gh¤%i0¤%p¥¤%qr¤tsu¤ vw¤tx over the semiring R

T

and a function

E E

 c 4¤~7

T

R~R

all 4¤~7Y

e

m :

¡  T 8

  E

4V¤t7 8 R

¢¡

 © such that for (4)

¡

In general, is an arbitrary function mapping

to © . In some cases, it may be desirable

to assume that it is a semiring morphism as in Section 3.6. It is often the identity function

when 8o© and may be a projection when the semiring T

another semiring ( 8©

T {

).

is the cross-product of © and

T T

Rational kernels can be naturally extended to kernels over weighted automata. In the following, to simplify the presentation, we will restrict ourselves to the case of acyclic weighted automata which is the case of interest for our applications, but our results apply

T over the semiring , then

similarly to arbitrary weighted automata. Let

  £ ¥¤¤

E R £ ¤

and be two acyclic weighted automata

is defined by:

  £3¤¦¤ §¡ £ E R

8

E

I  Q E R 4 ¡c 4V¤~7 ¡ E R ¤ E RtR 7

(5)

More generally, the results mentioned in the following for strings apply all similarly to acyclic weighted automata. Since the set of weighted transducers over a semiring is also closed under   -sum and ¡ -product [2, 3], it follows that rational kernels over a semiring

T

are closed under sum and product. We denote by

product of two rational kernels

 

g g   ¨ 

g

 the sum and by   © 

g

 the

and ` . Let c and cw be the associated transducers of

 

these kernels, we have for example:

E g    

 4¤~7 8

R¦E R ¡ E E g

T

 c  c  4¤~7 8

RE R~R   g E 4V¤t7  R    4¤~7 E R

(6)

In learning techniques such as those based on SVMs, we are particularly interested in positive definite symmetric kernels, which guarantee the existence of a corresponding reproducing kernel Hilbert space. Not all rational kernels are positive definite symmetric but in the following sections we will describe some general classes of rational kernels that have this property. Positive definite symmetric kernels can be used to construct other families of kernels that also meet these conditions [17]. Polynomial kernels of degree  are formed from

"!

$#&%

R

'  & r

the expression  E

4¤~7 8 R

!

E E~ 

E

 

, and Gaussian kernels can be formed as

7P¤~7

R  E

 

with

4V¤t4 

RX E

 R

4V¤t7 . Since the class of symmetric positive defi-

R

nite kernels is closed under sum [1], the sum of two positive definite rational kernels is also a positive definite rational kernel. In what follows, we will focus on the algorithm for computing rational kernels. The albased on two general algorithms that we briefly present: composition of weighted transto compute the   -sum of the weights of the successful paths of the combined machine. 3.2 Composition of weighted transducers Composition is a fundamental operation on weighted transducers that can be used in many the input alphabet of c  coincides with the output alphabet of c . Then, the composition

E R

gorithm for computing

  E R 4¤~7 , or   £3¤¦¤ , for any two acyclic weighted automata, is

ducers to combine

£

, c , and

¤ T

, and a general shortest-distance algorithm in a semiring

T

applications to create complex weighted transducers from simpler ones. Let

mutative semiring and let c and cw be two weighted transducers defined over g

T

of c and cw is a weighted transducer c g

)(g

g be a comsuch that

c which, whenit is regulated, is definedfor all


a:a/1.61

0

1 b:b/0.22 a:b/0 b:a/0.69 2

b:a/0.69 3/0

a:a/1.2 0

b:b/0.92

a:a/0.51 1 a:b/2.3 b:a/0.51 2/0

(a) a:a/2.81 a:b/3.91 (b)

0

1 4 b:a/0.73 a:a/0.51 a:b/0.92

b:a/1.2 2 3/0

(c) Figure 1: (a) Weighted transducer c over the log semiring. (b) Weighted transducer c  g over the log semiring. (c) Construction of the result of composition c

g (

c  . Initial states

are represented by bold circles, final states by double circles. Inside each circle, the first number indicates the state number, the second, at final states only, the value of the final weight function x at that state. Arrows represent transitions and are labeled with symbols followed by their corresponding weight. 4V¤t7 by [2, 3, 15, 7]:1

 c

g (

c 4V¤t7 8

E R

 c

g%E

4V¤ ¡c ¢

R E

¢ ¤~7

R

¡

e

Note that a transducer can be viewed as a matrix over a countable set

(7) m3 gum and com-

position as the corresponding matrix-multiplication. There exists a general and efficient composition algorithm for weighted transducers which takes advantage of the sparsity of ducers c and cV are identified with pairs of a state of c and a state of cV . Leaving aside transitions with inputs or outputs, the following rule specifies how to compute a transition

the input transducers [14, 12]. States in the composition c g (

g g  c of two weighted trans-

of c g (

EWz g

g c  fromg appropriate transitions of c and c  :2

¤tX¤ ¤~e ¤ 

£ z R EGz { g

and

¤ ¤¥¤ ¤~e  ¤

£ E~EWz g z { R g g EGz z { RtR

g

z { R 

8§¦

z g¤

¤%Xh¤¨¤l¤~e ¡e  ¤  ¤ 

(8)

In the worst case, all transitions of c leaving a state

zl{g



match all those of c leaving state



R~R E~E¨i g

 

 s

g R¦E  ¥

i  



, thus the space and time complexity of composition is quadratic: ©

s  . Fig.(1)(a)-(c)illustratethealgorithmwhenappliedtothetransducersofFig.(1)(a)-

(b) defined over the log semiring. The intersection of two weighted automata is a special case of composition. It corresponds to the case where the input and output label of each transition are identical.

3.3 Single-source shortest distance algorithm over a semiring Given a weighted automaton or transducer  , the shortest-distance from state of final states q is defined as the   -sum of all the paths from to q :

z

! z 8

e3f ¡xPdf 

B



 T}

w

z

to the set (9)

when this sum is well-defined and in

, which is always the case when the semiring is w -

closed or when  is acyclic [11], the case of interest in what follows. There exists a general algorithm for computing the shortest-distance  in linear time © i  c@c s , where c  denotes the maximum time to compute   and c  the time to compute ¡ [11]. The algorithm is a generalization of Lawler's algorithm [8] to the case of an arbitrary semiring . It is based on a generalized relaxation of the outgoing transitions of each state of  visited in reverse topological order [11]. This is a deliberate choice motivated by an improved readability in many applications. for dealing with  -multiplicity in the case of non-idempotent semirings.

 

T

1 We use a matrix notation for the definition of composition as opposed to a functional notation.

2 See [14, 12] for a detailed presentation of the algorithm including the use of a transducer filter

! z E¨ E R R


:b/3 :a/3 b:/2 a:/2 b:a/1 a:b/1 b:b/0 a:a/0 0/0 (a)

b: a: 0 :a :b

:b :a 1 a:a b:b

a:a b:/ :a/

b:b

a:/ 2

:b/

:b/ :a/ 3 a:a b:b

a:a b:b

b: a: 4

:a :b

:b :a 5

(b)

Figure 2: Weighted transducers associated to two rational kernels. (a) Edit-distance kernel. (b) Gappy -gram count kernel, with = 2. 3.4 Algorithm

Let

 

be a rational kernel and let c be the associated weighted transducer. Let

be two acyclic weighted automata.

£ ¤

and

£ ¤

and

m or may represent just two strings 4V¤t7Y

e

   

may be any other complex weighted acceptors. By definition of rational kernels (Eq.(5))

and the shortest-distance (Eq.(9)),

 !

( (

 

. 1. Constructing the acyclic composed transducer

  £

8 c

¤

!

  £3¤¦¤

E R

can be computed by:

2. Computing  , the shortest-distance from the initial states of

¡  



using the shortest-distance algorithm described in the previous section.

E R

£ ¤ ¢¡

    

 £

3. Computing  .

Thus, the total complexity of the algorithm is © c

denote respectively the size of c ,

¡

E R

4 , 4Y . If we assume that

T

¡£

and

¤ ¡

and

E¥ R

, where c ,

   

to its final states

 

, and

¤

the worst case complexity of computing

can be computed in constant time as in many applica-

¤ £ ¤

  £ ¦¤¤ E R

tions, then the complexity of the computation of and .

    

E¥ is: © c R

is quadratic with respect to

£

3.5 Edit-distance kernels Recently, several kernels, string kernels, have been introduced in computational biology for input vectors representing biological sequences [4, 19]. String kernels are specific instances of rational kernels. Fig.(2) (a) shows the weighted transducer over the tropical semiring associated to a classical type of string kernel. The kernel corresponds to an edit-distance based on a symbol substitution with cost £ , deletion with cost r , and insertion of cost semiring [13, 10]. The kernel computation algorithm just described can be used to compute efficiently the edit-distance of two strings or two sets of strings represented by automata. 3

£ . All classical edit-distances can be represented by weighted transducers over the tropical

3.6 Rational kernels of the type c

(

c H

g

There exists a general method for constructing a positive definite and symmetric rational transducer obtained from c by transposing the input and output labels of each transition.

kernel from a weighted transducer c when

T

implies in particular that

  © isg a semiring morphism ­ this

is commutative. Denote by c

H the inverse of c , that is the

(

8c c

H

Then the composed transducer

3

¤ g

is symmetric and, when it is regulated, defines

We have proved and will present elsewhere a series of results related to kernels based on the

¡

T

notion of edit-distance. In particular, we have shown that the classical edit-distance

¦¨§©

¥

with equal

costs for insertion, deletion and substitution is not negative definite [1] and that the Gaussian kernel

is not positive definite.

¥


a positive definite symmetric rational kernel by definition of composition:

 

which shows that

E

4V¤t7 8 R

¡ ¤ E E 

4¤~7 8 R~R

 

. Indeed, since

E E  c 4V¤ ¢

¡ is a semiring morphism,

¡  ¡ ¡

RtRi E E  c 7P¤

¡ ¢ RtR

 

£¢ is¤¢ 

symmetric. For any non-negative integer d and for all 4¤~7 we define by:

E

4V¤~7 8

R

¥ ¦ ¡

¡

¦§ ¢

E E  c 4V¤

¢

RtRi E E

 c 7¤

¡

¢

RtR a symmetric kernel

¢

of length less or equal to d . Let

¢ g

where the sum runs over all strings

define the matrix  by: 

E E n RtR  c 4 ¤ ¢



n

8

  ¢

4 ¤~4 . Then,

  

8



££ £andwith£

any 4 ¤¦u¦uu¦¤t4

defined by

g ¤  ¤¦uu¦uv¤e¢



¢

be an arbitrary ordering of these strings. For any

¡

E n R

. Thus, the eigenvalues of  are all non-negative, which implies that

E     ¢  

,

4V¤t7 8 )2(

R 9

positive definite [1]. Since

 

is a point-wise limit of

¢ "!   ¢

©¨ £Y 4V¤t7

E

n¢ 8m

, is

R

,

is also definite positive [1].

4 Application to spoken-dialog classification Rational kernels can be used in a variety of applications ranging from computational biology to optical character recognition. This section singles out one specific application, that of topic classification applied to the output of a speech recognizer. We will show how the use of weighted transducers rationalizes the design and optimization of kernels. Simple equations and graphs replace complex diagrams and intricate algorithms often used for the definition and analysis of string kernels. As mentioned in the introduction, the output of a speech recognition system associated to a speech utterance is a weighted automaton called a word lattice representing a set of alternative sentences and their respective probabilities based on the models used. Rational kernels help address both the problem of handling variable-length sentences and that of applying a classification algorithm to such distributions of alternatives. The traditional solution to sentence classification is the "bag-of-words" approach used in information retrieval. Because of the very large dimension of the input space, the use of large-margin classifiers such as SVMs [6] and AdaBoost [16] was found to be appropriate in such applications. One approach adopted in various recent studies to measure the topic-similarity of two senitly from each sentence [16] or matched implicitly through a string kernel [9]. We will show that such kernels are rational and will describe how they can be easily constructed and computed using the general algorithms given in the previous section. More generally, we will show how rational kernels can be used to compute the expected counts of common two lattices. This will demonstrate the simplicity, power, and flexibility of our framework

tences consists of counting their common non-contiguous

substrings of words with possible insertions. These

     

-grams, i.e., their common

-grams can be extracted explic-

non-contiguous

  -grams of two weighted automata and thus define the topic-similarity of

for the design of kernels.

4.1 Application of c Consider a word lattice

distribution

an

 

%$y

(

#

c H g

kernels

-gram sequence 4 in a string

 

over the probability semiring.

transducer c

&

I denotes the number of occurrences of 4 in . It is easy to construct a weighted



that outputs the set of

 

-grams of an input lattice with their correspond-

&`Y&

e

for the probability distribution y

&

m . The expected count or number of occurrences of

$ ')(y $ & &

E R

is:



I ,

#

can be viewed as a probability

over all strings

e

where

ing expected counts. Fig.(3) (a) shows that transducer, when the alphabet is reduced to

8 X¤ and

 

¡

£

8r . Similarly, the transducer c

of Fig.(3) (b) can be used to output

non-contiguous or gappy

4

 

-grams with their expected counts. 4 Long gaps are penalized

  r0

The transducers shown in the figures of this section are all defined over the probability semiring,

thus a transition corresponding to a gap in

132546

is weighted by .

7


b: a: 0

a:a b:b 1 a:a b:b

b: a: 2 b: a: 0

a:a b:b

b:/ a:/ 1

a:a b:b

b: a: 2

Figure 3:

counter transducer c . (b) Gappy bigram counter cv .

with a decay factor

counting variable-length ers: c  8 c

§

 0 ' ¢  ¢t 0

§

¡ ¢ £¢£

v

: a gap of length

¤

  (a) -gram transducers (   (b) = 2) defined over the probability semiring. (a) Bigram

0

reduces the count by v . A transducer

¨

-grams is obtained by simply taking the sum of these transduc.

In the remaining of this section, we will omit the subscript

 

and v since our results are

independent of the choice of these parameters. Thus the topic-similarity of two strings or

lattices

¥

and

¦

based on the expected counts of theirs common substrings is given by:

  ¥ ¦ E

¤

R

8 

¥ E

c c

g H R ¦ 

(10)

! ( ( (

  The kernel definite.

is of the type studied in section 3.6 and thus is symmetric and positive

4.2 Computation The specific form of the kernel

 

several alternatives for computing

 

 

and the associativity of composition provide us with .

General algorithm. We can use the general algorithm described in Section 3.4 to compute in the case of gappy bigrams. Using that algorithm, the complexity of the computation of particular example has been treated by ad hoc algorithms with a similar complexity, but that only work with strings [9, 5] and not with weighted automata or lattices. Other factoring. Thanks to the associativity of composition, we can consider a different

by precomputing the transducer c c

H

. Fig.(2)(b) shows the result of that composition

the kernel

  ¥ ¦ E

¤

R E¥

as described in the previous section is quadratic ©

¥ ¦   

R

. This

factoring of the composition cascade defining

  ¥ ¦ E

¤

This factoring suggests computing

R



E

¥

¥ (8

! (  (

: g

Hc

R E H

( c

¦

g

(

¦ R (11)

( g

transducers rather than constructing c

c andH cg

c

(

first and then composing the resulting

. The choice between the two methods does

not affect the overall time complexity of the algorithm, but in practice one method may be preferable over the other. We are showing elsewhere that in the specific case of the counting transducers such as those described in previous sections, the kernel computation can in fact

E¥

be performed in linear time, that is in © failure functions. 4.3 Experimental results

We used the c

(

c

H g

¥     ¦ R

, in particular by using the notion of

-type kernel with SVMs for call-classification in the spoken language

understanding (SLU) component of the AT&T How May I Help You natural dialog system. In this system, users ask questions about their bill or calling plans and the objective is to assign a class to each question out of a finite set of 38 classes made of call-types and named entities such as Billing Services, or Calling Plans. In our experiments, we used 7,449 utterances as our training data and 2,228 utterances as our test data. The feature space corresponding to our lattice kernel is that of all possible trigrams over a vocabulary of 5,405 words. Training required just a few minutes on a single processor of a 1GHz Intel Pentium processor Linux cluster with 2GB of memory and 256 KB cache. The implementation took only about a few hours and was entirely based on


the FSM library. Compared to the standard approach of using trigram counts over the best recognized sentence, our experiments with a trigram rational kernel showed a £¡ £¢ reduction in error rate at a ¢¤¢ rejection level. £

5 Conclusion In our classification experiments in spoken-dialog applications, we found rational kernels to be a very powerful exploration tool for constructing and generalizing highly efficient string and weighted automata kernels. In the design of learning machines such as SVMs, rational kernels give us access to the existing set of efficient and general weighted automata algorithms [13]. Prior knowledge about the task can be crafted into the kernel using graph editing tools or weighted regular expressions, in a way that is often more intuitive and easy to modify than complex matrices or formal algorithms. References

[1] Christian Berg, Jens Peter Reus Christensen, and Paul Ressel. Harmonic Analysis on Semigroups. Springer-Verlag: Berlin-New York, 1984. [2] Jean Berstel. Transductions and Context-Free Languages. Teubner Studienbucher: Stuttgart, 1979. [3] Samuel Eilenberg. Automata, Languages and Machines, volume A-B. Academic Press, 1974. [4] David Haussler. Convolution kernels on discrete structures. Technical Report UCSC-CRL-9910, University of California at Santa Cruz, 1999. [5] Ralf Herbrich. Learning Kernel Classifiers. MIT Press, Cambridge, 2002. [6] Thorsten Joachims. Text categorization with support vector machines: learning with many relevant features. In Proc. of ECML-98. Springer Verlag, 1998. [7] Werner Kuich and Arto Salomaa. Semirings, Automata, Languages. Number 5 in EATCS Monographs on Theoretical Computer Science. Springer-Verlag, Berlin, Germany, 1986. [8] Eugene L. Lawler. Combinatorial Optimization: Networks and Matroids. Holt, Rinehart, and Winston, 1976. [9] Huma Lodhi, John Shawe-Taylor, Nello Cristianini, and Christopher J. C. H. Watkins. Text classification using string kernels. In NIPS, pages 563­569, 2000. [10] Mehryar Mohri. Edit-Distance of Weighted Automata. In Jean-Marc Champarnaud and Denis Maurel, editor, Seventh International Conference, CIAA 2002, volume to appear of Lecture Notes in Computer Science, Tours, France, July 2002. Springer-Verlag, Berlin-NY. [11] Mehryar Mohri. Semiring Frameworks and Algorithms for Shortest-Distance Problems. Journal of Automata, Languages and Combinatorics, 7(3):321­350, 2002. [12] Mehryar Mohri, Fernando C. N. Pereira, and Michael Riley. Weighted automata in text and speech processing. In ECAI-96 Workshop, Budapest, Hungary. ECAI, 1996. [13] Mehryar Mohri, Fernando C. N. Pereira, and Michael Riley. The Design Principles of a Weighted Finite-State Transducer Library. Theoretical Computer Science, 231:17­32, January 2000. http://www.research.att.com/sw/tools/fsm. [14] Fernando C. N. Pereira and Michael D. Riley. Speech recognition by composition of weighted finite automata. In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing, pages 431­453. MIT Press, Cambridge, Massachusetts, 1997.

[15] Arto Salomaa and Matti Soittola. Springer-Verlag: New York, 1978. Automata-Theoretic Aspects of Formal Power Series.

[16] Robert E. Schapire and Yoram Singer. Boostexter: A boosting-based system for text categorization. Machine Learning, 39(2/3):135­168, 2000. [17] Bernhard Scholkopf and Alex Smola. Learning with Kernels. MIT Press: Cambridge, MA, 2002. [18] Vladimir N. Vapnik. Statistical Learning Theory. John Wiley & Sons, New-York, 1998. [19] Chris Watkins. Dynamic alignment kernels. Technical Report CSD-TR-98-11, Royal Holloway, University of London, 1999.


