Margin-Based Algorithms

for Information Filtering

 

Nicolo` Cesa-Bianchi DTI, University of Milan via Bramante 65 26013 Crema, Italy cesa-bianchi@dti.unimi.it Alex Conconi DTI, University of Milan via Bramante 65 26013 Crema, Italy conconi@dti.unimi.it Claudio Gentile CRII, Universit`a dell'Insubria Via Ravasi, 2 21100 Varese, Italy gentile@dsi.unimi.it

Abstract In this work, we study an information filtering model where the relevance labels associated to a sequence of feature vectors are realizations of an unknown probabilistic linear function. Building on the analysis of a restricted version of our model, we derive a general filtering rule based on the margin of a ridge regression estimator. While our rule may observe the label of a vector only by classfying the vector as relevant, experiments on a real-world document filtering problem show that the performance of our rule is close to that of the on-line classifier which is allowed to observe all labels. These empirical results are complemented by a theoretical analysis where we consider a randomized variant of our rule and prove that its expected number of mistakes is never much larger than that of the optimal filtering rule which knows the hidden linear model. 1 Introduction Systems able to filter out unwanted pieces of information are of crucial importance for several applications. Consider a stream of discrete data that are individually labelled as "relevant" or "nonrelevant" according to some fixed relevance criterion; for instance, news about a certain topic, emails that are not spam, or fraud cases from logged data of user behavior. In all of these cases, a filter can be used to drop uninteresting parts of the stream, forwarding to the user only those data which are likely to fulfil the relevance criterion. From this point of view, the filter may be viewed as a simple on-line binary classifier. However, unlike standard on-line pattern classification tasks, where the classifier observes the correct label after each prediction, here the relevance of a data element is known only if the filter decides to forward that data element to the user. This learning protocol with partial feedback is known as adaptive filtering in the Information Retrieval community (see, e.g., [14]). We formalize the filtering problem as follows. Each element of an arbitrary

data sequence is characterized by a feature vector the filtering system observes the -th feature vector

label (say, for relevant and



¨ ¨©¥ ¨©

¡£¢¥¤§¦

and an associated relevance

for nonrelevant). At each time

¡§'

© "!#%$&$%$,

and must decide whether or not to

forward it. If the data is forwarded, then its relevance label

)

¨('

is revealed to the system,

The research was supported by the European Commission under the KerMIT Project No. IST-

2001-25431.


which may use this information to adapt the filtering criterion. If the data is not forwarded,

its relevance label remains hidden. We call

the pair   ¢¡ the

¡ '¡.

'"¨ ' -th

¡ ' 

the -th instance of the data sequence and

example. For simplicity, we assume £ ¤£

¡ '¨ '

¡ is a false negative if

¡§'¨ ©   

for all ¦¥ . There

are two kinds of errors the filtering system can make in judging the relevance of a feature

vector We say that an example   ¡ is a false positive if and

as relevant by the system; similarly, we say that  

¡ '

¨ 'is©¥

classified

and

¡ '¨ ' ' ©¥ ¡ '

is classified as nonrelevant by the system. Although false negatives remain unknown,

the filtering system is scored according to the overall number of wrong relevance judgements it makes. That is, both false positives and false negatives are counted as mistakes. In this paper, we study the filtering problem under the assumption that relevance judgements are generated using an unknown probabilistic linear function. We design filtering rules that maintain a linear hypothesis and use the margin information to decide whether to forward the next instance. Our performance measure is the regret; i.e., the number of wrong judgements made by a filtering rule over and above those made by the rule knowing the probabilistic function used to generate judgements. We show finite-time (nonasymptotical) bounds on the regret that hold for arbitrary sequences of instances. The only other results of this kind we are aware of are those proven in [9] for the apple tasting model. Since in the apple tasting model relevance judgements are chosen adversarially rather than probabilistically, we cannot compare their bounds with ours. We report some preliminary experimental results which might suggest the superiority of our methods as opposed to the general transformations developed within the apple tasting framework. As a matter of fact, these general transformations do not take margin information into account. In Section 2, we introduce our probabilistic relevance model and make some preliminary observations. In Section 3, we consider a restricted version of the model within which we prove a regret bound for a simple filtering rule called SIMPLE-FIL. In Section 4, we generalize this filtering rule and show its good performance on the Reuters Corpus Volume 1. The algorithm employed, which we call RIDGE-FIL, is a linear least squares algorithm inspired by [2]. In that section we also prove, within the unrestricted probabilistic model, a regret bound for the randomized variant P-RIDGE-FIL of the general filtering rule. Both RIDGE-FIL and its randomized variant can be run with kernels [13] and adapted to the case when the unknown linear function drifts with time. 2 Learning model, notational conventions and preliminaries

The relevance of

¡ '

is given by a §

 %

©¨ -valued random variable  (where 

' © 

 

 ¡ ' !' ¢© %

#  ¡%$  & ¤ . The random variables ('

¡ '  ©  "!#%$%$&$ 

"! . Hence

&$%$%$ 

%0) are assumed to be indepen-

¡ '

'¢

¤¦

means "relevant") such that there exists a fixed and unknown vector 

for which      for all

, ££

© ,

is relevant with probability

dent, whereas we do not make any assumption on the way the sequence 1' 32

¡ "¡ %$&$%$ "¡

3) is

generated. In this model, we want to perform almost as well as the algorithm that knows

 and forwards if and only if   4¥5& . We consider linear-threshold filtering al-

gorithms that predict the value of  through SGN 687  @9 BA , where 7 is a dynamically updated weight vector which might be intended as the current approximation to  , and 9 is a suitable time-changing "confidence" threshold. For any fixed sequence

denote the margin 7 

¡ "¡ &$%$%$ "¡ ¢ ¤'¦¡

' 32 3)

'

' ' ¡ '  '

to denote the margin  

' ¢ ¤ ¦ ¡ ' '

¡ ' ¡ '

 ''of. ' ' ' ( ' '

instances, we use C

We define the expected regret of the linear-threshold filtering al-

 '

gorithm at time as EF 8   CD G9 ¡ HI&P¡ QEF R C HI&S¡ . We observe that in the conditional

EUT -probability space where CD V9 is given we have

©© E T  R   CD  YE T  R   CD  YE T  R C

''' ''' '' ' '' ''

V9 ¡¦HW&P¡ VE T  8 C @9 ¡1HX&P¡ @E T  R C

¥W&P¡ VE T  R C

'

HX&S¡ HI&P¡"¡`§S  CD

HI&S¡"¡c§d  CD

'  ' ' © ' '  ' ' 

e9 ¡fC ¦a &g¨ ih C h§S  CD V9 ¡"C a &b¨

'

and CD to

'  ' ' V9 ¡"C ¦a &b¨


where we use ¡ § ¨ to denote the Bernoulli random variable which is 1 if and only if predicate   is true. Integrating over all possible values of CD V9 we obtain

EF 8   CD

' '  '  ' '

@9 ¡¦HI&S¡ @E¦ R C HI&S¡

'  ' © '' '  ' '

a

h C h C h¢EF "  CD h¢EF fh CD

a

¢£¥¤¦¢¨§ '

   CD

V9 ¡"C ¦a &S¡

''  ''  '' '

V9 eC hd¥ h C

@9 C ¡  2



(1)

h ¡

(2)

where the last inequality is Markov's. These (in)equalities will be used in Sections 3 and 4.2 for the analysis of SIMPLE-FIL and P-RIDGE-FIL algorithms. 3 A simplified model We start by analyzing a restricted model where each data element has the same unknown probability © of being relevant and we want to perform almost as well as the filtering rule wards otherwise). The analysis of this model is used in Section 4 to guide the design of good filtering rules for the unrestricted model.

that consistently does the optimal action (i.e., always forwards if ©X¥

 ! $ and never for-

Let 

©©   !

$ and let D

¦ ¦

¤

©D

©   !

¤ $ be the sample average of  , where 

'

is

the number of forwarded data elements in the first

true positives among the

'

 time steps and ©D

¦

¤

is the fraction of

rule forwards if and only if  ¥& . Consider instead the empirical rule that forwards if

and only if D

¦

¤





a gh a



¥ & . This rule makes a mistake only when 3D

¤

& . To make

h gh  ¡ the probability of this event go to zero with , it suffices that E¦ fh D

as "! , which can only happen if 

 '

¦¦

¤

elements that have been forwarded. Obviously, the optimal

increases quickly enough with . Hence, data

level for D

deviation bounds require 

¦

¤

gets too small with respect to . A problem in this argument is that large

  % ¡ for making EF %h D $

2

¦ ¤

gh'& h gh ¡ small. But in



¦

¤

should be forwarded (irrespective to the sign of the estimate D ) also when the confidence

' ©$# 

2

our case  is unknown. To fix this, we use the condition 

dangerous, as we use the empirical value of D

¦

¤

'©(# 

  $ D

itself; however, we will show that this approach indeed works. An algorithm, which we call SIMPLE-FIL, implementing the above line of reasoning takes the form of the following expected regret at time of SIMPLE-FIL is defined as the probability that SIMPLE-FIL makes  ' %' © 0)  '76

simple rule: forward if and only if D

¦ ¤ 9 ¥ & , where 9 10 243 "¡%$5 ' . The



' minus § ' (!  ! A1

a mistake at time the probability that the optimal filtering rule makes a mistake,

that is E¦ R   D on this regret.

¦ ¤

9 ¡H &P¡ EF 8  H &S¡ . The next result shows a logarithmic bound

Theorem 1 The expected cumulative regret of SIMPLE-FIL after any number !@¥ steps is at most 8  P$gh gh ©¡92@31! .



'

to control the large deviations of D

¦

2 ¤

¡ . This looks

¦

¤

 of time

Proof sketch. We can bound the actual regret after ! time steps as follows. From (1) and the definition of the filtering rule we have

B

'  '  EF 8  RD

B )

¦ ¤ V9 ¡¦HI&S¡

'

1T243

$¦

2



RQS 76 ' a E



' D ¤VU

' §© ! E¦ R GHX&S¡

B )

RQ3D E

¦ ¤D

 '¦

V9 ¡



¤VUSX

) ) )

'DC B

B

0h gh FE  RD E

¦ ¤D a HG & '

!

a

© !

0h ghPI

'DC

'DC ' 'DC '

 'DC

'

 a & W 76 ' &

# '

1T2@3

¦

2 D

0h gh     YT`¦ ¡ e aY¥b  ¡ 


Without loss of generality, assume ! &

Since   ¥ Y ` £¢ ¡

'76

' a 10 243 "¡%$ D



¡

¦

2 ¤

¤

for some

¡ a 

¥ . Hence we can write



Q  76 ' a

'76

'



'

1T2@3

.

We now bound aY `¦ and   YTb  separately.

' © '76 ¥,

 '

¡

we have that YT` ¥

B ) B

'76 '

implies



implies that 

¡

1T243 D

B )

a

¡ 

'DC 'DC

¦¥¨§

B

)

' D

'

¦¥2@3

2 ¤

 2

W '76 ' ¥ U a ¡ 

'DC

¦¥¨§ ¢ ¦¥C  '

©¤Q a ¢2 U

B

¦¥¨§ ¢ ¦¥C ¦¥¨§ ¢ ¦¥C ¦¥¨§ ¢ ¦¥C

B ) B

'76 '

'DC 'DC '

B ) B

'76 '

'

¤ a

a

¡ 

a

¡ 

E h D h a h gh $ G ¢ !

ghb¥ h gh $ G E h D ¢ 

 ! $

E h D h a h gh $ WG

¡

¢ !

for ¥   ¥243 ! ¡%$ 

 2  

Applying Chernoff-Hoeffding [11] bounds to D , which is a sum of

independent random variables, we obtain

¡ '76

3aY¥`¦ a

! 'DC ) ¦¥¨§ ¢ ¦¥C #" ¢ ' ' E Ph D 

¢ ¤ ( !#% ! $

 ! $

$ d¨ -valued

)

§

ghb¥ h gh $

!%$ a '

'&)(0132

We now bound   YTb  by adapting a technique from [8]. Let

8

B1'2(0C

¢

 ' © DD ¢A6 BE

' 6 )

'DC

CGFBE C¨F¤

¤

$We

¦ ¤

have



' 45¢76 98 1(02 4@¢A6 ¢ D

' ©

DD ¦

'  ' ©

B

Y¥b a E h D

B )

'

ghb¥

¤D



6¥

ghd¥

!4 6 ¤

¦

'  h gh G B )

!

'DC'

B76 ' C

Q

DD

E h D

'

¦ ' &

1T2@3

¦ 'DC

2 D

B ) '

a

UTY

'DC

¢UVYSR

¢ !4 ¢A6 '  h gh G B

©  $

'DC IH' 4 6 ¤ ¦ ' ¥ ¤D 6 'QP

 '  W '76

¤VU

Q

DD )

'

¦ ¤ 6F¥

a

'   '76  ' &

1T2@3

¦

2



D ¤ U

Applying Chernoff-Hoeffding bounds again, we get  aY

Finally, one can easily verify that Y result. XV

© WT1

& . Piecing everything together we get the desired

Y

! 'DC ' !   $

) '

'

a g  2@31! ¡

4 Linear least squares filtering In order to generalize SIMPLE-FIL to the original (unrestricted) learning model described in Section 2, we need a low-variance estimate of the target vector  . Let whose columns are the forwarded feature vectors after the first



` '

be the matrix

time steps and let

d`e` 'f7`e``

i`e` 'f¡



ba c`

©

  holds. Consider the least squares estimator  



a

'

be the vector of corresponding observed relevance labels (the index will be momentarily

dropped). Note that 

of  , where  

© $To

is the pseudo-inverse of

`h`

d`e` 3fg`ha

 ¡

 . For all  belonging to the column

space of , this is an unbiased estimator of  , that is 

   ¡

u



qpf d`h` 3fg`rats i`e` 'f7`¡ ba

 ¡

`h`

©

i   G

©

 remove the assumption on  , we make  full rank by adding

the identity . This also allows us to replace the pseudo-inverse with the standard inverse,


1

RIDGE-FULL RIDGE-FIL FREQUENCY x 10

0.8

0.6

F-MEASURE

0.4

0.2

0

34 CATEGORIES

Figure 1:   -measure for each one of the 34 filtering tasks. The   -measure is defined by ¡£¢¥¤§¦©¨¢ ¤ , where ¤ is precision (fraction of relevant documents among the forwarded ones) and ¢ is recall (fraction of forwarded documents among the relevant ones). In the plot, the filtering rule RIDGE-FIL is compared with RIDGE-FULL which sees the correct label after each classification. While precision and recall of RIDGE-FULL are balanced, RIDGE-FIL's recall is higher than precision due to the need of forwarding more documents than believed relevant. This in order to make the confidence of the estimator converge to 1 fast enough. Note that, in some cases, this imbalance causes RIDGE-FIL to achieve a slightly better   -measure than RIDGE-FULL.

obtaining

du  `h` 

 ¡ 6 '

`ha

, a "sparse" version of the ridge regression estimator [12] (the

sparsity is due to the fact that we only store in

`

the forwarded instances, i.e., those for

which we have a relevance labels). To estimate directly the margin 1 , rather than  , we further modify, along the lines of the techniques analyzed in [3, 6, 15], the sparse ridge

regression estimator. More precisely, we estimate   the 7 is defined by

7

'

Using the Sherman-Morrison¤D

#pR7 is

` '76

 ' . Let 

¥ ¤ ¥

§%

'76



' ¡ ' © 

'

¡6¤

  $

¡ '

with the quantity 7 

' ¡ ',

where

' © !` '76 '76  ¡ ' ¡ ' '76 '76 $

6 '

 

u

'

`

 '  ¡

` a ' '

§!¤D

¡

¡§

' be the number of forwarded instances among ¦'

formula,we¤ can then write out the expectation of 7 

¤ " ¤#"



¡

¤



which holds for all  ,

¡ &$%$&$¡ ¡','76

and all matrices

' . In order to

¡ ' ¡ '(3)as

generalize to the estimator (3) the analysis of SIMPLE-FIL, we need to find a large deviation bound of the form EV6fh 7  eC h  76 ' A '&b  ¡ for all & & , where &b  ¡ goes to zero "sufficiently fast" as R ! . Though we have not been able to find such bounds, we report some experimental results showing that algorithms based on (3) and inspired by the analysis of SIMPLE-FIL do exhibit a good empirical behavior on real-world data. Moreover, in Section 4.2 we prove a bound (not based on the analysis of SIMPLE-FIL) on the expected regret of a randomized variant of the algorithm used in the experiments. For this variant we are able to prove a regret bound that scales essentially with the square root of ! (to be contrasted with the logarithmic regret of SIMPLE-FIL). 4.1 Experimental results

' ' ©¥0)  '76 $

We ran our experiments using the filtering rule that forwards

where 7 is the estimator (3) and 9 )(  ¥243 "¡%$5

¡ '

if SGN Y7 

' ¡ '  ' © ,

V9 ¡

' ¡ '  '¤9&  ' ©c¤ ©   D D 

' Note that this rule, which we call

RIDGE-FIL, is a natural generalization of SIMPLE-FIL to the unrestricted learning model; in particular, SIMPLE-FIL uses a relevance threshold 9 of the very same form as RIDGE-FIL, although SIMPLE-FIL's "margin" D is defined differently. We tested our algorithm on a

&'


Algorithm: P-RIDGE-FIL.

Parameters: Real

Initialization: 7 ' i R& Loop for

1. Get

'¢ ¤ ¦

§©¥¡' "!#%$%$&$©

4

&X& ; © e &

%$%$&$¢   ©

 .

f&S¡ , '

and let CD W7 

#%

4)u#` ¢¡ £ ' , © © .

¨ '

;

and update as follows: 2. If CD ¥W& then forward

7 7   ' 

that h h 7

££¤ 

' i 

§

¦¥¤` © ¤  ¨ '  '6§  ¤6 ¡ ';

'§©¡ §¡¤ '.

',

'

get label

¤¤§§ © ` ¤ ¡ '©¨  ¤u§ ©  `¤ ¤ § ` ¤

©   ¤§© ,



'

¡ '

' h h

.

CD ¡ ' d¡

'

§ ¥¤' '`7

otherwise;

 §

'

7 , where

 © & if h h 7 Qh h a ¥¤   and &W& is such

3. Else forward with probability © . If

¡ '

was forwarded then get label

¨ ' and do

the same updates as in 2; otherwise, do not make any update.

Figure 2: Pseudo-code for the filtering algorithm P-RIDGE-FIL. The performance of this algorithm is analyzed in Theorem 3. document filtering problem based on the first 70000 newswire stories from the Reuters Corpus Volume 1. We selected the 34 Reuters topics whose frequency in the set of 70000 documents was between 1% and 5% (a plausible range for filtering applications). For each topic, we defined a filtering task whose relevance judgements were assigned based on whether the document was labelled with that topic or not. Documents were mapped to real vectors using the bag-of-words representation. In particular, after tokenization we lemmatized the tokens using a general-purpose finite-state morphological English analyzer and then removed stopwords (we also replaced all digits with a single special character). Document vectors were built removing all words which did not occur at least three times in the word frequency in the document, DF is the number of documents containing the word,

the corpus and using the TF-IDF encoding in the form  

  243 TF92@3U   $ DF¡ , where TF is ¡

and  is the total number of documents (if TF

©

& the TF-IDF coefficient was also set to

& ). Finally, all document vectors were normalized to length 1. To measure how the choice

of the threshold 9 affects the filtering performance, we ran RIDGE-FIL with 9 set to zero on the same dataset as a standard on-line binary classifier (i.e., receiving the correct label after every classification). We call this algorithm RIDGE-FULL. Figure 1 illustrates the

experimental results. The average

tively, &

#$  #$"!



-measure of RIDGE-FULL and RIDGE-FIL are, respec-

and & ( ; hence the threshold compensates pretty well the partial feedback in

' '

the filtering setup. On the other hand, the standard Perceptron achieves here a

of &

#$#



-measure

in the classification task, hence inferior to that of RIDGE-FULL. Finally, we also

tested the apple-tasting filtering rule (see [9, STAP transformation]) based on the binary classifier RIDGE-FULL. This transformation, which does not take into consideration the margin, exhibited a poor performance and we did not include it in the plot.

4.2 Probabilistic ridge filtering In this section we introduce a probabilistic filtering algorithm, derived from the (on-line) ridge regression algorithm, for the class of linear probabilistic relevance functions. The

algorithm, called P-RIDGE-FIL, is sketched in Figure 2. The algorithm takes

probability value © as input parameters and maintains a linear hypothesis 7 . If 7 

& , then is forwarded and 7

4

& & and a

¥

¡ ' ¤

¤ ¤ ¡ '

gets updated according to the following two-steps ridge

regression-like rule. First, the intermediate vector 7

¥¤

is computed via the standard on-line

ridge regression algorithm using the inverse of matrix

is obtained by projecting 7

#¥¤

  ¤

. Then, the new vector 7

¤ §

'

onto the unit ball, where the projection is taken w.r.t. the


distance function  

7 ' 7

¤¤ §is © ¦¥¤

¤ §  ©    ¤ § 

'© Y f7 ¡ 2'  R @7 ¡ 

7 updated) with some probability © . The analysis of P-RIDGE-FIL is inspired by the

¤ ¡ '

'© Y @7 ¡ . Note that h h 7 Gh h a

H & then

¡ '

#¥¤ 

implies

. On the other hand, if 7  is forwarded (and consequently

analysis in [1] for a related but different problem, and is based on relating the expected regret in a given trial to a measure of the progress of 7 towards  . The following lemma

will be useful.



Lemma 2 Using the notation of Figure 2, let

curs. Then the following inequality holds:

  

 Y "7  Y "7 ¡  §©    ¤  ¡

2' '  Y f7  R @74¡ 

¤¤  ¤ ¥  ¤ §  ¤ §  

2'

  CD

' 'be'thetrial '  ' !V2@3

X ¡ 2 2'

when the -th update oc-

¢` ¢

X ¡ 2 a ¢¡¤£¢¡ ¢` ¢

 

£

 8C



' ¡ , where h Gh denotes the determinant of matrix

 Y V7 ¡ .

and

¦Proof

£

sketch. From Lemma 4.2 and Theorem 4.6 in [3]¢ ` and¢ the fact that h CD h a h' h 7 R h h a ' ¡¤£ ¢

¤ §  ©

 ¡

'  Y f7 ¡

2

¢ ¤ ¦

 ¡

 R

'  '  '  ' !V2@3  §  ¤  ¤ ¨  ¤§  ¥¤

2'   C 2 a

` ¡ '  Y

 Y f7 ¡ f7

2'

7 ¡ 

¤¢§ 

¤ ¤ 

¡ . it follows that   CD

2

Now, the function  

gence (e.g., [4, 10]), and it can be easily shown that 7

tion of 7  

3

onto the convex set ©§

©"!$#&%(' © ¢a¢ ¢a¢ )

'

  § 0©  '

¤ ¦¥¤

"7

 ©h

h h h a

¦¥¤

e.g., the appendix in [10]) it follows that  

¡ . By a projection property of Bregman divergences (see,

'  R f7 ¡G¥

1  §

'P R "7 ' ¡ for all  such

Y

¤ § 

74¡ is a Bregman diver' in Figure 2 is the projec-

¨ w.r.t.

  § ; i.e.,

'

¤

7

¤ § ©

'



¤ § ¦¥¤ ¤  ¤ §

,

that h h  h h a . Putting together gives the desired inequality.

Theorem 3 Let 2

)

© ' '#©© ' ¡ '3

 

3 h C h  

' '

3 h  

)  

)

 

h . For all ! &

'

)

of Figure 2 is run with1 ©

' EF 8 CD HI&P¡

!%4   3

4 )

¡ , then its expected cumulative regret

if algorithm P-RIDGE-FIL

'DC ' '  'DC ' '3

2

'

EF 8 C

3

HW&P¡ is at most

4  2@3 ) 6

   $ E )

¦

5 A '

2 ! ' 2

variables 6

in trial



 £

Proof sketch. If

we set 6

the regret of the update rule 7

   can be lower bounded via Lemma 2. If CD

6

Lemma 2 only with probability © , while for the regret we can only use the trivial bound

 

A

 a With probability

, instead,  A 

 T  and  

A 6

 & . Let

B be a

constant to be specified. We can write 2c A CB 6 D20 A



'  ' © ' ' CB ' '    

'' .

'©7  ¤'©@9 ¤ 8 ¤¤§ '¤§ ¤§

is the trial when the -th forward takes place, we define the random ¢

' ©

¡

¢`

'© '

'

 Y "7 '  Y f7 ' ¡ and

& . Let

9

¢¡¤£¢¡ ¢` ¢

. If no update occurs

A be the regret of

'

' in trial

P-RIDGE-FIL in trial

'

¥i& , then  

A

and A T be

 T  and

A

' © !V2@3

7

. '

If CD

H & , then 3 

' © '

6 gets lower boundedvia

' ©  R©

C2 ' ' #EB ' ' $ A

13

6

§ CD HW&b¨ 

 c3

§ CD

¥X&g¨  § CD HW&b¨ 

  6 § CD ¥I&b¨ 

(4)

' 

Now, it is easy to verify that in the conditional space where CD is given we have 3  8C

 B¡

2

h CD  C

2

 "¡

2

h CD    CD C ¢¡

2

C

2

and    CD

' ' ©   ' '  ' ' © '  '  '  '.

Thus, using Lemma

2 and Eq. (4) we can write

2c3A CB 6   

'  ' ©F2 ' ' #CB

   T §cDC

A

"S 

1      CD '2

¥I&g¨  ¡  T § CD

      CD '2

'  '  ' ' ' eC ¡ @ 2

E2EBT©  © ' ' (  ' A

HI&g¨  ©g  § CD

'  '  ' ' '

C ¡ @  2 9 hRDC Y¡§cDC

9 hRDC Y¡§cDC ¥X&g¨ 

HX&g¨  HI&g¨ 

$

1

This parametrization requires the knowledge of G . It turns out one can remove this assumption

at the cost of a slightly more involved proof.


This can be further upper bounded by

    CD



eC 2 ¡      CD '2 C

B

'  '' CB

' ' (

'  ' ' #CB¥© 2 ¡ §cDC ¥I&g¨  1   ¤DC '2

' ' ' (C2© ' 

'  ' '

C 1  § CD 2 ¡ §0DC

HW&b¨ 

    Sh CD 8§ CD ¥W&b¨ 

9 B¥©

3   Ph CD 8 § CD FHI&g¨ 

9

terms   AT § CD HI&g¨  and  AT2 § CD ¥W&b¨  into  AT2  . In turn, this term has been& bounded point we work in the conditional space where CD is given and distinguish the two cases

as   AT  a

'

¢£ ¤ ¢ § '    CD

'  ' C ¡  a ' §   CD '  ' C

¡  by virtue of (2) with 9

' © . At this

§© '  ' '  EB !  ' '  CB !  ' ' 

¥W& and CD HI& . In the first case we have

  (©¡ I   CD C ¡ hRDC 2 B  $ P¡

B%© DB ©g 9

¡

Bg39

 ©h CD 8

hRDC  a 10  $ ©¡

Bb9

hRDC 

a 1c 

5 2'

B ©c¡ B ©g 9  ©h CD 

§© %$%$&$E 

2@3 6 )

CD

' '

'

' '4

 

HI&g¨  (5)

where in the inequality we have dropped © from factor  

' ' '

©c¡ and combined the resulting

whereas in the second case we have

)(  P¡ W    CD eC "¡ h CD B  2

2'

§© '  ' '    ' '#E29©© ¢`¢` ! ' ' C2¦ 

where in both cases we used   CD QC ¢¡ a 1 . We) set B 1 ! and sum over ¢

Notice that

'DC '

)

' 6

E

a a ¥ ¡ 2 h h  h h 2

and that

'DC ' !

' 9 a V243

£ ¢

'© 'E

2

9© "! . A

(e.g., [3], proof of Theorem 4.6 therein). After a few overapproximations (and taking the worst between the two cases CD ¥I& and CD HI& ) we obtain

'DC ' !%4  

)

' 2c A 

5

 a !

thereby concluding the proof. References

5 4 5

2

4

! $243 6

    E

)

¦ A ! 2 Y

' '

[1] Abe, N., and Long, P.M. (1999). Associative reinforcement learning using linear probabilistic concepts. In Proc. ICML'99, Morgan Kaufmann. [2] Auer, P. (2000). Using Upper Confidence Bounds for Online Learning. In Proc. FOCS'00, IEEE, pages 270­279. [3] Azoury, K., and Warmuth, M.K. (2001). Relative loss bounds for on-line density estimation with the exponential family of distributions, Machine Learning, 43:211­246. [4] Censor, Y., and Lent, A. (1981). An iterative row-action method for interval convex programming. Journal of Optimization Theory and Applications, 34(3), 321­353. [5] Cesa-Bianchi, N. (1999). Analysis of two gradient-based algorithms for on-line regression. Journal of Computer and System Sciences, 59(3):392­411. [6] Cesa-Bianchi, N., Conconi, A., and Gentile, C. (2002). A second-order Perceptron algorithm. In Proc. COLT'02, pages 121­137. LNAI 2375, Springer. [7] Cesa-Bianchi, N., Long, P.M., and Warmuth, M.K. (1996). Worst-case quadratic loss bounds for prediction using linear functions and gradient descent. IEEE Trans. NN, 7(3):604­619. [8] Gavald`a, R., and Watanabe, O. (2001). Sequential sampling algorithms: Unified analysis and lower bounds. In Proc. SAGA'01, pages 173­187. LNCS 2264, Springer. [9] Helmbold, D.P., Littlestone, N., and Long, P.M. (2000). Apple tasting. Information and Computation, 161(2):85­139. [10] Herbster, M. and Warmuth, M.K. (1998). Tracking the best regressor, in Proc. COLT'98, ACM, pages 24­31. [11] Hoeffding, W. (1963). Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58:13­30. [12] Hoerl, A., and Kennard, R. (1970). Ridge regression: biased estimation for nonorthogonal problems. Technometrics, 12:55­67. [13] Vapnik, V. (1998). Statistical learning theory. New York: J. Wiley & Sons. [14] Voorhees, E., Harman, D. (2001). The tenth Text REtrieval Conference. TR 500-250, NIST. [15] Vovk, V. (2001). Competitive on-line statistics. International Statistical Review, 69:213­248.


