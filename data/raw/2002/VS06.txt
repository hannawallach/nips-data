A Bilinear Model for Sparse Coding

David B. Grimes and Rajesh P. N. Rao Department of Computer Science and Engineering University of Washington Seattle, WA 98195-2350, U.S.A. grimes,rao @cs.washington.edu

 

¡

Abstract Recent algorithms for sparse coding and independent component analysis (ICA) have demonstrated how localized features can be learned from natural images. However, these approaches do not take image transformations into account. As a result, they produce image codes that are redundant because the same feature is learned at multiple locations. We describe an algorithm for sparse coding based on a bilinear generative model of images. By explicitly modeling the interaction between image features and their transformations, the bilinear approach helps reduce redundancy in the image code and provides a basis for transformationinvariant vision. We present results demonstrating bilinear sparse coding of natural images. We also explore an extension of the model that can capture spatial relationships between the independent features of an object, thereby providing a new framework for parts-based object recognition.

1 Introduction Algorithms for redundancy reduction and efficient coding have been the subject of considerable attention in recent years [6, 3, 4, 7, 9, 5, 11]. Although the basic ideas can be traced to the early work of Attneave [1] and Barlow [2], recent techniques such as independent component analysis (ICA) and sparse coding have helped formalize these ideas and have demonstrated the feasibility of efficient coding through redundancy reduction. These techniques produce an efficient code by attempting to minimize the dependencies between elements of the code by using appropriate constraints. One of the most successful applications of ICA and sparse coding has been in the area of image coding. Olshausen and Field showed that sparse coding of natural images produces localized, oriented basis filters that resemble the receptive fields of simple cells in primary visual cortex [6, 7]. Bell and Sejnowski obtained similar results using their algorithm for ICA [3]. However, these approaches do not take image transformations into account. As a result, the same oriented feature is often learned at different locations, yielding a redundant code. Moreover, the presence of the same feature at multiple locations prevents more complex features from being learned and leads to a combinatorial explosion when one attempts to scale the approach to large image patches or hierarchical networks. In this paper, we propose an approach to sparse coding that explicitly models the interac-


tion between image features and their transformations. A bilinear generative model is used to learn both the independent features in an image as well as their transformations. Our approach extends Tenenbaum and Freeman's work on bilinear models for learning content and style [12] by casting the problem within probabilistic sparse coding framework. Thus, whereas prior work on bilinear models used global decomposition methods such as SVD, the approach presented here emphasizes the extraction of local features by removing higher-order redundancies through sparseness constraints. We show that for natural images, this approach produces localized, oriented filters that can be translated by different amounts to account for image features at arbitrary locations. Our results demonstrate how an image can be factored into a set of basic local features and their transformations, providing a basis for transformation-invariant vision. We conclude by discussing how the approach can be extended to allow parts-based object recognition, wherein an object is modeled as a collection of local features (or "parts") and their relative transformations. 2 Bilinear Generative Models We begin by considering the standard linear generative model used in algorithms for ICA

and sparse coding [3, 7, 9]:

¥

where and

 ¢¡

¤¥£ ¥¥

¦¨§¨©

is a -dimensional input vector (e.g. an image),

¥  

 ¥  ¥ ©

(1) is a -dimensional basis vector



is its scalar coefficient. Given the linear generative model above, the goal of ICA is

 ¥

to learn the basis vectors

©

such that the are as independent as possible, while the goal

in sparse coding is to make the distribution of

 ¥ ¥

highly kurtotic given Equation 1.

The linear generative model in Equation 1 can be extended to the bilinear case by using

two independent sets of coefficients and

 ¥  ¢¡  "!#%$ ¡



¤¥£(or¤

equivalently, two vectors

'

¥  ¥ ( (





and ) [12]:





( ¦&§)¥ ¦&§ © ( ¥

The coefficients

vector . For the present study, the coefficient

of object feature in the image while the

0 

 

and jointly modulate a set of basis vectors

(

©

( (2) to produce an input

can be regarded as encoding the presence

values determine the transformation present in

the image. In the terminology of Tenenbaum and Freeman [12],

of the image while



encodes its "style."

Equation 2 can also be expressed as a linear equation in

¥

 1¡%¨$32 ¡

'

45 ¤¥£ ¤



describes the "content"

¦&§ ¦&§6© (

 ¥ ( (879 ¡  for a fixed : ¤¥£

¥  ¥ ¦&§)©A@

(3)

Likewise, for a fixed , one obtains a linear equation in . Indeed this is the definition of bilinear: given one fixed factor, the model is linear with respect to the other factor. The power of bilinear models stems from the rich non-linear interactions that can be represented

by varying both



and



simultaneously.

 

3 Learning Sparse Bilinear Models 3.1 Learning Bilinear Models Our goal is to learn from image data an appropriate set of basis vectors describe the interactions between the feature vector

¥

and the transformation vector

©

( that effectively



.




A commonly used approach in unsupervised learning is to minimize the sum of squared

pixel-wise errors over all images:

 

¡   ¡  

¡¢¡ ¤£

¤£

¥ § !# ! &$ © ( ¤¥£ ¤

¤¥£¦&§ ¤

'

('¦&§ ©

¥  ¥ ( (



¥  ¥

¡¢¡ ¥ (4)

( (    $ §¦ ¨£

¤¥£ ¤

'

¦&§ ¦&§ © ( ¦&§ ¦&§ © (

¥  ¥ ( (  $

(5)

where ¡©¡¡¢¡ denotes the  ¥ norm of a vector. A standard approach to minimizing such

¥

a function is to use gradient descent and alternate between minimization with respect to

"! 

 

and minimization with respect to

 

¡

stated is underconstrained. The function

. Unfortunately, the optimization problem as has many local minima and results from our

© §(

simulations indicate that convergence is difficult in many cases. There are many different ways to represent an image, making it difficult for the method to converge to a basis set that can generalize effectively. A related approach is presented by Tenenbaum and Freeman [12]. Rather than using gradient descent, their method estimates the parameters directly by computing the singular value

decomposition (SVD) of a matrix

class



 containing input data corresponding to each content

in every style . Their approach can be regarded as an extension of methods based



on principal component analysis (PCA) applied to the bilinear case. The SVD approach avoids the difficulties of convergence that plague the gradient descent method and is much faster in practice. Unfortunately, the learned features tend to be global and non-localized similar to those obtained from PCA-based methods based on second-order statistics. As a result, the method is unsuitable for the problem of learning local features of objects and their transformations. and . In particular, we could cast the problem within a probabilistic framework and imcertain desirable properties. We focus here on the class of sparse prior distributions for several reasons: (a) by forcing most of the coefficients to be zero for any given input, sparse

The underconstrained nature of the problem can be remedied by imposing constraints on



pose specific prior distributions on



 and  with higher probabilities for values that achieve

 ¥

priors minimize redundancy and encourage statistical independence between the various in the brain ­ the distribution of neural responses in visual cortical areas is highly kurtotic i.e. the cell exhibits little activity for most inputs but responds vigorously for a few inputs, causing a distribution with a high peak near zero and long tails, (c) previous approaches

and between the various  [7], (b) there is growing evidence for sparse representations

 ¥

based on sparseness constraints have obtained encouraging results [7], and (d) enforcing sparseness on the encourages the parts and local features shared across objects to be in terms of a small set of basic transformations.

learned while imposing sparseness on the  (

allows object transformations to be explained

3.2 Bilinear Sparse Coding We assume the following priors for  ¥ ¥

(



 ¡ $  ( ¡  $ and  (

:

 !#"

%$'&¢(0)21



3%$'& 1

43 5

"

   3

@

and where and are normalization constants, 6 7

(6) (7) are parameters that control the

 ¡ 29 $

degree of sparseness, and

@©ACB 9 ¥

D

$

.

 8 is a "sparseness function." For this study, we used 8


¥

Within a probabilistic framework, the squared error function  

§

ters: £

   ( ¡

© !3 !# $

(see, for example, [7]). The priors

¥

¥summed¥

over all images

can be interpreted as representing the negative log likelihood of the datagiven the parame@©ACB  

$

and

$

can be used

 ¡

to marginalize this likelihood to obtain the new likelihood function:

The goal then is to find the

log of 



$

.



©

. Under certain reasonable assumptions (discussed in [7]), this is equivalent to

(

 ($( ¡    (

¥

© ©

that maximize  , or equivalently, minimize the negative

minimizing the following optimization function over all input images:

'

 

! "!#%$ ¡   ¡©¡ ¨£

¤¥£ ¤

¦&§ ¦&§ © ( ¡©¡ ¥

¥ © ( ¥  ¥ ( ( 

D 6

¤¥£ ¦&§

8

 ¥

$

¤

D 7

(

' ¦&§

8

 (

and Gradient descent can be used to derive update rules for the components

feature vector

basis

© :



¤£¥

¤

(



and transformation vector

§  ¡   ¤

       ¥

respectively for any image , assuming a fixed

'



 

¦  8

¡

$ £¢

(8)

of the

¡ ¡ £ ¦ §

¡ ¨

¤ 

¤£¥ ¢ ¡ §  

£

¦ §  ¡ ¤

¢ ¨

 £,

' £¦&§ ¦&§¥ ©

© ¡©¨¦

¨¦ ¢

¤£

£

¤¥£ ¤ ( ¤¥£¦ ¤

§ ¦&§' © ¦&§ ¦&§6© (

and



¥  ¥ ( (  $  ¥  ¥  ( (  $

¨ 6 D

¨ 7 D ¦  ¢ 8

  ¡ $

(9)

$ (10)

Given a training set of inputs the values for

§  

©

( 

for each image after convergence

can be used to update the basis set

¤

©¤£¥¡ ¢ ¡ £ ¦ §

in batch mode according to:

¤



  

¤¥£ ¤

'

£

¦&§ ¦&§ ¦&§6© (

 $  ¡ ¡ ¡

¢

¥  ¥  ( (

¢ (11)

©

As suggested by Olshausen and Field [7], in order to keep the basis vectors from growing

without bound, we adapted the

of the and

 (

 ¥ norm of each basis vector in such a way that the variances

were maintained at a fixed desired level.

 ¥

4 Results 4.1 Training Paradigm We tested the algorithms for bilinear sparse coding on natural image data. The natural images we used are distributed by Olshausen and Field [7], along with the code for their

algorithm. The training set of images consisted of

ten !

¦ ¦

 

!



   

patches randomly extracted from

source images. The images are pre-whitened to equalize large variances in

frequency, and thus speed convergence. We choose to use a complete basis where "





¡

and we let # be at least as large as the number of transformations (including the no-

¦%$ ¦ $

transformation case). The sparseness parameters 6 and 7 were set to and



! . In

order to assist convergence all learning occurs in batch mode, where the batch consisted

of & set to

$

 

!'(. The transformations were chosen to be 2D translations in the range 0 

image patches. The step size ) for gradient descent using Equation 11 was

214351(6 £

¡

pixels in both the axes. The style/content separation was enforced by learning a single

vector to describe an image patch regardless its translation, and likewise a single to describe a particular style given any image patch content. 4.2 Bilinear Sparse Coding of Natural Images





vector

Figure 1 shows the results of training on natural image data. A comparison between the learned features for the linear generative model (Equation 1) and the bilinear model is


(a)

Example of linear basis

wi y(-3) wi y(-2) wi y(-1) wi

Example of Bilinear basis y(0)

wi y(1) wi y(2) wi y(3) wi

i = 1

i = 2

(b) Estimated feature x vector i = 3 9

wi after learning j

2 7 x 

91

y  j 1 i 3

8

Canonical patch y 9

Estimated transformation vectors

91

Translated patch y

j = 1 2 7 8

Figure 1: Representing natural images and their transformations with a sparse bilinear model. (a) A comparison of learned features between a standard linear model and a bilinear model, both trained with the same sparseness priors. The two rows for the bilinear pixels. (b) The representation of an example natural image patch, and of the same patch ing only three significant coefficients. The code for the style vectors for both the canonical

¥

case depict the translated object features w (see Equation 3) for translations of

¡  £ $ $ $ ! !   @

translated to the left. Note that the bar plot representing the

 vector is indeed sparse, hav-

 ¥

patch, and the translated one is likewise sparse. The dimensions which have non-zero coefficients for or

¥ © (

(

basis images are shown for those .

provided in Figure 1 (a). Although both show simple, localized, and oriented features, the bilinear method is able to model the same features under different transformations. In model. Figure 1 (b) provides an example of how the bilinear sparse coding model encodes

this case, the range 0 ¡    ! £ 6

horizontal translations were used in the training of the bilinear

a natural image patch and the same patch after it has been translated. Note that both the

and



vectors are sparse.



Figure 2 shows how the model can account for a given localized feature at different locations by varying the y vector. As shown in the last column of the figure, the translated local

feature is generated by linearly combining a sparse set of basis vectors 4.3 Towards Parts-Based Object Recognition ©

(

.

¥

The bilinear generative model in Equation 2 uses the same set of transformation values

$ $ $ ! !

for all the features

0



¡  (

" . Such a model is appropriate for global transformations


Feature 1 (x57) Selected transformations y(-1,+2)

wi j

y(0,3)

Feature 2 (x32)

y(-2,0)

wi j

j = 1 2 3 4 5 6 7 8

y(+1,0) j = 1

... 8

¥

Figure 2: Translating a learned feature to multiple locations. The two rows of eight

images represent the individual basis vectors

0 

values for two

selected transformations for each are shown as bar plots.

9

!¢  $



0

©

for two values of . The

29

  !¡ 8$

denotes a translation of

( (

pixels in the Cartesian plane. The last column shows the resulting basis vectors after

translation. that apply to an entire image region such as a shift of £ pixels for an image patch or a global illumination change. Consider the problem of representing an object in terms of its constituent parts. In this case, we would like to be able to transform each part independently of other parts in order to account for the location, orientation, and size of each part in the object image. The standard bilinear model can be extended to address this need as follows:

 1¡

¤¥£ ¤



'

¦&§ ¦&§ © (

¥  ¥ ¥ ( (  $

¥

Note that each object feature now has its own set of transformation values

0

¥



(

(12) . The double

summation is thus no longer symmetric. Also note that the standard model (Equation 2) is We have conducted preliminary experiments to test the feasibility of Equation 12 using a set of object features learned for the standard bilinear model. Fig. 3 shows the results. These results suggest that allowing independent transformations for the different features provides a rich substrate for modeling images and objects in terms of a set of local features (or parts) and their individual transformations. 5 Summary and Conclusion A fundamental problem in vision is to simultaneously recognize objects and their transformations [8, 10]. Bilinear generative models provide a tractable way of addressing this problem by factoring an image into object features and transformations using a bilinear equation. Previous approaches used unconstrained bilinear models and produced global basis vectors for image representation [12]. In contrast, recent research on image coding has stressed the importance of localized, independent features derived from metrics that emphasize the higher-order statistics of inputs [6, 3, 7, 5]. This paper introduces a new probabilistic framework for learning bilinear generative models based on the idea of sparse coding. Our results demonstrate that bilinear sparse coding of natural images produces localized oriented basis vectors that can simultaneously represent features in an image and their transformation. We showed how the learned generative model can be used to translate a

a special case of Equation 12 where   ( ( for all . 0

¡


(a) wy81

y(0,1) x81 z

x wy57 57

81

x57

y(0,1)

(b)

w81 j y81 x81 j

 

y81 ¡ z y(-2,0)

y(0,1) y(-2,0)

y57 ¡

x57

y(0,1) y(1,0)

y(1,1) y(1,0)

y(1,1)

¥

Figure 3: Modeling independently transformed features. (a) shows the standard bilinear

method of generating a translated feature by combining basis vectors

¢

set of



values for two different features (

0

images generated by allowing different values of

!

(

and

(

¡

). (b) shows four examples of

©

using the same

£



(

for the two different features. Note the

significant differences between the resulting images, which cannot be obtained using the standard bilinear model.

basis vector to different locations, thereby reducing the need to learn the same basis vector at multiple locations as in traditional sparse coding methods. We also proposed an extension of the bilinear model that allows each feature to be transformed independently of other features. Our preliminary results suggest that such an approach could provide a flexible platform for adaptive parts-based object recognition, wherein objects are described by a set of independent, shared parts and their transformations. The importance of parts-based methods has long been recognized in object recognition in view of their ability to handle a combinatorially large number of objects by combining parts and their transformations. Few methods, if any, exist for learning representations of object parts and their transformations directly from images. Our ongoing efforts are therefore focused on deriving efficient algorithms for parts-based object recognition based on the combination of bilinear models and sparse coding.


Acknowledgments This research is supported by NSF grant no. 133592 and a Sloan Research Fellowship to RPNR. References [1] F. Attneave. Some informational aspects of visual perception. Psychological Review, 61(3):183­193, 1954. [2] H. B. Barlow. Possible principles underlying the transformation of sensory messages. In W. A. Rosenblith, editor, Sensory Communication, pages 217­234. Cambridge, MA: MIT Press, 1961. [3] A. J. Bell and T. J. Sejnowski. The `independent components' of natural scenes are edge filters. Vision Research, 37(23):3327­3338, 1997. [4] G. E. Hinton and Z. Ghahramani. Generative models for discovering sparse distributed representations. Philosophical Transactions Royal Society B, 352(1177­ 1190), 1997. [5] M. S. Lewicki and T. J. Sejnowski. Learning overcomplete representations. Neural Computation, 12(2):337­365, 2000. [6] B. A. Olshausen and D. J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381:607­609, 1996. [7] B. A. Olshausen and D. J. Field. Sparse coding with an overcomplete basis set: A strategy employed by V1? Vision Research, 37:33113325, 1997. [8] R. P. N. Rao and D. H. Ballard. Development of localized oriented receptive fields by learning a translation-invariant code for natural images. Network: Computation in Neural Systems, 9(2):219­234, 1998. [9] R. P. N. Rao and D. H. Ballard. Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive field effects. Nature Neuroscience, 2(1):79­87, 1999. [10] R. P. N. Rao and D. L. Ruderman. Learning Lie groups for invariant visual perception. In Advances in Neural Information Processing Systems 11, pages 810­816. Cambridge, MA: MIT Press, 1999. [11] O. Schwartz and E. P. Simoncelli. Natural signal statistics and sensory gain control. Nature Neuroscience, 4(8):819­825, August 2001. [12] J. B. Tenenbaum and W. T. Freeman. Separating style and content with bilinear models. Neural Computation, 12(6):1247­1283, 2000.


