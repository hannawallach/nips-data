Artefactual Structure from Least Squares Multidimensional Scaling

Nicholas P. Hughes Department of Engineering Science University of Oxford Oxford, 0X1 3PJ, UK nph@robots.ox.ac.uk David Lowe Neural Computing Research Group Aston University Birmingham, B4 7ET, UK d.lowe@aston.ac.uk

Abstract We consider the problem of illusory or artefactual structure from the visualisation of high-dimensional structureless data. In particular we examine the role of the distance metric in the use of topographic mappings based on the statistical field of multidimensional scaling. We show that the use of a squared Euclidean metric (i.e. the SSTRESS measure) gives rise to an annular structure when the input data is drawn from a highdimensional isotropic distribution, and we provide a theoretical justification for this observation.

1 Introduction The discovery of meaningful patterns and relationships from large amounts of multivariate data is a significant and challenging problem with close ties to the fields of pattern recognition and machine learning, and important applications in the areas of data mining and knowledge discovery in databases (KDD). For many real-world high-dimensional data sets (such as collections of images, or multichannel recordings of biomedical signals) there will generally be strong correlations between neighbouring observations, and thus we expect that the data will lie on a lower dimensional (possibly nonlinear) manifold embedded in the original data space. One approach to the aforementioned problem then is to find a faithful1 representation of the data in a lower dimensional space. Typically this space is chosen to be two- or three-dimensional, thus facilitating the visualisation and exploratory analysis of the intrinsic low-dimensional structure in the data (which would otherwise be masked by the dimensionality of the data space). In this context then, an effective dimensionality reduction algorithm should seek to extract the underlying relationships in the data with minimum loss of information. Conversely, any interesting patterns which are present in the visualisation space should be representative of similar patterns in the original data space, and not artefacts of the dimensionality reduction process.

1 By "faithful" we mean that the underlying geometric structure in the data space, which charac-

terises the informative relationships in the data, is preserved in the visualisation space.


Although much effort has been focused on the former problem of optimal structure elucidation (see [7, 10] for recent approaches to dimensionality reduction), comparatively little work has been undertaken on the latter (and equally important) problem of artefactual structure. This shortcoming was recently highlighted in a controversial example of the application of visualisation techniques to neuroanatomical connectivity data derived from the primate visual cortex [12, 9, 13, 3]. In this paper we attempt to redress the balance by considering the visualisation of highdimensional structureless data through the use of topographic mappings based on the statistical field of multidimensional scaling (MDS). This is an important class of mappings which have recently been brought into the neural network domain [5], and have significant connections to modern kernel-based algorithms such as kernel PCA [11]. The organisation of the remainder of this paper is as follows: In section 2 we introduce the technique of multidimensional scaling and relate this to the field of topographic mappings. In section 3 we show how under certain conditions such mappings can give rise to artefactual structure. A theoretical analysis of this effect is then presented in section 4. 2 Multidimensional Scaling and Topographic Mappings The visualisation of experimental data which is characterised by pairwise proximity values is a common problem in areas such as psychology, molecular biology and linguistics. Multidimensional scaling  (MDS) is a statistical technique which can be used to construct measure of the similarity or dissimilarity between the objects, and the geometric layout of the resulting MDS configuration reflects the relationships between the objects as defined by this matrix. In this way the information contained within the proximity matrix can be captured by a more succinct spatial model which aids visualisation of the data and improves understanding of the processes that generated it. In many situations, the raw dissimilarities will not be representative of actual inter-point distances between the objects, and thus will not be suitable for embedding in a lowdimensional space. In this case the dissimilarities can be transformed into a set of values more suitable for embedding through the use of an appropriate transformation: ¢¤£¦¥¨§©¢£¥ ¡

a spatial configuration of points in a (typically) two- or three-dimensional space given a

matrix of pairwise proximity values between

 

objects. The proximity matrix provides a

© ¢¡ £¦¥

where represents the transformation function and are the resulting transformed dis-

similarities (which are termed "disparities"). The aim of metric MDS then is that the transtances  in the resulting configuration2. Metric MDS can be formulated as a continuous optimisation problem through the definition of an appropriate error function. In particular, least squares scaling algorithms directly seek to minimise the sum-of-squares error between the disparities and the inter-point distances. This error, or STRESS3 measure, is given by: ¢£¥ ¡

formed dissimilarities £¥ should correspond as closely as possible to the inter-point dis-

§  £¥10 ¢¡ £¥32 £¦¥465

STRESS £!¥ £¦¥¨$ £ $¥&%'£)( ¢#" ¡  (1)

2 This is in contrast to nonmetric MDS which requires that only the ordering of the disparities

corresponds to the ordering of the inter-point distances (and thus that the disparities are some arbitrary monotonically increasing function of the distances).

3 STRESS is an acronym for STandard REsidual Sum of Squares.


where the term ¡  £ !¥ £¦¥ ¢¡ " is a normalising constant which reduces the sensitivity of the

£¥

measure to the number of points and the scaling of the disparities, and the

(

are the

weighting factors. It is straightforward to differentiate this STRESS measure with respect to the configuration points ¢ and minimise the error through the use of standard nonlinear £ optimisation techniques. An alternative and commonly used error function, which is referred to as SSTRESS, is given by:

§ 

SSTRESS £!¥ £¥ $ £ $¥&%'£ ¢¡ " 0 ¢¡ " 2 £¥ 4 5  £¦¥"

(2)

which represents the sum-of-squares error between squared disparities and squared distances. The primary advantage of the SSTRESS measure is that it can be efficiently minimised through the use of an alternating least squares procedure4 [1]. Closely related to the field of Metric MDS is Sammon's mapping [8], which takes as its input a set of high-dimensional vectors and seeks to produce a set of lower dimensional vectors such that the following error measure is minimised:

 £¦¥  £¥¤§¦©¨¨ §

£!¥ £¥     £¥  5

$ £ $¥&% £

2 £¥

(3)

  £ 2  ¥ 



where the£¥  are the inter-point Euclidean distances in the data space:  

and the 

space: 

§

£¥ £¥ ! £ 2

£¥ § ,

are the corresponding inter-point Euclidean distances in the feature or map

¢ ¢

¥ 

.

Ignoring the normalising constant, Sammon's mapping is thus equivalent to least squares metric MDS with the disparities taken£¥to be the raw inter-point distances in the data space

§ and the weighting factors given by

(

£¥ "    . Lowe (1993) termed£¥ such a mapping

£ !¥ £¥    2 

based on the minimisation of an error measure of the form  5 a topographic

mapping, since this constraint "optimally preserves the geometric structure in the data" [5]. Interestingly the choice of the STRESS or SSTRESS measure in MDS has a more natural interpretation when viewed within the framework of Sammon's mapping. In particular, STRESS corresponds to the use of the standard Euclidean distance metric whereas SSTRESS corresponds to the use of the squared Euclidean distance metric. In the next section we show that this choice of metric can lead to markedly different results when the input data is sampled from a high-dimensional isotropic distribution.

3 Emergence of Artefactual Structure In order to investigate the problem of artefactual structure we consider the visualisation of high-dimensional structureless data (where we use the term "structureless" to indicate that the data density is equal in all directions from the mean and varies only gradually in any direction). Such data can be generated by sampling from an isotropic distribution (such as a spherical Gaussian), which is characterised by a covariance matrix that is proportional to the identity matrix, and a skewness of zero. We created four structureless§ data sets by randomly sampling 1000 i.i.d. points from unit

hypercubes of dimensions #

4

5, 10, 30 and 100. For each data set, we generated a pair

The SSTRESS measure now forms the basis of the ALSCAL implementation of MDS, which is

included as part of the SPSS software package for statistical data analysis.


4 1.4 2.5

1.2 1.5 2 3

1 1.5

2

1 0.8

1

1 0.6

0.5 0.5

0.4 0

0

0.2

0 -1

-0.5 0

-1 -2 -0.2 -0.5

-0.4 -1.5

-0.5 0 0.5 1 1.5 -1 -0.5 0 0.5 1 1.5 2 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 2.5 3

-3 -4

-3 -2 -1 0 1 2 3 4 5

(a)  ¢¡ 5 (b)  £¡ 10 (c)  £¡ 30 (d)  £¡ 100

Figure 1: Final map configurations produced by STRESS mappings of data uniformly randomly distributed in unit hypercubes of dimension # .

of 2-D configurations by£ minimising£¦¥" Srespectively.SSTRESS error measures of the form (for each individual error function and data set) using different initial configurations of the map points, and the configuration with the lowest final error was retained. As previously noted, the choice of the STRESS or SSTRESS error measure is best viewed as a choice of distance metric, where STRESS corresponds to the standard Euclidean metric and SSTRESS corresponds to the squared Euclidean metric. Figure 1 shows the resulting configurations from the STRESS mappings. It is clear that each configuration has captured the isotropic nature of the associated data set, and there are no spurious patterns or clusters evident in the final visualisation plots. £ !¥ £¥    2 £¥   5 !¥ £¥    " 2

and  5 The process was repeated fifty times 5  TRESS and

1.6

1.2 2 3

1.4

2.5 1

1.2 1.5

2

0.8 1

1.5

1 0.8

0.6 1

0.6

0.4 0.5 0.5

0.4

0

0.2 0.2 0

-0.5

0 0

-1 -0.5

-0.2 -0.2 -1.5

-0.4 -1

-0.4

-0.5 0 0.5 1 1.5 -0.5 0 0.5 1 1.5 -1.5 -1 -0.5 0 0.5 1 1.5 2 2.5

-2 -3

-2 -1 0 1 2 3

(a)  £¡ 5 (b)  £¡ 10 (c)  £¡ 30 (d)  £¡ 100

Figure 2: Final map configurations produced by SSTRESS mappings of data uniformly randomly distributed in unit hypercubes of dimension # . Figure 2 shows the resulting configurations from the SSTRESS mappings. The configurations exhibit significant artefactual structure, which is characterised by a tendency for the map points to cluster in a circular fashion. Furthermore, the degree of clustering increases with increasing dimensionality of the data space # (and is clearly evident for # as low as 10). Although the tendency for SSTRESS configurations to cluster in a circular fashion has been noted in the MDS literature [2], the connection between artefactual structure and the choice of distance metric has not been made. Indeed, in the next section we show analytically that the use of the squared Euclidean metric leads to a globally optimal solution corresponding to an annular structure. To date, the most significant work on this problem is that of Klock and Buhmann [4], who proposed a novel transformation of the dissimilarities (i.e. the squared inter-point distances

5 We used a conjugate gradients optimisation algorithm.


in the data space) such that "the final disparities are more suitable for Euclidean embedding". However this transformation assumes that the input data are drawn from a spherical Gaussian distribution6, which is inappropriate for most real-world data sets of interest. 4 Theoretical Analysis of Artefactual Structure

In this section we present a theoretical analysis of the artefactual structure problem. A

 

dimensional map configuration is considered to be the result of a SSTRESS mapping of a

data set of

¡ i.i.d. points drawn from a # dimensional isotropicdistribution (where #

§  

§ 

¢

¨

T .

¨¨ 

¢ £ §

£¢¤ 

).

The set of data points is given by the

the set of map points is given by the

¡  

x

¡

x # matrix

matrix

 ¥

¦¨§¦©¨¢ ¨¨ 1

5

5

T and similarly

£!¥ £¦¥    " 2  £¥"  5

with respect to a particular map vector ¢ : We begin by defining the derivative of the£ SSTRESS error measure

 £ 2

" 2 £¦¥" ¥

¢ £ §

$ £ !¥ "  £¥     £ 2 ¢ ¢

(4)

The inter-point distances   and  are given by:

  £¥



£¥"

" §   £ 2  ¥  §   £62  ¥    £ 2  ¥  §   £ T

£ ¢ ¢ T

T

¥   £ 2 T ¢ §  £ 2 ¢ ¢

5 ¥  §  £62

5 ¢ ¢ ¢ ¥  §

£¦¥ " £¥"

$#£'#£

 ¥  ¥ 2 T

¥T ¢ ¢ ¥ 2

&% (%

 £  ¥ T

£ ¢ ¢ T ¥

Equation (4) can therefore be expanded to:

 £

  £  £ 2 T

£ ¢ ¢ T ¥  £ ¢

£ ¢ ¢ T £

§ 2 2

¢

) 43

!¥ "

$ £ $ £

!¥ "

£   £62 ¢ ¢ ¥  2

0 1

$ £

 5#63

!¥ " $ £   £  ¥  £ T ¢

!¥ 5#73"

¥T ¥ 2 ¥T ¢ ¢ ©2¥  £#2 ¢

¢

¥    £  ¥  ¥

T

¢

!¥ " $ £  £ ¥  ¥ 2 ¢ ¢ T ¢ )3 !¥ "

$ £

We can immediately simplify some of these terms as follows:

£  ¥ '§ £ T

$ £ $ £

!¥ " !¥ "

$ £ $ £

!¥ "

!¥ " 

£ ¢ ¢ T ¥  £ § ¢

$ £ $ £

!¥ " !¥ "

$ £ $ £

!¥ "

!¥ " ¢

£ ¢ ¢ T £ ¢ ¢

$ £ $ £

!¥ "

   ¥  £ § £ T

£ ¢ ¢ T

¢ ¥  ¥ § ¢



¢ £    ¥ 6§ £ T

1¢ 82£ 1 82

¥T ¢

¥   £ § ¥T

FE ¡ §

¢ £  T £

1¢ 2 1¢ 2

¥ ¢

¥  ¥ T

!¥ "

¢ ¥ §

T

¢ ¢

!¥ "

$ £ $ £

!¥ "

¢  ¥ ¥T ¥

¢ £

   ¥  ¥ § £  £

Thus at a stationary point of the error (i.e.

   £ 2 £ T £ ¢ ¢ T £ HGI

9BDC9A@

¢ £62 2

$ £ !¥ " ¢

PQR# ¡ ¥



), we have:

2

!¥ "

$ £

1 ¥T  ¥32



¥T ¢ ¢ ¥  £62 ¢ 2

¢ ¥ 

6 In this case the squared inter-point distances will follow a

ST distribution.


§

%

2

GI ¢ £  T £ !¥ "

$ £

 ¥ 2



£ ¢ ¢ T £

!¥ " $ £ ¢ ¥ # ¡

$ £ !¥ "

1¢ 2 ¥ ¢ ¥T ¢ £62

$ £ !¥ "

1¢ 2 PQ ¥  ¥T  £

(5)

£ Since the error is a function of the inter-point distances only, we can centre both the data

points and the map points on the origin without loss of generality. For large

¡

2 2 2 ¡

E£¢ ¦

!

¡§¦©¨ tr

 ¥ ¡

E¥¤ ¦

!

¡¦©¨

tr ¦ 

 $ £

!¥ " !¥ " !¥ "

$ £

$ £

 

¢ ¥ ¡

2 2 2

 $ £

!¥ " !¥ " !¥ "

$ £

$ £

¡

we have:

¡ 

¥ ¢ ¢ ¥T ¢ ¢ ¥T ¢

¥  ¥T

¡ 

¡  ¥ ¡

¦ ¨ ¦ ¨

  ¥ ¥T

¡ ¡ 

where

E ¨ ! 

is the  x zero matrix, is the covariance matrix of the map vectors,

¦ ¨

is the covariance matrix of the map vectors and the data vectors, and tr is the matrix

trace operator. Thus equation (5) reduces to:   £  £ 2

T

§ % ¦ ¨



¢ ¢ £62 T

£ £  £

¢

4%

# 2

$#£ 

$ £

tr ¢ ¦ ¨  

!¥ "

1¢ 2

¥T ¥ ¢ 2 ¢ ¥ 2 ¦ ! 2

$ £

 £ ¢

!¥ " 1 2 ¥T ¥ ¡ ¡ ¢ ¥



¦ ¨  tr (6)

This represents a general expression for the value of the map vector ¢ at a stationary point £ of the SSTRESS error, regardless of the nature of the input data distribution. However we are interested in the case where the input data is drawn from a high-dimensional isotropic distribution. If the data space is isotropic then a stationary point of the error will correspond to a similarly

isotropic map space7. Thus, at a stationary point, we have for large

¦©¨"¡$# ¦ ¨ ¡ E£¢%'&"

!¤

¡

:

tr ¦©¨  2 tr ¦(  ¡ #  

¢ %" # )"

2 #

where & is the x ¢

   

identity matrix, and %" and )" are the variances in the map space and # #

the data space respectively. Finally, consider the expression:

¡ 2  $ £ !¥ "

1¢ A2¥ ¥T ¢ ¢ ¥ 2 2

$ £ !¥ "

1 !2¥ ¥T ¢ ¥ ¡



The first term is the third order moment, which is zero for an isotropic distribution [6]. For high-dimensional data (i.e. large # ) the second term can be simplified to:

0 ¤

¡ 2

1 A2

¥T  ¥ ¥ § ¥" 143 ¥ ¡ # # )" ¥ ¡ E5¢ ¦ !

(7) $ £ !¥ " ¢

 ¡ #2

 $ £ !¥ "  # 1$ ¦¥2 " ¢ 2 !¥ "

$ £ ¢ ¡ 

7 This is true regardless of the initial distribution of the map points, although a highly non-uniform

initial configuration would take significantly longer to reach a local minimum of the error function.


Thus the equation governing the £stationary" points of the SSTRESS error is given by: £

T

 £ 2 ¢ ¢ T £ # ) # 2   

 " # % ¢ £ § ¢ !

At the minimum error configuration,£ we have:"

 £  £ 2 £ Summing over all points , gives:

T

¢ ¢ T

 ¢

$£

¡

tr

# %"

" ¦

1

£ T  £ 2 £ ¢ ¢ T

# ) #

# # )" £ ¢ ¢

T

# 2   

#6% ¡  # % 2 £  #6% £ 

 " § # %

 " §

# 2  %

# )" #   # % ¡   " § #

%

 " § # %

1 # # % 2 FE ¦

$#£

$£

2 

$#£

2 

 

¤  

$£

¦  §

" ¦

  £ 2  £ T

¡

¦ ¨  )" 2

  ## #

# " ¦

¤¤ tr 

# )" #  

(8)

Thus, for large # , the variance of the map points is related to the variance of the data points by a factor of . Table 1 shows the values of the observed and predicted map variances¤

(i.e. )" #

    3 ¨ §  ©¨

) of dimensions #

§

5, 10, 30, and 100. Clearly as the dimension of the

¤ for 1000§ data points sampled randomly from uniform distributions in the interval

¦¥¢ ¦

data space # increases, so too does the accuracy of the approximation given by equation (7), and therefore the accuracy of equation (8).

Dimension # 5 10 30 100 Number of points 1000 1000 1000 1000 ¡ # %" observed 0.166 0.303 0.864 2.823 # %" predicted 0.139 0.278 0.835 2.783 Percentage error 16.4% 8.1% 3.4% 1.4%

Table 1: A comparison of the predicted and observed map variances. We can show that this mismatch in variances in the two spaces results in the map points clustering in a circular fashion by considering the expected squared distance of the map

points from the origin (i.e. the expected squared radius



 5  § ¡ £ § # § $£

" ¦ £ ¢ ¢ T   %"

  5

of the annulus):

#

 

# )"



#

  (9)

In addition we can derive an analytic expression for

two-dimensional map space ¢

  



T



§  § § §

 ¦¨%¦¦¦





"!#



## %.% ¦5  # 



  . For simplicity, consider a

5

Then we have:

  ¦5   #   5    55  

 ¦5 

and

55

  

5

 

where the expectation over

 ¦5 

55 separates since

(10)

% . Thus the varianceof

!

$#%'& 5

  55

will be uncorrelated due to the

isotropic nature of ¢ . In general for a -dimensional map space we have that

  " #

is given by:



5

 §

  



 2 



  5 5   §

( 

  #  §

Hence for large # the optimal configuration will be an annulus or ring shape, as observed in figure 2.


5 Conclusions We have investigated the problem or artefactual or illusory structure from topographic mappings based upon least squares scaling algorithms from multidimensional scaling. In particular we have shown that the use of a squared Euclidean distance metric (i.e. the SSTRESS measure) gives rise to an annular structure when the input data is drawn from a highdimensional isotropic distribution. A theoretical analysis of this problem was presented and a simple relationship between the variance of the map and the data points was derived. Finally we showed that this relationship results in an optimal configuration which is characterised by the map points clustering in a circular fashion. Acknowledgments We thank Miguel Carreira-Perpi~n´an for useful comments on this work. References

[1] T. F. Cox and M. A. A. Cox. Multidimensional scaling. Chapman and Hall, London, 1994. [2] J. deLeeuw and B. Bettonvil. An upper bound for sstress. Psychometrika, 51:149 ­ 153, 1986. [3] G. J. Goodhill, M. W. Simmen, and D. J. Willshaw. An evaluation of the use of multidimensional scaling for understanding brain connectivity. Philosophical Transactions of the Royal Society, Series B, 348:256 ­ 280, 1995. [4] H. Klock and J. M. Buhmann. Multidimensional scaling by deterministic annealing. In M. Pelillo and E. R. Hancock, editors, Energy Minimization Methods in Computer Vision and Pattern Recognition, Proc. Int. Workshop EMMCVPR '97, Venice, Italy, pages 246­260. Springer Lecture Notes in Computer Science, 1997. [5] D. Lowe and M. E. Tipping. Neuroscale: Novel topographic feature extraction with radial basis function networks. In M. C. Mozer, M. I. Jordan, and T. Petsche, editors, Advances in Neural Information Processing Systems 9. Cambridge, MA: MIT Press, 1997. [6] K. V. Mardia, J. T. Kent, and J. M. Bibby. Multivariate analysis. Academic Press, 1997. [7] S. T. Roweis, L. K. Saul, and G. E. Hinton. Global coordination of local linear models. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14. Cambridge, MA: MIT Press, 2002. [8] J. W. Sammon. A nonlinear mapping for data structure analysis. IEEE Transactions On Computers, C-18(5):401 ­ 409, 1969. [9] M. W. Simmen, G. J. Goodhill, and D. J. Willshaw. Scaling and brain connectivity. Nature, 369:448­450, 1994. [10] J. B. Tenenbaum. Mapping a manifold of perceptual observations. In M. I. Jordan, M. J. Kearns, and S. A. Solla, editors, Advances in Neural Information Processing Systems 10. Cambridge, MA: MIT Press, 1998. [11] C. K. Williams. On a connection between kernel PCA and metric multidimensional scaling. In T. K. Leen, T. G. Diettrich, and V. Tresp, editors, Advances in Neural Information Processing Systems 13. Cambridge, MA: MIT Press, 2001. [12] M. P. Young. Objective analysis of the topological organization of the primate cortical visual system. Nature, 358:152­155, 1992. [13] M. P. Young, J. W. Scannell, M. A. O'Neill, C. C. Hilgetag, G. Burns, and C. Blakemore. Non-metric multidimensional scaling in the analysis of neuroanatomical connection data and the organization of the primate cortical visual system. Philosophical Transactions of the Royal Society, Series B, 348:281 ­ 308, 1995.


