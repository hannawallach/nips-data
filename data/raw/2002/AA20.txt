Boosting Density Estimation

Saharon Rosset Department of Statistics Stanford University Stanford, CA, 94305 saharon@stat.stanford.edu Eran Segal Computer Science Department Stanford University Stanford, CA, 94305 eran@cs.stanford.edu

Abstract

Several authors have suggested viewing boosting as a gradient descent search for a good fit in function space. We apply gradient-based boosting methodology to the unsupervised learning problem of density estimation. We show convergence properties of the algorithm and prove that a strength of weak learnability property applies to this problem as well. We illustrate the potential of this approach through experiments with boosting Bayesian networks to learn density models.

1 Introduction Boosting is a method for incrementally building linear ¢¡¤£¦¥¢§£©¨

combinations of "weak" models, weak learners  and a loss function  , a boosting algorithm£ sequentially1 finds models

, a basis (or dictionary) of to generate a "strong" predictive model. Given data

 ¢  © "!  and constants # ¢  $ ©"!&% # to minimize ' )( ¡¢£0 '213#  ¡¢£5464 1 (

. Ad-

aBoost [6], the original £B6CD£E4 ¡7£98 fication, where (A@ boosting algorithm, was specifically devised for the£5464 of classiCD£"!F DGIHPH¤¥ 8

with and  )( CP£0 ' 1Q# 1 1 (R@ task . AdaBoost

sequentially fits weak learners on re-weighted versions of the data, where the weights are determined according to the performance of the model so far, emphasizing the more "challenging" examples. Its inventors attribute its success to the "boosting" effect which the linear combination of weak learners achieves, when compared to their individual performance. This effect manifests itself both in training data performance, where the boosted model can be shown to converge, under mild conditions, to ideal training classification, and in generalization error, where the success of boosting has been attributed to its "separating" -- or margin maximizing -- properties [18]. It has been shown [8, 13] that AdaBoost can be described as a gradient descent algorithm, where the weights in each step of the algorithm correspond to the gradient of an exponential loss function at the "current" fit. In a recent paper, [17] show that the margin maximizing properties of AdaBoost can be derived in this framework as well. This view of boosting as gradient descent has allowed several authors [7, 13, 21] to suggest "gradient boosting machines" which apply to a wider class of supervised learning problems and loss functions than the original AdaBoost. Their results have been very promising. In this paper we apply gradient boosting methodology to the unsupervised¡learning problem

of density estimation, using the negative log likelihood loss criterion S( ' 13#

GWV©XDY

( ' 13#

1 1  ¡T464

(

1 1 ( ¡T464U8

. The density estimation problem has been studied extensively in many

contexts using various parametric and non-parametric approaches [2, 5]. A particular


framework which has recently gained much popularity is that of Bayesian networks [11], whose main strength stems from their graphical representation, allowing for highly interpretable models. More recently, researchers have developed methods for learning Bayesian networks from data including learning in the context of incomplete data. We use Bayesian networks as our choice of weak learners, combining the models using the boosting methodology. We note that several researchers have considered learning weighted mixtures of networks [14], or ensembles of Bayesian networks combined by model averaging [9, 20]. We describe a generic density estimation boosting algorithm, following the approach of

 !

[13]. The main idea is to identify, at each boosting iteration, the basis function  which gives the largest "local" improvement in the loss at the current fit. Intuitively,



assigns higher probability to instances that received low probability by the current model. A

line search is then used to find an appropriate coefficient for the newly selected and it is added to the current model. function,

We provide a theoretical analysis of our density estimation boosting algorithm, showing an explicit condition, which if satisfied, guarantees that adding a weak learner to the model improves the training set loss. We also prove a "strength of weak learnability" theorem which gives lower bounds on overall training loss improvement as a function of the individual weak learners' performance on re-weighted versions of the training data. We describe the instantiation of our generic boosting algorithm for the case of using Bayesian networks as our basis of weak learners  and provide experimental results on two distinct data sets, showing that our algorithm achieves higher generalization on unseen data as compared to a single Bayesian network and one particular ensemble of Bayesian networks. We also show that our theoretical criterion for a weak learner to improve the overall model applies well in practice. 2 A density estimation boosting algorithm

At each step   in a boosting algorithm, the model built so far is: ¡£¢¥¤ (

 !

If we now choose a weak learner around the loss at ¡¢¥¤ gives ¨

, then developing the training loss of the new model ©

 

£ S( ¡¢£0 © ( ¡¢£ 4B4U8 ¨

 )(

¡ £ 

 ¡ 4 8

' §¦1 ¢ #

1 1  ¡ 4

( .

 and add it to our8 model with a small coefficient   ¨

in a Taylor series

S( ¡¢£0 ¡¢¥¤ (

 ¡¢£5464 

£ 

¡ ¢¥¤ ¡ ¢¥¤ (

£ ¡ ¢¥¤ (

 ¡ £ 464  ¡ £ 4  ¡¢£54  (

( ¨  4 



which in the case of negative log-likelihood loss can be written as

 G "!$#

¨



H

¡¢¥¤ (

 ¡¢£E4 

£ "©( ( ¡¢£ 464 8

 G %!$#

£ %¡¢¥¤ ( (  ¡ £ 464 G

£  ¡¢£54 ( (

¨  4 

Since  ¨

is small, we can ignore the second order term and choose the next boosting step

¢ tomaximize ' £ &('")1032547698  ¡¢£ 4 (

. We are thus finding the first order optimal weak learner,

which gives the "steepest descent" in the loss at the current model predictions. However,

claimed for this selected ¢ . we should note that once

¨

becomes non-infinitesimal, no "optimality" property can be

The main idea of gradient-based generic boosting algorithms, such as AnyBoost [13] and GradientBoost [7], is to utilize this first order approach to find, at each step, the weak learner which gives good improvement in the loss and then follow the "direction" of this weak learner to augment the current model. The step size # ¢ is determined in various ways in the different algorithms, the most popular choice being line-search, which we adopt here. When we consider applying this methodology to density estimation, where the basis  is comprised of probability distributions and the overall model ¡£¢ is a probability distribution


as well, we cannot simply augment the model, since ¡£¢¥¤

 

# ¢

¢# ¢ will¢# no4 longer¢# be a

8 ( H G

¡¢¥¤

 

¢ ,



probability distribution. Rather, we consider a step of the form ¡ ¢ ¡£¢ ¢

H

where . It is easy to see that the first order theory of gradient boosting and the

line search solution apply to this formulation as well. If at some stage   , the current ¡ ¢¥¤ cannot be improved by adding any of the weak learners  as above, the algorithm terminates, and we have reached a global minimum. This can only happen if the derivative of the loss at the current model with respect to the coefficient of

each weak learnerGWV©XDYnon-negative:

¤  !



 ' £ (B( H"G



is

# ¡¢¥¤ (

#



4  ¡¢£E4   ¡¢£5464 # ( ¥¦D¨¨§ ©

8

& '9)10 £ 

G 

H

¢¥¤

 ¡ 

Thus, the algorithm terminates if no proof and discussion).  gives '

©¡ £

 ¡¢£E4  (

 !  ¡ £ 4 (

(see section 3 for

The resulting generic gradient boosting algorithm for density estimation can be seen in Fig. 1. Implementation details for this algorithm include the choice of the family of weak learners  , and the method for searching for ¢ at each boosting iteration. We address  these details in Section 4.

1. Set

 "!$#

to uniform on the domain of

!

2. For t = 1 to T

(a) Set

%'&)(10324576)83"!3&9#

(b) Find (c) If (d) Find

E &P¨5Q(SR3TVUXW`Ybadc

(e) Set

@ 5BADC

% &@ 5 "! &#GFIH

to maximize

E & % &@ 5 "! &#

break.

5¨(1r0 P5r#r576s8¨tyP¨5@w5

e

E &fehgbi Upqr0 e PQ#r576s83"!4&9#utvP@w5x"!3&9#q#

3. Output the final model



Figure 1: Boosting density estimation algorithm 3 Training data performance The concept of "strength of weak learnability" [6, 18] has been developed in the context of boosting classification models. Conceptually,¨ this property can be described as follows: achieves weighted training error slightly better than random guessing on the re-weighted version of the data using these weights, then the combined boosted learner will have vanishing error on the training data". In classification, this concept is realized elegantly. At each step in the algorithm, the weighted error of the previous model, using the new weights is exactly . Thus, the new weak learner doing "better than random" on the re-weighted data means it can improve the previous weak learner's performance at the current fit, by achieving weighted classification error better than . In fact it is easy to show that the weak learnability condition of at least one weak learner attaining classification error less than on the re-weighted data does not hold only if the current combined model is the optimal solution in the space of linear combinations of weak learners. start with a quantitative description of the performance of the previous weak learner ¢¥¤ We now derive a similar formulation for our density estimation boosting algorithm. We at the combined model ¡ ¢¥¤ , given in the following lemma: 

  )£6¥ §£  "if for any weighting of the training data  ! , there is a weak learner which

¡ 

¡   ¡ 



¤

   '

B£ ' 254 6 8 ©

8

©

Lemma 1 Using the algorithm of section 2 we get: number of training examples. & ' 254 6 8 , where is the


Proof: The line search (step 2(c) in the algorithm) implies:

¡

8

4

'

£ GWV©XDY H G (6( ¥¦P¨X¦



# ¡¢¥¤ (

#



 ¡¢£54   ¡¢£E4B4 # ¢ (

' 8

H

H"G ¢# (

©WG 

 ¡ £ 4

¢ ( 4 

¡¢ ( ¡¢£E4 £

Lemma 1 allows us to derive the following stopping criterion (or optimality condition) for the boosting algorithm, illustrating that in order to improve training set loss, the new weak learner only has to exceed the previous one's performance at the current fit. then8 ¡ ¢ is the global minimum1 in1 the domain of normalized1 linear combinations of  : Proof: This is a direct result of the optimality conditions for a convex function (in this case So unless we have reached the global optimum in the simplex within (which will generally happen quickly only if  is very small, i.e. the "weak" learners are very weak), If this is indeed the case, we can derive an explicit lower bound for training set loss improvement as a function of the new weak learner's performance at the current model: Theorem 2 Assume: 1. The£ sequence of selected weak learners in the algorithm of section 2 has:

 !  ©

Theorem 1 If there does not exist a weak learner  such that ' £ & ' 254 6 8  ¡¢£ 4 (

,

¡¢ ¡£¢ ¥¤§¦©¨ Y

 ¡ ©

' £ G "!$#

( '  1  ¡ £5464D  (    '21  8 H

GWV©XDY

) in a compact domain.

"!    ¥  ©

 ©

we will have some weak learners doing better than "random" and attaining '

h£ & '2542546688 .

¤'

& '")10 254 6 8  ¡¢£E4 8 ¢ ( © $#

©Q£

¢

 ¡¢£ 4   ¡¢£ 464



2.  &%(' "¡¢¥¤ ( (

G V XPY Then we get: '

Proof:



£ "¡( ¢ (

¢ (

¡ £ 4B4

¨ ¢

¢ G ' £ V XPY %¡( ¢¥¤ (  ¡ £ 464 0)21 1 G

¥¦P¨¨§S8 ©

8 

'43§ '

' £ G V XPY H)G (6( # ¡¢¥¤ ( 4  ¡¢£54 



'

GWV©XDY H"G  4

(B(

#

£

# ¡ ¢¥¤ (



#



 ¡ £ 4 

6



 ¡¢£E464 # ¢ (  ¡ £ 464 # ¢ (

G 

¢ ( ¡ ¢¥¤ ( ¡¢¥¤4 (

 ¡¢£ 4  ¡¢£ 4 G  ¡¢£E476

¡ £ 4 8 G #

¢ (

# ¡ ¢¥¤ (

¢ G # 

 ¡ £ 4 

¦

£ ¢

5 

5 H"G

¤CBD"E ¤ 292 89& '9)10 254 6 8GF '(254 6 898 

¦

¢ §

IHQP 9 G

'SR§T '1



¦ £ ¦

 ¡ £ 864 # ¢ (



¢ ¨ ©

¢

Combining these two gives: 9A@

' £ V©XDY %¡( ¢ ( ¡ £ 464 G ' £ V XPY %¡( ¢¥¤ (

¢ 3 '1 ,whichimplies:

§

 ¡ £ 4B4 # VU §  8 G )21§ 1  )21 1 8 G )21 1 ¢ 3 '1 @ G 'W3 ' 'W3§ ' '43§ '

The second assumption of theorem 2 may not seem obvious but it is actually quite mild. With a bit more notation we could get rid of the need to lower bound ¢ completely. For 

¡ ¢ , we can see intuitively that a boosting algorithm will not let any observation have ex-

whelming weight in the next boosting iteration and hence the next selected ¢ is certain to ceptionally low probability over time since that would cause this observation to have overgive it high probability. Thus, after some iterations we can assume that we would actually have a threshold independent of the iteration number and hence the loss would decrease at least as the sum of squares of the "weak learnability" quantities ¢ . 4 Boosting Bayesian Networks We now focus our attention on a specific application of the boosting methodology for density estimation, using Bayesian networks as the weak learners. A Bayesian network is a

¨ #


graphical model for describing a joint distribution over a set of random variables. Recently, there has been much work on developing algorithms for learning Bayesian networks (both network structure and parameters) from data for the task of density estimation and hence they seem appropriate as our choice of weak learners. Another advantage of Bayesian networks in our context, is the ability to tune the strength of the weak learners using parameters

such as number of edges and strength of prior. Assume we have categorical data in a domain   ¡ £ ¥ §£ ¨ 

contains assignments to ¢

(¤£ Find ¢

4  ! ¡

©

  where each of the observations

variables. We rewrite step 2(b) of the boosting algorithm as:

 to maximize ' 4¦¥¨§© 4

¡

 ¡T4 ( , where

©

4 8 ' 4 6 4 ¨

"£

In this formulation, all possible values of have weights, some of which may be .

¡

As mentioned above, the two main implementation-specific details in the generic density estimation algorithm are the set  of weak models and the method for searching for the "optimal" weak model ¢ at each boosting iteration. When boosting Bayesian networks, a natural way of limiting the "strength" of weak learners in  is to limit the complexity of the network structure in  . This can be done, for instance, by bounding the number of edges in each "weak density estimator" learned during the boosting iterations. The problem of finding an "optimal" weak model at each boosting iteration (step 2(b) of the algorithm) is trickier. We first note that if( we only),impose an  constraint on the norm 

of ¢ (specifically, the PDF constraint '

4

 ¡T4"8 H ¡

then step 2(b) has a  trivial solution, ( ¡T4 8 HP  ¡ 8

concentrating all¥ the probability at the value of with the highest "weight":

¡£¢ ¥¤ Y ¡ ¥¨§ © 

. This phenomenon is not limited to the density estimation case and would

appear in boosting for classification if the set of weak learners  had fixed  norm, rather  than the fixed  norm, implicitly imposed by limiting  to contain classifiers. This consequence of limiting  to contain probability distributions is particularly problematic when boosting Bayesian networks, since can be represented with a fully disconnected network. Thus, limiting  to "simple" structures by itself does not amend this problem. However, the boosting algorithm does not explicitly require  to include only probability distributions. Let us consider instead a somewhat different family of candidate models, with an implicit  size constraint, rather than  as in the case of probability distributions 

 

(note that using an  solution would be

constraint as in Adaboost is not possible, since the trivial optimal

H

). For the unconstrained "distribution" case (corresponding to a



fully connected Bayesian network), this leads to re-writing step 2(b) of the boosting algo-

rithm4 as: ¢ (¤£

Find



 to maximize ' 4!¥¨§"© 4  ¡T4 ( , subject to ' 4!¥¨§

  ¡T4 8 H (

By considering the%$# Lagrange multiplier version of this problem it is easy to see that the

optimal solution is

1 ( ¡T4 8

&('

@"02143

) & 1 and is proportional to the optimal solution to the

log-likelihood maximization problem:V ¢

(¤£ 4



Find 4!¥¨§"© 4

%57698 ¡ 4I8 #

to maximize '

&@'

& given by

 0

XPY  ¡T464 ( ( , subject to ' 4¦¥¨§  ¡T4U8 H (

(

. This fact points to an interesting correspondence between

solutions to  -constrained linear optimization problems and  -constrained log optimization problems and leads us to believe that good solutions to step (A£ of the boosting  ¢ 4

¢ 4

algorithm can be approximated by solving step (¤£ instead.

The formulation given in (A£ ¢ 4

presents us with a problem that is natural for Bayesian

@ 02143 0 



network learning,V©XDY of¡T4 maximizing the log-likelihood (or in this case the weighted logOur implementation of the boosting algorithm, therefore, does indeed limit  to include probability distributions only, in this case those that¢ can4 be represented by "simple"  Bayesian4 networks. It solves a constrained version of step (¤£ instead of the original version (¤£ . Note that this use of "surrogate" optimization tasks is not alien to other boosting

likelihood ' 4B© 4 ( ) of the data given the structure.

¢

that


-25.5

doohilekil-goL.gv

-26 Boosting Bayesian Network AutoClass

-26.5

-27

-27.5

doohilekil-goL.gv

A A

-28

-28.5

-24.5 -24.7 -24.9 -25.1 -25.3 -25.5 -25.7 -25.9 -26.1 -26.3 -26.5

Boosting Bayesian Network

1 3 5 7 9 11 31 15 71 91 12 32 52 72 92 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

Boosting Iterations Boosting Iterations

(a) (b)

ytilibanraeL

kae

W

goL

70 60 50 40 30 20 10 0

Training performance Weak Learnability Log (n)

-20 -21 -22 -23 -24 -25 -26 -27

doohilekiL-goL.gv ytilibanraeL

100

80 60

kae

40 20 0

Training performance Weak Learnability Log (n)

W

A goL

-24 -24.2 -24.4 -24.6 -24.8 -25 -25.2 -25.4 -25.6

doohilekiL-goL.gv

A

1 3 5 7 9 11 31 51 71 91 12 32 52 72 92 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

Boosting Iterations

(c)

Boosting Iterations

(d)

Figure 2: (a) Comparison of boosting, single Bayesian network and AutoClass performance on the genomic expression dataset. The average log-likelihood for each test set instance is plotted. (b) Same as (a) for the census dataset. Results for AutoClass were omitted as they were not competitive in this domain (see text). (c) The weak learnability condition is plotted along with training data performance

Up #

for the genomic expression dataset. The plot is in log-scale and also includes

where  

gbi

¡  as a reference

is the number of training instances (d) Same as (c) for the census dataset.

applications as well. For example, Adaboost calls for optimizing a re-weighted classification problem at each step; Decision trees, the most popular boosting weak learners, search for "optimal" solutions using surrogate loss functions - such as the Gini index for CART [3] or information gain for C4.5 [16].

5 Experimental Results We evaluated the performance of our algorithms on two distinct datasets: a genomic expression dataset and a US census dataset. In gene expression data, the level of mRNA transcript of every gene in the cell is measured simultaneously, using DNA microarray technology, allowing researchers to detect functionally related genes based on the correlation of their expression profiles across the various experiments. We combined three yeast expression data sets [10, 12, 19] for a total of 550 expression experiments. To test our methods on a set of correlated variables, we selected 56 genes associated with the oxidative phosphorlylation pathway in the KEGG database [1]. We discretized the expression measurements of each gene into three levels (down, same, up) as in [15]. We obtained the 1990 US census data set from the UC Irvine data repository (http://kdd.ics.uci.edu/databases/census1990/USCensus1990.html). The data set includes 68 discretized attributes such as age, income, occupation, work status, etc. We randomly selected 5k entries from the 2.5M available entries in the entire data set. Each of the data sets was randomly partitioned into 5 equally sized sets and our boosting algorithm was learned from each of the 5 possible combinations of 4 partitions. The performance of each boosting model was evaluated by measuring the log-likelihood achieved on


the data instances in the left out partition. We compared the performance achieved to that of a single Bayesian network learned using standard techniques (see [11] and references therein). To test whether our boosting approach gains its performance primarily by using an ensemble of Bayesian networks, we also compared the performance to that achieved by an ensemble of Bayesian networks learned using AutoClass [4], varying the number of classes from 2 to 100. We report results for the setting of AutoClass achieving the best performance. The results are reported as the average log-likelihood measured for each instance in the test data and summarized in Fig. 2(a,b). We omit the results of AutoClass for the census data as it was not comparable to boosting and a single Bayesian network, achieving an average test instance log-likelihood of . As can be seen, our boosting algorithm performs significantly better, rendering each instance in the test data roughly and times more likely than it is using other approaches in the genomic and census datasets, respectively. To illustrate the theoretical concepts discussed in Section 3, we recorded the performance of our boosting algorithm on the training set for both data sets. As shown in Section 3, set performance. Theorem 2 relates the magnitude of this difference to the amount of improvement in training set performance. Fig. 2(c,d) plots the weak learnability quantity log scale. As can be seen, the theory matches nicely, as the improvement is large when the

¡  ¢¤£¦¥ ¡ ¨§¢ G HP 

  ¢  §

 © if ' £ & ' 254 6 8  ¡¢£ 4 (  , then adding to the model is guaranteed to improve our training

© ' £ & ' 254 6 8  ¡¢£E4 ( , the training set log-likelihood and the threshold for both data sets on a

©

weak learnability condition is large and stops entirely once it asymptotes to . Finally, boosting theory tells us that the effect of boosting is more pronounced for "weaker" weak learners. To that extent, we experimented (data not shown) with various strength parameters for the family of weak learners  (number of allowed edges in each Bayesian network, strength of prior). As expected, the overall effect of boosting was much stronger for weaker learners.

6 Discussion and future work In this paper we extended the boosting methodology to the domain of density estimation and demonstrated its practical performance on real world datasets. We believe that this direction shows promise and hope that our work will lead to other boosting implementations in density estimation as well as other function estimation domains. Our theoretical results include an exposition of the training data performance of the generic algorithm, proving analogous results to those in the case of boosting for classification. Of particular interest is theorem 1, implying that the idealized algorithm converges, asymptotically, to the global minimum. This result is interesting, as it implies that the greedy boosting algorithm converges to the exhaustive solution. However, this global minimum is usually not a good solution in terms of test-set performance as it will tend to overfit (especially if  is not very small). Boosting can be described as generating a regularized path to this optimal solution [17], and thus we can assume that points along the path will usually have better generalization performance than the non-regularized optimum. In Section 4 we described the theoretical and practical difficulties in solving the optimization step of the boosting iterations (step 2(b)). We suggested replacing it with a more easily solvable log-optimization problem, a replacement that can be partly justified by theoretical arguments. However, it will be interesting to formulate other cases where the original problem has non-trivial solutions - for instance, by not limiting  to probability distributions only and using non-density estimation algorithms to generate the "weak" models ¢ .  The popularity of Bayesian networks as density estimators stems from their intuitive interpretation as describing causal relations in data. However, when learning the network


structure from data, a major issue is assigning confidence to the learned features. A potential use of boosting could be in improving interpretability and reducing instability in structure learning. If the weak models in  are limited to a small number of edges, we can collect and interpret the "total influence" of edges in the combined model. This seems like a promising avenue for future research, which we intend to pursue. Acknowledgements We thank Jerry Friedman, Daphne Koller and Christian Shelton for useful discussions. E. Segal was supported by a Stanford Graduate Fellowship (SGF). References [1] Kegg: Kyoto encyclopedia of genes and genomes. In http://www.genome.ad.jp/kegg. [2] C. M. Bishop. Neural Networks for Pattern Recognition. Oxford University Press, Oxford, U.K., 1995. [3] L. Breiman, J.H. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wardsworth International Group, 1984. [4] P. Cheeseman and J. Stutz. Bayesian Classification (AutoClass): Theory and Results. AAAI Press, 1995. [5] R. O. Duda and P. E. Hart. Pattern Classification and Scene Analysis. John Wiley & Sons, New York, 1973. [6] Y. Freund and R.E. Scahpire. A decision theoretic generalization of on-line learning and an application to boosting. In the 2nd Eurpoean Conference on Computational Learning Theory, 1995. [7] J.H. Friedman. Greedy function approximation: A gradient boosting machine. Annals of Statistics, Vol. 29 No. 5, 2001. [8] J.H. Friedman, T. Hastie, and R. Tibshirani. Additive logistic regression: a statistical view of boosting. Annals of Statistics, Vol. 28 pp. 337-407, 2000. [9] N. Friedman and D. Koller. Being bayesian about network structure: A bayesian approach to structure discovery in bayesian networks. Machine Learning Journal, 2002. [10] A.P. Gasch, P.T. Spellman, C.M. Kao, O.Carmel-Harel, M.B. Eisen, G.Storz, D.Botstein, and P.O. Brown. Genomic expression program in the response of yeast cells to environmental changes. Mol. Bio. Cell, 11:4241­4257, 2000. [11] D. Heckerman. A tutorial on learning with Bayesian networks. In M. I. Jordan, editor, Learning in Graphical Models. MIT Press, Cambridge, MA, 1998. [12] T. R. Hughes et al. Functional discovery via a compendium of expression profiles. Cell, 102(1):109­26, 2000. [13] L. Mason, J. Baxter, P. Bartlett, and P. Frean. Boosting algorithms as gradient descent in function space. In Proc. NIPS, number 12, pages 512­518, 1999. [14] M. Meila and T. Jaakkola. Tractable bayesian learning of tree belief networks. Technical Report CMU-RI-TR-00-15, Robotics institute, Carnegie Mellon University, 2000. [15] D. Pe'er, A. Regev, G. Elidan, and N. Friedman. Inferring subnetworks from perturbed expression profiles. In ISMB'01, 2001. [16] J.R. Quinlan. C4.5 - Programs for Machine Learning. Morgan-Kaufmann, 1993. [17] S. Rosset, J. Zhu, and T. Hastie. Boosting as a regularized path to a margin maximizer. Submitted to NIPS 2002. [18] R.E. Scahpire, Y. Freund, P. Bartlett, and W.S. Lee. Boosting the margin: a new explanation for the effectiveness of voting methods. Annals of Statistics, Vol. 26 No. 5, 1998. [19] P. T. Spellman et al. Comprehensive identification of cell cycle-regulated genes of the yeast saccharomyces cerevisiae by microarray hybridization. Mol. Biol. Cell, 9(12):3273­97, 1998. [20] B. Thiesson, C. Meek, and D. Heckerman. Learning mixtures of dag models. Technical Report MSR-TR-98-12, Microsoft Research, 1997. [21] R.S. Zemel and T. Pitassi. A gradient-based boosting algorithm for regression problems. In Proc. NIPS, 2001.


