Self Supervised Boosting

Max Welling, Richard S. Zemel, and Geoffrey E. Hinton Department of Computer Science University of Toronto 10 King's College Road Toronto, M5S 3G5 Canada

Abstract Boosting algorithms and successful applications thereof abound for classification and regression learning problems, but not for unsupervised learning. We propose a sequential approach to adding features to a random field model by training them to improve classification performance between the data and an equal-sized sample of "negative examples" generated from the model's current estimate of the data density. Training in each boosting round proceeds in three stages: first we sample negative examples from the model's current Boltzmann distribution. Next, a feature is trained to improve classification performance between data and negative examples. Finally, a coefficient is learned which determines the importance of this feature relative to ones already in the pool. Negative examples only need to be generated once to learn each new feature. The validity of the approach is demonstrated on binary digits and continuous synthetic data. 1 Introduction While researchers have developed and successfully applied a myriad of boosting algorithms for classification and regression problems, boosting for density estimation has received relatively scant attention. Yet incremental, stage-wise fitting is an attractive model for density estimation. One can imagine that the initial features, or weak learners, could model the rough outlines of the data density, and more detailed carving of the density landscape could occur on each successive round. Ideally, the algorithm would achieve automatic model selection, determining the requisite number of weak learners on its own. It has proven difficult to formulate an objective for such a system, under which the weights on examples, and the objective for training a weak learner at each round have a natural gradient-descent interpretation as in standard boosting algorithms [10] [7]. In this paper we propose an algorithm that provides some progress towards this goal. A key idea in our algorithm is that unsupervised learning can be converted into supervised learning by using the model's imperfect current estimate of the data to generate negative examples. A form of this idea was previously exploited in the contrastive divergence algorithm [4]. We take the idea a step further here by training a weak learner to discriminate between the positive examples from the original data and the negative examples generated by sampling from the current density estimate. This new weak learner minimizes a simple additive logistic loss function [2].


Our algorithm obtains an important advantage over sampling-based, unsupervised methods that learn features in parallel. Parallel-update methods require a new sample after each iteration of parameter changes, in order to reflect the current model's estimate of the data density. We improve on this by using one sample per boosting round, to fit one weak learner. The justification for this approach comes from the proposal that, for stagewise additive models, boosting can be considered as gradient-descent in function space, so the new learner can simply optimize its inner product with the gradient of the objective in function space [3]. Unlike other attempts at "unsupervised boosting" [9], where at each round a new component distribution is added to a mixture model, our approach will add features in the log-domain and as such learns a product model. Our algorithm incrementally constructs random fields from examples. As such, it bears some relation to maximum entropy models, which are popular in natural language processing [8]. In these applications, the features are typically not learned; instead the algorithms greedily select at each round the most informative feature from a large set of pre-enumerated features. 2 The Model Let the input, or state be a vector of £ random variables taking values in some finite domain ¤¦¥ . The probability of § is defined by assigning it an energy, ¨©§ , which is converted into a probability using the Boltzmann distribution,

 ¢¡



©§  ¢!#"%$'& ¨©§)(



1032 4!5"%$6& ¨7©8§9@( (1)

We furthermore assume that the energy is additive. More explicitly, it will be modelled as

a weighted sum of features,

A AEDFA

¨7©8§9 05A ¨ ©§ 0#ACB D A R

A ©8§HGPI 

(2)

ASR

where Q B are theA weights, Q ©UT  the features and each feature may depend on its own

set of parameters I . The model described above is very similar to an "additive random field", otherwise known as "maximum entropy model". The key difference is that we allow each feature to be A flexible through its dependence on the parameters I . Learning in random fields may proceed by performing gradient ascent on the log-

likelihood:

VXW VXY  V V

 & `

0 a bdc¦e ¨7©f VXY b  g 

Y

©§ ¨7©§ VsY 2ihqpr 0 (3)

where f b is a data-vector and is some arbitrary parameter that we want to learn. This

equation makes explicit the main philosophy behind learning in random fields: the energy of states "occupied" by©§data is lowered (weighted by ) while the energy of all states is raised (weighted by ). Since there are usually an exponential number of states in the system, the second term is often approximated by a sample from ©§ . To reduce sampling noise a relatively large sample is necessary and moreover, it must be drawn each time we compute gradients. These considerations make learning in random fields generally very inefficient. Iterative scaling methods have been developed for models that do not include adaptive feature parameters QtI but instead train only the coefficients Q B [8]. These methods make more efficient use of the samples than gradient ascent, but they only minimize a loose bound on the cost function and their terminal convergence can be slow. e

a 

A R A R


3 An Algorithm for Self Supervised Boosting

Boosting algorithms typically implement

 

phases: a feature (or weak learner) is trained,

the relative weight of this feature with respect to the other features already in the pool is determined, and finally the data vectors are reweighted. In the following we will discuss a similar strategy in an unsupervised setting. 3.1 Finding New Features In [7], boosting is reinterpreted as functional gradient descent on a loss function. Using the log-likelihood as a negative loss function this idea can be used to find features for additive random field models. Consider a change in the energy by adding an infinitesimal multiple of a feature. The optimal feature is then the one that provides the maximal increase in log-likelihood, i.e. the feature that maximizes the second term of

W

¢¡

W g DFA

¢¡

©8§9@(

¤£ $ ¨7©8§9@( g

V W V

¡

¥¥¥¥¦¨§c

(4)

V V

Using Eqn. 3 with

©¨

V W V

¡

$ ¨7©8§9 DXA



¥¥¥¥¦¨§c

we rewrite the second term as,

 D A

 & ` 0 a bdc¦e ©8f b  g  2ihqp r 0 ©8§9 ¡ D A

©8§9 (5)

 where ©§ is our current estimate of the data distribution. In order to maximize this

derivative, the feature should therefore be small at the data and large at all other states. It is however important to realize that the norm of the feature must be bounded, since otherwise the derivative can be made arbitrarily large by simply increasing the length of ©§ . Because the total number of possible states of a model is often exponentially large, the second term of Eqn. 5 must be approximated using samples from ©§ ,

D A

§   VXW V



¡ £ ¥¥¥¥¦§c D A & ` 0 a bdc¦e ©f b  g  D A 0 ©§   (6)

c¦e

These samples, or "negative examples", inform us about the states that are likely under the current model. Intuitively, because the model is imperfect, we would like to move its density estimate away from these samples and towards the actual data. By labelling the problem where a new feature is a classifier. Since a good classifier is negative at the data and positive at the negative examples (so we can use its sign to discriminate them), adding its output to the total energy will lower the energy at states where there are data and raise it at states where there are negative examples. The main difference with supervised boosting is that the negative examples change at every round. 3.2 Weighting the Data It has been observed [6] that boosting algorithms can outperform classifications algorithms that maximize log-likelihood. This has motivated us to use the logistic loss function from

data with

  & and the negative examples with   g , we can map this to a supervised

the boosting literature for training new features.

 "!#%$ 

'&(¤)1032¤04 g

5 





Loss C0 

& ) and negative examples (





 g  where runs over data (

(7) ). Perturbing the

energy of the negative loss function by adding an infinitesimal multiple of a new feature:


¡ 

¨ ¨ g

¡ D A and computing the derivative w.r.t. ¡ we derive the following cost function

£  ¥¤  © &   ¨ 

for adding a new feature,

¢

 & 0 a b c e

£ D A



g

0 £

c¦e

 

D A

£

©§ 



b b ©8f   (8)

The main difference with Eqn. 6 is the weights on data and negative examples, that give

poorly "classified" examples (data with very high energy and negative examples with very low energy) a stronger vote in changes to the energy surface. The extra weights (which are bounded between [0,1]) will incur a certain bias w.r.t. the maximum likelihood solution. However, it is expected that the extra effort on "hard cases" will cause the algorithm to converge faster to good density models. It is important to realize that the loss function Eqn. 7 is a valid cost function only when the negative examples are fixed. The reason is that after a change of the energy surface, the negative examples are no longer a representative sample from the Boltzmann distribution in Eqn. 1. However, as long as we re-sample the negative examples after every change in the energy we may use Eqn. 8 as an objective to decide what feature to add to the energy, i.e. we may consider it as the derivative of some (possibly unknown) weighted log-likelihood:

¢ V W ¨§¡ ¦



¦ © §© V c

§

By analogy, we can interpret ©  &

 



§9 

¤ © & ¨7©8§9P as the probability that a certain

state § is occupied by a data-vector and consequently & ¨7©8§9 as the "margin". Note that the introduction of the weights has given meaning to the "height" of the energy surface, in contrast to the Boltzmann distribution for which only relative energy differences count. In fact, as we will further explain in the next section, the height of the energy will be chosen such that the total weight on data is equal to the total weight on the negative examples. 3.3 Adding the New Feature to the Pool According to the functional gradient interpretation, the new feature computed as described above represents the infinitesimal change in energy that maximally increases the (weighted) A log-likelihood. Consistent with that interpretation we will determine B via a line search in the direction of this "gradient". In fact, we will propose a slightly more general change in

energy given by,



A

¨7©§

 

¨7©8§9 g A D A



B A©8§9 g (9)

As mentioned in the previous section, the constant will have no effect on the Boltzmann

distribution in Eqn. 1. However, it does influence the relativeV totalV weight on data versus

negative examples. UsingW the interpretation of A

see that the derivatives of V W

V V W

¦

A

B

w.r.t. to B and1

& 0 a bdc¦e & 0 a

W

bdc¦e

¦

£

D A b

¦

A

in Eqn. 8 as are given by,



b  g

0 £

c

it is not hard to

¢

©8f

W

¦ © ¨§ §¡ ¦

¦ £  c¦e

  D A ©8§  

V

 A 

(10)

b g

A

0 £

c¦e

 (11)

Therefore, at a stationary point of

ples precisely balances out.

A

w.r.t.



the total weight on data and negative exam-



When iteratively updating B we not only change the weights

£

but also the Boltzmann

distribution, which makes the negative examples no longer representative of the current

1 Since

!#"

is independent of

$&%,

it is easy to compute the second derivative

')((02143576 ( 598 5

and we can do Newton updates to compute the stationary point.


3

2.5

2 Error

1.5

Classification 1

%

0.5

0 0 100 200

300 boosting round 400 500 600

Figure 1: (a ­ left). Training error (lower

¡

A

 

curves) and test error (higher

 

curves) for the

weighted boosting algorithm (solid curves) and the un-weighted algorithm (dashed curves). (b ­ right). Features found by the learning algorithm.

 negative examples that are all from iteration to iteration using estimated data distribution. To correct for this weItAinclude importance weights

 

B

 ¢!#" © & B

¢© ¥¢at §¦ 

A

isDFA very easy to update these weights ©8§ FP and renormalizing. It is well

¤£. ¢ 

on the

known that in high dimensions the effective sample size of the weighted sample can rapidly become too small to be useful. We therefore monitor the effective sample size, given by old we have two choices. We can obtain a new set of negative examples from the Aupdated natively, we simply accept the current value of B and proceed to the next round of boosting. the importance of this particular feature, which is not a problem since a similar feature can be added in the next round. 4 A Binary Example: The Generalized RBM We propose a simple extension of the "restricted Boltzmann machine" (RBM) withA (+1,-



©¨©  ¢

, where the sum runs over the negative examples only. If it drops below a thresh-





Boltzmann distribution, reset the importance weights to

A

© and resume fitting B . Alter-

A Because we initialize B 

£

in the fitting procedure, the latter approach underestimates

1)-units [1] as a model for binary data. Each feature is parametrized by weights

bias :

A D A A

B ©§ & B

"!#©A ! ¡© 

A

 

Y

§ g A



Y A

¡

and a (12)

where the RBM is obtained by setting all B . One can sample from the summed

energy model using straightforward Gibbs sampling, where every visible unit is sampled given all the others. Alternatively, one can design a much faster mixing Markov chain by introducing hidden variables and sampling all hidden units independently given the visible A units and vice versa. Unfortunately, by including the coefficients B this trick is no longer

valid. But an approximate MarkovA chainY can be used A

B § g A



"!#© ! ¡©  £ ! ©# !"! ¡

A A

© B § g A A Y

B  (13)

This approximate Gibbs sampling thus involves sampling from an RBM with scaled weights and biases,



$# A § A A A A Y '& §(

 

10& A A A

©   §

¥¤ $  ¡%  

© B § g B   ¡ © 

¤ ) 

© 0 A B

#

 (14)

When using the above Markov chain, we will not wait until it has reached equilibrium but initialize it at the data-vectors and use it for a fixed number of steps, as is done in contrastive divergence learning [4].


When we fit a new feature we need to make sure its norm is controlled. The appropriate value depends on the number of dimensions in the problem; in the experiment described

below we boundedA the norm of Athe vector $  Y

A

Y

are thus given by

¦¡ £¢A

0



£

g A

   ¦©¡%A 

¤¦¥¨§



§

£

 

and

Y A

 

g E§ 

A Y

¡ ¤¡ ¦¡ A 

A



¡ to be no larger than Y(

A

¦

Y

¦©¢

A

with,

0



£

£ ©

g . The updates

Y g A

    ¡%©  ¤¥¨§ A

§

A

 (15)

where the weights

¤   

are proportional to © & ¨  . The coefficients B are determined

using the procedure of Section 3.3.

To test whether we can learn good models of (fairly) high-dimensional, real-world data, we used the real-valued digits from the "br" set on the CEDAR cdrom # . We learned  



completely separate models on binarized "2"s and "3"s. The first

class were used for training while the remaining 

£ £

£ £

data cases of each

digits of each class were used for test-

A 

7

ing. The minimum effective sample size for the coefficients B D was set toA A

different sets of negative examples, examples each, to fit

£ £



©ET  and B . After a new fea-

£

. We used

 

ture was added, the total energies of all "2"s and "3"s were computed under both models. The energies of the training data (under both models) were used as two-dimensional features to compute a separation boundary using logistic regression, which was subsequently applied to the test data to compute the total misclassification. In Figure 1a we show the total error on both training data and test data as a function of the number of features in the model. For comparison we also plot the training and test error for the un-weighted version of the

£

algorithm (





weighted algorithm is about

neighbors ( & units achieves



££

¡! ). The" classification error after

£ ©

£ £

rounds of boosting for the

, and only very gradually increases to about

 after

rounds of boosting.isThis is good as compared to logistic regression (

©£ 5

  ©%#

£ ©¡£ £ © £¡©



' ¡ $# ¡ (



optimal), while a parallel-trained RBM with 



0)A 

" respectively. The un-weightedlearning algorithm con-

£ ££   £k-nearest

¡ ¡), hidden



£ ©$#£

verges much more slowly to aA good solution, both on training and test data. In Figure 1b we show every feature between rounds and for both digits. 5 A Continuous Example: The Dimples Model For continuous data we propose a different form of feature, which we term a dimple because of its shape in the energy domain. A dimple is a mixture of a narrow Gaussian and a broad



Gaussian, with a common mean:

D A

©§  &

"!# $ ©§3G 1 32 ¡ ¤ e  g 1 42 ¡ ©8§HG



 £ £

of the algorithm fits 2 and ¤

e

¤

¤

for a new learner. A nice property of dimples is that they can



)( (16)

where the mixing proportion is constant and equal, and is fixed and large. Each round

reduce the entropy of an existing distribution by placing the dimple in a region that already has low energy, but they can also raise the entropy by putting the dimple in a high energy

region [5].

A

Sampling is again simple if all B 

 , since in that case we can use a Gibbs chain which

first picks a narrow or broad Gaussian for every feature given the visible variables and then samples the visible variables from the resulting multivariate Gaussian. For general B the situation is less tractable, but using a similar approximation as for the generalized RBM,

B

"!#

$ ©§3G 1 32 ¡

¤

e  g 1 42 ¡ ©8§HG

¤ ¤£ "!#



@( $ ©8§HG 1 42 ¡ 35 e

¤

g 1 42 ¡ 35 ©8§HG

¤



( (17)

This approximation will be accurate when one Gaussian is dominating the other, i.e., when the responsibilities are close to zero and one. This is expected to be the case in highdimensional applications. In the low-dimensional example discussed below we implemented a simple MCMC chain with isotropic, normal proposal density which was initiated at the data-points and run for a fixed number of steps.


25 25

20 20

15 15

10 10

5 5

(a) 0 (c) 0

-5 -5

-10 -10

-15 -15

-20 -20

-25 -40 -30 -20 -10 0 10 20 30 40 -25 -40 -30 -20 -10 0 10 20 30 40

5

0

-5

-10

-15

(b) -20 30 (d)

20

10

0

-10

-20

10 20 30 40 -30

-10 0

0 -20 -40 -60 -80 -100 25 20 15 10 5 0 -5 -10 -15 -20 -25

-30 -20 -20 -10 10 20 30 40 -30 0 -40 -40

Figure 2: (a). Plot of iso-energy contours after

 !££

rounds of boosting. The crosses rep-

resent the data and the dots the negative examples generated from the model. (b). Three

dimensional plot of the negative energy surface. (c). Contour plot for a mixture of

Gaussians learned using EM. (d). Negative energy surface for the mixture of

  £

Gaussians.

£ 

The type of dimple we used in the experiment below can adapt a common mean ( ) and

rules are given by,

the inverse-variance of theg smalland

¦2 ©¦

g

& ¢

0

§&

¡ £¡  ¦¡ ¢ ¤¢  ¦¢¦¨

Gaussian (

e

¦§& & §© §& § §§&&4

e e )g in each dimension separately. The update e

2 4© e

with e

g

¨ ©  ©©



(18) (19)

¢ ¡



£

e

   ¦¥© 

£ ¢

& 0

¨  ©

e 

1

e



 ¨  $ ¦¥© 

e

&

§ ¦§& &

& 2  & 

where

§

e

#©

1

e

1

and broad Gaussian respectively and the weights are given by

the combination coefficients

 

 and A



¨  ¨ 

  & e

§ §

are the responsibilities for the narrow

 © & ¨  . Finally,

£

 ¤   

are computed as described in Section 3.3.

To illustrate the proposed algorithm we fit the dimples model to the two-dimensional data

(crosses) shown in Figure 2a-c. The data were synthetically generated bywith 

with uniform between $ ¡ ( and a radius  g

  "! ! £ ¨ £ #

defining angles

standard

normal, which were converted to Euclidean coordinates and mirrored and translated to produce the spirals. The first feature is an isotropic Gaussian with the mean and the variance of the data, while later features were dimples trained in the way described above. Figure 2a ples (dots) from the model. A 3-dimensional plot of the negative energy surface is shown in

also shows the contours of equal energy after

 !££ rounds of boosting together with exam-

Figure 2b. For comparison, similar plots for a mixture of with EM, are depicted in Figures 2c and 2d.

£ 

Gaussians, trained in parallel

The main qualitative difference between the fits in Figures 2a-b (product of dimples) and


2c-d (mixture of Gaussians), is that the first seems to produce smoother energy surfaces, only creating structure where there is structure in the data. This can be understood by recalling that the role of the negative examples is precisely to remove "dips" in the energy surface where there is no data. The philosophy of avoiding structure in the model that is not dictated by the data is consistent with the ideas behind maximum entropy modelling [11] and is thought to improve generalization. 6 Discussion This paper discusses a boosting approach to density estimation, which we formulate as a sequential approach to training additive random field models. The philosophy is to view unsupervised learning as a sequence of classification problems where the aim is to discriminate between data-vectors and negative examples generated from the current model. The sampling step is usually the most time consuming operation, but it is also unavoidable since it informs the algorithm of the states whose energy is too low. The proposed algorithm uses just one sample of negative examples to fit a new feature, which is very economical as compared to most non-sequential algorithms which must generate an entire new sample for every gradient update. There are many interesting issues and variations that we have not addressed in this paper. What is the effect of using approximate, e.g. variational distributions for ©§ ? Can we improve the accuracy of the model by fitting the feature parameters and the coefficients B together? Does re-sampling the negative examples more frequently during learning improve the final model? What is the effect of using different functions to weight the data and how do the weighting schemes interact with the dimensionality of the problem? References [1] Y. Freund and D. Haussler. Unsupervised learning of distributions of binary vectors using 2-layer networks. In Advances in Neural Information Processing Systems, volume 4, pages 912­919, 1992. [2] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic regression: A statistical view of boosting. Technical report, Dept. of Statistics, Stanford University Technical Report., 1998. [3] J.H. Friedman. Greedy function approximation: A gradient boosting machine. Technical report, Technical Report, Dept. of Statistics, Stanford University, 1999. [4] G.E. Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14:1771­1800, 2002. [5] G.E. Hinton and A. Brown. Spiking Boltzmann machines. In Advances in Neural Information Processing Systems, volume 12, 2000. [6] G. Lebanon and J. Lafferty. Boosting and maximum likelihood for exponential models. In Advances in Neural Information Processing Systems, volume 14, 2002. [7] L. Mason, J. Baxter, P. Bartlett, and M. Frean. Boosting algorithms as gradient descent. In Advances in Neural Information Processing Systems, volume 12, 2000. [8] S. Della Pietra, V.J. Della Pietra, and J.D. Lafferty. Inducing features of random fields. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(4):380­393, 1997. [9] S. Rosset and E. Segal. Boosting density estimation. In Advances in Neural Information Processing Systems, volume 15 (this volume), 2002. [10] R.E. Schapire and Y. Singer. Improved boosting algorithms using confidence-rated predictions. In Computational Learing Theory, pages 80­91, 1998. [11] S.C. Zhu, Z.N. Wu, and D. Mumford. Minimax entropy principle and its application to texture modeling. Neural Computation, 9(8):1627­1660, 1997.



A


