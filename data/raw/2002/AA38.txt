A Differential Semantics for Jointree Algorithms

James D. P ark and Adnan Darwiche Computer Science Department Univ ersity of California, Los Angeles, CA 90095 {jd,darwiche}@cs.ucla.edu

Abstract A new approach to inference in belief networks has been recently proposed, which is based on an algebraic representation of belief networks using multi­linear functions. According to this approach, the key computational question is that of representing multi­linear functions compactly, since inference reduces to a simple process of ev aluating and differentiating such functions. W e show here that mainstream inference algorithms based on jointrees are a special case of this approach in a v ery precise sense. W e use this result to prov e new properties of jointree algorithms, and then discuss some of its practical and theoretical implications.

1 Introduction

It was recently shown that the probability distribution of a belief network can be represented using a multi­linear function, and that most probabilistic queries of interest can be retriev ed directly from the partial deriv ativ es of this function [2]. Although the multi­linear function has an exponential number of terms, it can be represented using a small arithmetic circuit in certain situations [3].1 Once a belief network is represented as an arithmetic circuit, probabilistic inference is then performed by ev aluating and differentiating the circuit, using a v ery simple procedure which resembles back­propagation in neural networks. W e show in this paper that mainstream inference algorithms based on jointrees [14, 8] are a special-case of the arithmetic­circuit approach proposed in [2]. Specifically, we show that each jointree is an implicit representation of an arithmetic circuit; that the inward­pass in jointree propagation ev aluates this circuit; and that the outward­ pass differentiates the circuit. Using these results, we prov e new useful properties of jointree propagation. W e also suggest a new interpretation of the process of factoring graphical models into jointrees, as a process of factoring exponentially­ sized multi­linear functions into arithmetic circuits of smaller size.

1 For example, it was shown recently that real­world b elief networks with treewidth up

to 60 can b e compiled into arithmetic circuits with few thousand nodes [3]. Such networks hav e local structure, and are outside the scope of mainstream algorithms for inference in b elief networks whose complexity is exponential in treewidth.


A true true false false B true false true false

b |a ¯ b|a |a b|a

b ¯

¯ ¯

= .2 = .8 = .7 = .3 A true false

a = .6 a = .4 ¯

A true true false false C true false true false

c = .8 |a

c¯|a = .2 c = .15 c¯|a = .85 ¯

|a ¯

Figure 1: The CPTs of belief network B  A  C.

This paper is structured as follows. Sections 2 and 3 are dedicated to a review of inference approaches based on arithmetic circuits and jointrees. Section 4 shows that the jointree approach is a special case of the arithmetic­circuit approach, and discusses some practical implications of this finding. Finally, Section 5 closes with a new perspective on factoring graphical models. Proofs of all theorems can be found in the long version of this paper [11]. 2 Belief netw orks as m ulti­linear functions A belief network is a factored representation of a probability distribution. It consists of two parts: a directed acyclic graph (D A G) and a set of conditional probability tables (CPTs). For each node X and its parents U, we have a CPT that specifies the distribution of X given each instantiation u of the parents; see Figure 1.2 A belief network is a representational factorization of a probability distribution, not a computational one. That is, although the network compactly represents the distribution, it needs to be processed further if one is to obtain answers to arbitrary probabilistic queries. Mainstream algorithms for inference in belief networks operate on the network to generate a computational factorization, allowing one to answer queries in time which is linear in the factorization size. A most influential computational factorization of belief networks is the jointree [14, 8, 6]. Standard jointree factorizations are structure­based: their size depend only on the network topology and is invariant to local CPT structure. This observation has triggered much research for alternative, finer­grained factorizations, since real-world networks can exhibit significant local structure that leads to smaller factorizations if exploited. W e discuss next one of the latest proposals in this direction, which calls for using arithmetic circuits as a computational factorization of belief networks [2]. This proposal is based on viewing each belief network as a multi­linear function, which can be represented compactly using an arithmetic circuit. The multi­linear function itself contains two types of variables. First, evidence indicators, where for each variable X in the network , we have a variable x for each value x of X. Second, network parameters, where for each variable X and its parents U in the network, The multi­linear function has a term for each instantiation of the network variables, which is constructed by multiplying all evidence indicators and network parameters that are consistent with that instantiation. For example, the multi­linear function of the network in Figure 1 has eight terms corresponding to the eight instantiations W e will often refer to such a multi­linear function as the network polynomial.

we have a variable x |u for each value x of X and instantiation u of U.

of variables A, B, C: f = abcab |a c |a +abc¯ab |a c¯|a+. . .+a¯¯bc¯a¯¯b  |a ¯ c¯|a ¯ .

2 Variables are denoted by upper­case letters (A) and their v alues by lower­case letters

(a). Sets of v ariables are denoted by bold­face upper­case letters (A) and their instantiations are denoted by bold­face lower­case letters (a). For a v ariable A with v alues true and false, we use a to denote A= true and a to denote A= false. Finally , for a v ariable X ¯

and its parents U, we use x |u to denote the CPT entry corresponding to Pr (x | u).


+

* * A

BDD|BC BCD

+ +

B C

* * * *

D E

ABC AAB|AC|A CE CEE|C

tA qA qBDA tB qBDA qBDA tB qBDA qA tA

Figure 2: On the left:

abab |a + a¯ba¯b |a

An arithmetic circuit which computes the function

+ aba ¯ ¯ b|a ¯ + a¯ba¯b ¯ ¯ |a ¯ . The circuit is a D AG, where

leaf nodes represent function variables and internal nodes represent arithmetic operations. On the right: A belief network structure and its corresponding jointree.

Given the network polynomial f, we can answer any query with respect to the belief network. Specifically, let e be an instantiation of some network variables, and suppose we want to compute the probability of e. W e can do this by simply evaluating the polynomial f while setting each evidence indicator x to 1 if x is consistent with e, and to 0 otherwise. For the network in Figure 1, we can compute the probability of evidence e = bc¯ by evaluating its polynomial above under which equals the probability of b, c¯ in this case. W e use f(e) to denote the result of evaluating the polynomial f under evidence e as given above. This algebraic representation of belief networks is attractive as it allows us to obtain answers to a large number of probabilistic queries directly from the derivatives of the network polynomial [2]. For example, the posterior marginal Pr(x|e) for a evaluated at e. Second, the probability of evidence e after having retracted the value of some variable X from e, Pr(e - X), equals . Third, the posterior

a = 1,a = 1,b = 1, ¯b = 0 and c = 0, c = 1. This leads to ab ¯ ¯ |a c ¯|a +a ¯ b|a ¯ c¯|a  ¯ ,

variable X  E equals

1  f (e)

, where is the partial derivative of f wrt x

f (e)  x

 f (e)  x

x

 f (e)  x

x

marginal Pr(x, u|e) for a variable X and its parents U equals

|u  f (e)

.

f (e)  x |u

The network polynomial has an exponential number of terms, yet one can represent it compactly in certain cases using an arithmetic circuit; see Figure 2. The (first) partial derivatives of an arithmetic circuit can all be computed simultaneously in time linear in the circuit size [2, 12]. The procedure resembles the back­propagation algorithm for neural networks as it evaluates the circuit in a single upward­pass, and then differentiates it through a single downward­pass. The main computational question is then that of generating the smallest arithmetic circuit that computes the network polynomial. A structure­based approach for this has been given in [2], which is guaranteed to generate a circuit whose size is bounded by O(n exp(w)), where n is the number of nodes in the network and w is its treewidth. A more recent approach, however, which exploits local structure has been presented in [3] and was shown experimentally to generate small arithmetic circuits for networks whose treewidth is up to 60. As we show in the rest of this paper, the process of factoring a belief network into a jointree is yet another method for generating an arithmetic circuit for the network. Specifically, we show that the jointree structure is an implicit representation of such a circuit, and that jointree propagation corresponds to circuit evaluation and differentiation. Moreover, the difference between Shenoy­Shafer and Hugin propagation turns out to be a difference in the numeric scheme used for circuit differentiation [11].


3 Join tree Algorithms

We now review jointree algorithms, which are quite influential in graphical models. Let B be a belief network. A jointree for B is a pair (T , L), where T is a tree and L is a function that assigns labels to nodes in T . A jointree must satisfy three properties: (1) each label L(i) is a set of variables in the belief network; (2) each network variable X and its parents U (a family) must appear together in some label L(i); (3) if a variable appears in the labels of i and j, it must also appear in the label of each node k on the path connecting them. The label of edge ij in T is defined as L(i)  L(j). We will refer to the nodes of a jointree (and sometimes their labels) as clusters. We will also refer to the edges of a jointree (and sometimes their labels) as separators. Figure 2 depicts a belief network and one of its jointrees. Jointree algorithms start by constructing a jointree for a given belief network [14, 8, 6]. They also associate tables (also called potentials) with clusters and separators.3 The conditional probability table (CPT or CP Table) of each variable X with parents U, denoted X|U, is assigned to a cluster that contains X and U. In addition, an evidence table over variable X, denoted X, is assigned to a cluster that contains X. Figure 2 depicts the assignments of evidence and CP tables to clusters. Evidence e is entered into a jointree by initializing evidence tables as follows: we set X(x) to 1 if x is consistent with evidence e, and we set X(x) to 0 otherwise. Given some evidence e, a jointree algorithm propagates messages between clusters. After passing two message per edge in the jointree, one can compute the marginals Pr(C, e) for every cluster C. There are two main methods for propagating messages in a jointree: the Shenoy­Shafer architecture [14] and the Hugin architecture [8]. Shenoy­Shafer propagation proceeds as follows [14]. First, evidence e is then entered into the jointree. A cluster is then selected as the root and message propagation proceeds in two phases, inward and outward. In the inward phase, messages are passed toward the root. In the outward phase, messages are passed away from the root. Cluster i sends a message to cluster j only when it has received messages from all its other neighbors k. A message from cluster i to cluster j is a table Mij i, S are the variables of separator ij, and i is the multiplication of all evidence and CP tables assigned to cluster i. Once message propagation is finished, we have Pr(C, e) = i Mki, where C are the variables of cluster i. Hugin propagation proceeds similarly to Shenoy­Shafer by entering evidence; selecting a cluster as root; and propagating messages in two phases, inward and outward [8]. The Hugin method, however, differs in some major ways. It maintains a table ij with each separator, whose entries are initialized to 1s. It also maintains a table i with each cluster i, initialized to the multiplication of all CPTs and evidence tables assigned to cluster i. Cluster i passes a message to neighboring cluster j only when i has received messages from all its other neighbors k. When cluster i is ready to send a message to cluster j, it does the following. First, it saves the table of where C are the variables of cluster i and S are the variables of separator ij. Third,

defined as follows: Mij = C\S i Mki, where C are the variables of cluster k=j

k

separator ij into old. Second, it computes a new separator table ij = ij C\S i,

it computes a message to cluster j: Mij = ij old

ij

message into the table of cluster j: j = jMij. After the inward and outward­ passes of Hugin propagation are completed, we have: Pr(C, e) = i, where C are the variables of cluster i.

3 A table is an array which is indexed by v ariable instantiations. Sp ecifically , a table 

. Finally, it multiplies the computed

ov er v ariables X is indexed by the instantiations x of X. Its entries (x) are in [0, 1].


4 Join trees as arithmetic circuits

We now show that every jointree (together with a root cluster and a particular assignment of evidence and CP tables to clusters) corresponds precisely to an arithmetic circuit that computes the network polynomial. We also show that the inward­ pass of the Shenoy­Shafer architecture evaluates this circuit, while the outward­pass differentiates it. We show a similar result for the Hugin architecture. Definition 1 Given a root cluster, a particular assignment of evidence and CP tables to clusters, the arithmetic circuit embedded in a jointree is defined as follows:4 Nodes: The circuit includes: an output addition node f; an addition node s for each instantiation of a separator S; a multiplication node c for each instantiation of a cluster C; an input node x for each instantiation x of variable X; an input node Edges: The children of the output node f are the multiplication nodes generated by the root cluster; the children of an addition node s are all compatible nodes generated by the child cluster; the children of a multiplication node c are all compatible nodes generated by child separators, and all compatible input nodes assigned to cluster C. Hence, separators contribute addition nodes and clusters contribute multiplication nodes. Moreover, the structure of the jointree dictates how these nodes are connected into a circuit. The arithmetic circuit in Figure 2 is embedded in the jointree A - AB, with cluster A as the root, and with tables A, A assigned to cluster A

x |u for each instantiation xu of family XU.

and tables B and B

Theorem

|A

assigned to cluster B.

1 The circuit embedded in a jointree computes the network polynomial.

Therefore, by constructing a jointree one is generating a compact representation of the network polynomial in terms of an arithmetic circuit. We are now ready to state our basic results on the differential semantics of jointree propagation, but we need some notational conventions first. In the following three theorems: f denotes the circuit embedded in a jointree or its (unique) output node; s denotes a separator instantiation or the addition node generated by that instantiation; and c denotes a cluster instantiation or the multiplication node generated by that instantiation. Moreover, the value that a circuit node v tak es under evidence e is denoted v(e). Recall that a circuit (or network polynomial) is evaluated under evidence e by setting each input x to 1 if x is consistent with e; and to 0 otherwise. Finally, recall that  f/ v represents the derivative of the circuit output with respect to node v. Our first result relates to Shenoy­Shafer propagation. Theorem 2 The messages produced using Shenoy­Shafer propagation on a jointree under evidence e have the following semantics. F or each inward message Mij, we

have Mij(s) = s(e). F or each outward message Mji, we have Mji(s) = f (e) s .

Hence, if we interpret separator instantiations as addition nodes in a circuit as given by Definition 1, we get that a message directed towards the jointree root contains the values of these addition nodes, while a message directed outward from the root contains the partial derivatives of the circuit output with respect to these nodes. Shenoy­Shafer propagation does not compute derivatives with respect to input

nodes x and x

4

|u , but these can be obtained using local computations as follows.

Given a root cluster, one can direct the jointree b y having arrows point away from the

root, which also defines a parent/child relationship b etween clusters and separators.


Theorem 3 If evidence table X is assigned to cluster i with variables C:

 f (e)  x =  C

Mji

\X j =X

 (x), 

(1)

where  ranges over all evidence and CP tables assigned to cluster i. Moreover, if

CPT X |U is assigned to cluster i with variables C:

 f (e)

 x |u

=

 C

Mji

\XU j =X |U

 (xu), 

(2)

where  ranges over all evidence and CP tables assigned to cluster i. Therefore, even though Shenoy­Shafer propagation does not fully differentiate the embedded circuit, the differentiation process can be completed through local computations after propagation has finished.5 W e now discuss some applications of the partial derivatives with respect to evidence

indicators x and network parameters x

F ast retraction &

|u .

evidence flipping. Suppose jointree propagation has been

performed using evidence e, which gives us access directly to the probability of e. Suppose now we are interested in the probability of a different evidence e , which results from changing the value of some variable X in e to a new value x. The by Equation 1. The ability to perform this computation efficiently is crucial for algorithms that try to approximate maximum aposteriori hypothesis (MAP) using local search [9, 10]. Another application of this derivative is in computing the probability of evidence e , which results from retracting the value of some variable X from e: Pr (e ) = . This computation is k ey to analyzing evidence conflict, as it allows us to determine the extent to which one piece of evidence is contradicted by the remaining pieces.

probability of e in this case is equal to f (e) x [2], which can be obtained as given

x

f (e) x

Sensitivity analysis & parameter learning. The derivative

Pr (e)

x |u

is essen-

tial for sensitivity analysis--it is the basis for an efficient approach that identifies minimal network parameters changes that are necessary to satisfy constraints on probabilistic queries [1]. This derivative is also crucial for gradient ascent approaches for learning network parameters as it is required to compute the gradient

5 Hugin propagation also corresponds to circuit ev aluation/differentiation:

Theorem 4 Cluster tables, separator tables and messages produced using Hugin propaga-

tion under evidence e have the following semantics: F or table i of cluster i with variables C: i(c) = c(e) fc . F or table ij of separator ij with variables S: ij(s) = s(e) fs .

(e) (e)

F or each inward message Mij, we have Mij(s) = s(e). F or each outward message Mji, we Again, Hugin propagation does not compute deriv ativ es with respect to input nodes x by v alues. Hence, if we want to recov er the deriv ativ e with respect to, say, multiplication node c, we must know the v alue of this node and it must be different than zero. In such a case, we hav e f(e)/c = i(c)/c(e), where i is the table associated with the cluster i that generates node c. One can also compute the quantity v f/v for input nodes using equations similar to those in Theorem 3. But such quantities will be useful for obtaining deriv ativ es only if the v alues of such input nodes are not zero. Hence, Shenoy­Shafer propagation is more informativ e than Hugin propagation as far as the computation of deriv ativ es is concerned.

have Mji(s) = f (e) s if s(e) = 0.

and x |u . Ev en for addition and multiplication nodes, it only retains deriv ativ es multiplied


used for deciding moves in the search space [13]. This derivative equals

can be obtained as given by Equation 2.

f (e)

x |u

, and

The only other method we are aware

of to compute this derivative (beyond the one in [2]) is the one using the identity seem to suggest the first general approach for computing this derivative using standard jointree propagation. Bounding rounding errors. Jointree propagation gives exact results only when infinite precision arithmetic is used. In practice, however, finite precision floating­ point arithmetic is typically used, in which case the differential semantics of jointree propagation can be used to bound the rounding error in the computed probability of evidence. See the full paper [11] for details on computing this bound.

Pr (e)/x |u = Pr(x, u, e)/x |u , which requires x |u = 0 [13]. Hence, our results

5 A new perspectiv e on factoring graphical models

W e have shown in this paper that each jointree can be viewed as an implicit representation of an arithmetic circuit which computes the network polynomial, and that jointree propagation corresponds to an evaluation and differentiation of the circuit. These results have been useful in unifying the circuit approach presented in [2] with jointree approaches, and in uncovering more properties of jointree propagation. Another outcome of these results relates to the level at which it is useful to phrase the problem of factoring graphical probabilistic models. Specifically, the perspective we are promoting here is that probability distributions defined by graphical models should be viewed as multi­linear functions, and the construction of jointrees should be viewed as a process of constructing arithmetic circuits that compute these functions. That is, the fundamental object being factored is a multi­linear function, and the fundamental result of the factorization is an arithmetic circuit. A graphical model is a useful abstraction of the multi­linear function, and a jointree is a useful structure for embedding the arithmetic circuit. This view of factoring is useful since it allows us to cast the factoring problem in more refined terms, which puts us in a better position to exploit the local structure of graphical models in the factorization process. Note that the topology of a graphical model defines the form of the multi­linear function, while the model's local structure (as exhibited in its CPTs) constrains the values of variables appearing in the function. One can factor a multi­linear function without knowledge of such constraints, but the resulting factorizations will not be optimal. For a dramatic example, consider a fully connected network with variables X1, ..., Xn, where all n, leading to O(exp(n)) complexity. There is, however, a circuit of O(n) size here, Hence, in the presence of local structure, it appears more promising to factor the graphical model into the more refined arithmetic circuit since not every arithmetic circuit can be embedded in a jointree. This promise is made apparent by the results in [3], which we sketch next. First, the multi­linear function of a belief network is "encoded" using a propositional theory, which is expressive enough to capture the form of the multi­linear function in addition to constraints on its variables. The theory is then compiled into a special logical form, known as deterministic decomposable negation normal form. An arithmetic circuit is finally extracted from that form. The method was able to generate relatively small arithmetic circuits for a significant suite of real­world belief networks with treewidths up to 60. It is worth mentioning here that the above perspective is in harmony with recent

parameters are equal to 1 2 . Any jointree for the network will have a cluster of size

since the network polynomial can be easily factored as: f = ( 2 ) 1 n n i=1 (xi + x ). ¯i


approaches that represent probabilistic models using algebraic decision diagrams (ADDs), citing the promise of ADDs in exploiting local structure [5]. ADDs and related representations, such as edge­v alued decision diagrams, are known to be compact representations of multi­linear functions. Moreov er, each of these representations can be expanded in linear time into an arithmetic circuit that satisfies some strong properties [4]. Hence, such representations are special cases of arithmetic circuits as well. W e finally note that the relationship between multi­linear functions (polynomials in general) and arithmetic circuits is a classical subject of algebraic complexity theory [15]. In this field of complexity, computational problems are expressed as polynomials, and a central question is that of determining the size of the smallest arithmetic circuit that computes a giv en polynomial, leading to the notion of circuit complexity. Using this notion, it is then meaningful to talk about the circuit complexity of a graphical model: the size of the smallest arithmetic circuit that computes the multi­linear function induced by the model.

Ackno wledgment This work has been partially supported by NSF 9988543 and MURI grant N00014-00-1-0617. References

[1] H. Chan and A. Darwiche. When do numbers really matter? 2002.

grant IIS-

JAIR, 17: 265­287,

[2] A. Darwiche. A differential approach to inference in Bay esian networks. In UAI'00, pages 123­132, 2000. T o appear in JACM. [3] A. Darwiche. A logical approach to factoring belief networks. In KR'02, pages 409­ 420, 2002. [4] A. Darwiche. On the factorization of multi­linear functions. T echnical Report D­128, UCLA, Los Angeles, Ca 90095, 2002. [5] J. Hoey, R. St-Aubin, A. Hu, and G. Boutilier. SPUDD: Stochastic planning using decision diagrams. In UAI'99, pages 279­288, 1999. [6] C. Huang and A. Darwiche. Inference in belief networks: A procedural guide. IJAR, 15(3): 225­263, 1996. [7] M. Iri. Simultaneous computation of functions, partial deriv ativ es and estimates of rounding error. Japan J. Appl. Math., 1:223­252, 1984. [8] F. V. Jensen, S.L. Lauritzen, and K.G. Olesen. Bay esian updating in recursiv e graphical models by local computation. Comp. Stat. Quart., 4:269­282, 1990. [9] J. Park. MAP complexity results and approximation methods. In UAI'02, pages

388­396, 2002. [10] J. Park and A. Darwiche.

Approximating MAP using stochastic local search. In

UAI'01, pages 403­410, 2001. [11] J. Park and A. Darwiche. A differential semantics for jointree algorithms. T echnical Report D­118, UCLA, Los Angeles, Ca 90095, 2001. [12] G. Rote. Path problems in graphs. Computing Suppl., 7:155­189, 1990. [13] S. Russell, J. Binder, D. Koller, and K. Kanazawa. Local learning in probabilistic networks with hidden v ariables. In UAI'95, pages 1146­1152, 1995. [14] P. P. Shenoy and G. Shafer. Propagating belief functions with local computations. IEEE Expert, 1(3):43­52, 1986. [15] J. v on zur Gathen. Algebraic complexity theory. Ann. Rev. Comp. Sci., 3:317­347, 1988.


