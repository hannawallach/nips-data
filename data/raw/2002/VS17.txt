How to Combine Color and Shape
Information for 3D Object Recognition:
Kernels do the Trick
B. Caputo
Smith-Kettlewell Eye Research Institute,
2318 Fillmore Street,
94115 San Francisco, California, USA
caputo@ski.org
Gy. Dorko
Department of Computer Science,
Chair for Pattern Recognition,
University of Erlangen-Nuremberg,
dorko@informatik.uni-erlangen.de
Abstract
This paper presents a kernel method that allows to combine color
and shape information for appearance-based object recognition. It
doesn't require to dene a new common representation, but use the
power of kernels to combine dierent representations together in an
eective manner. These results are achieved using results of statis-
tical mechanics of spin glasses combined with Markov random elds
via kernel functions. Experiments show an increase in recognition
rate up to 5.92% with respect to conventional strategies.
1 Introduction
Consider the two cars in Figure 1. They look very similar, but this wouldn't be
the case if we would look at color pictures: as the left car is yellow and the right
car is red, we would realize at a rst glance that they are dierent. This simple
example shows that color and shape information are both important cues for object
recognition. In spite of this, just a few systems employ both. This is because most
of representations proposed in literature aren't suitable for both type of information
[5, 11, 13, 2]. Some authors tackled this problem building up new representations,
containing both color and shape information; these approaches show very good per-
formances [7, 12, 6]. However, this strategy has two important drawbacks:
 both types of information must be used always.
Although there are many cases where it is convenient to have both, a huge litera-
ture shows that color only, or shape only representations work very well for many
applications [9, 13, 11, 2]. A new, common representation doesn't always permit to
use just color or just shape information alone, depending on the task considered;
 the dimension of the feature vector.
If the new representation brings as much information as separate representations
do, then we must expect it to have a higher dimensionality than each separate

Figure 1: An example of objects similar with respect to shape but not with respect
to color (the left car is yellow while the right car is red).
representation alone, with all the risks of a curse of dimensionality eect. If the
dimension of the new representation vector is kept under control, we can expect
that the representation contains less information that single ones, with a possible
decrease of eectiveness
Our goal in this paper is to present a system that uses both types of information
while keeping them distinct, allowing the exibility to use the information some-
times combined, sometimes separated, depending on the application considered. We
achieve this goal focusing the attention on how two given shape and color representa-
tions can be combined together as they are, rather than dene a new representation.
We obtain this using Spin Glass-Markov Random Fields (SG-MRF), a new kernel
method that integrates results of statistical physics of spin glasses with Gibbs prob-
ability distributions via nonlinear kernel mapping. SG-MRFs have been used for
robust appearance-based object recognition with very good results, using a kernel-
ized Hopeld energy [3]. Here we extend SG-MRF to a new SG-like energy function,
inspired by the ultrametric properties of the SG phase space. The structure of this
energy provides a natural framework for combining shape and color representations
together, without dening a new common representation (such as a concatenated
one, see for instance [7]). This approach presents two main advantages:
 it permits us to use existing and well tested representations both for shape
and color information;
 it permits us to use this knowledge in a exible manner, depending on the
task considered.
To the best of our knowledge, there are no previous similar approaches to this
problem. Experimental results show the eectiveness of the new proposed kernel
method. The paper is organized as follows: section 2 denes the probabilistic
framework for object recognition, section 3 reviews SG-MRF and section 4 presents
the new energy function and how it can be used for combining together color and
shape information. Section 5 presents experiments that show the eectiveness of our
approach, compared to other conventional strategies (NNC,  2 and SVM [10, 14]).
The paper concludes with a summary discussion.
2 Probabilistic Appearance-based Object Recognition
Probabilistic appearance-based object recognition methods consider images as ran-
dom feature vectors. Let x  [x ij ]; i = 1; : : : N ; j = 1; : : : M be an M  N im-
age. We will consider each image as a random feature vector x 2 < MN . Assume
we have k dierent
classes
 1
;
 2 ; : : :
;
 k of objects, and that for each object is

given a set of n j data samples, d j = fx j
1 ; x j
2 ; : : : ; x j
n j
g; j = 1; : : : k. We will assign
each object to a pattern
class
 1
;
 2 ; : : :
;
 k . How the object
class
 j is repre-
sented, given a set of data samples d j (relative to that object class), varies for
dierent appearance-based approaches: it can consider shape information only, or
color information only or both. This is equivalent to consider a set of features
fh j
1 ; h j
2 ; : : : ; h j
n j
g; j = 1; : : : k, where each feature vector h j
n j
is computed from the
image x j
n j
; h j
n j
= T (x j
n j
); h j
n j
2 G  < m . Assuming that the data samples d j are
a suÆcient statistic for the pattern
class
 j , the goal will be to estimate the prob-
ability distribution
P
 j (h) that has generated them. Then, given a test image x
and its associate feature vector h, the decision will be made using a Maximum A
Posteriori (MAP) classier:
j  = argmax
j
P
 j
(h) = argmax
j
P(
 j jh) = argmax
j
P
(hj
 j
)P(
 j ); (1)
using Bayes rule. P
(hj
 j ) are the Likelihood Functions (LFs) and
P(
 j ) are the
prior probabilities of the classes. In the rest of the paper we will assume that the
prior
P(
 j ) is the same for all object classes; thus the Bayes classier (1) simplies
to
j  = argmax
j
P
(hj
 j ): (2)
A possible strategy for modeling P
(hj
 j ) is to use Gibbs distributions within a
Markov Random Field (MRF) framework. The MRF joint probability distribution
is given by
P
(hj
 j ) = 1
Z
exp (
E(hj
 j )) ; Z =
X
fhg
exp (
E(hj
 j )) : (3)
The normalizing constant Z is called the partition function, and
E(hj
 j ) is the
energy function. Using MRF modeling for appearance-based object recognition, eq
(2) will become
j  = argmax
j
P
(hj
 j ) = argmin
j
E(hj
 j ) (4)
Only a few MRF approaches have been proposed for high level vision problems
such as object recognition [8], due to the modeling problem for MRF on irregular
sites (for a detailed discussion about this point, we refer the reader to [3]). Spin
Glass-Markov Random Fields overcome this limitation and can be eectively used
for robust appearance-based object recognition [3]. Next sections review SG-MRF
and introduce a new energy function that allows to combine shape and color only
representations in a common probabilistic framework.
3 Spin Glass-Markov Random Fields
Consider k object
classes
 1
;
 2 ; : : :
;
 k , and for each object a set of n j data sam-
ples, d j = fx j
1 ; : : : x j
n j
g; j = 1; : : : k. We will suppose to extract, from each data
sample d j a set of features fh j
1 ; : : : h j
n j
g. For instance, h j
n j
can be a color histogram
computed from x j
n j
. The SG-MRF probability distribution is given by
PSGMRF
(hj
 j ) = 1
Z
exp [ ESGMRF
(hj
 j )] ; Z =
X
fhg
exp [ ESGMRF
(hj
 j )] ; (5)

Descendant
Descendant
Descendant
Ancestor
!


!

Figure 2: Hierarchical structure induced by the ultrametric energy function.
where ESGMRF
(hj
 j ) is a kernelized spin glass energy function. The most general
SG energy is given by [1]
E =
X
(i;j)
J ij s i s j i; j = 1; : : : N; (6)
where the s i are random variables taking values in [ 1; +1], s = (s 1 ; : : : ; s N ) is a
conguration and J = [J ij ]; (i; j) = 1; : : : ; N is the connection matrix. When the
J ij is given by the Hopeld's prescription
J ij = 1
N
p
X
=1
 ()
i  ()
j ; (7)
with f () g p
=1 given congurations of the system ( prototypes) having the following
properties: (a)  () ?  () ; 8 6= ; (b) p = N;  0:14; N ! 1, then it can be
demonstrated that ESGMRF becomes [3]
ESGMRF
(hj
 j ) =
p j
X
=1
h
K(h; ~
h ( j ) )
i 2
; (8)
where the function K(h; ~
h ( j ) ) is a Generalized Gaussian kernel [14]:
K(x; y) = expfd a;b (x; y)g; d a;b (x; y) =
X
i
jx a
i y a
i j b : (9)
f ~ h ( j ) g p j
=1 ; j 2 [1; k] are the prototypes selected (according to a chosen ansatz, [3])
from the training data. The number of prototypes per class must be nite, and
they must satisfy the condition K( ~
h (i) ; ~ h (l) ) = 0, for all i; l = 1; : : : p j ; i 6= l and
j = 1; : : : k. Note that SG-MRFs are dened on features rather than on raw pixels
data. The sites are fully connected, which ends in learning the neighborhood system
from the training data instead of choosing it heuristically. A key characteristic of the
model is that in SG-MRF the functional form of the energy is given by construction.

4 Ultrametric Spin Glass-Markov Random Fields
Consider the energy function (6) with the following connection matrix:
J ij = 1
N
p
X
=1
 ()
i  ()
j
 
1 +
q
X
=1
 ()
i  ()
j
!
= 1
N
p
X
=1
 ()
i  ()
j + 1
N
p
X
=1
q
X
=1
 ()
i  ()
j
(10)
with  ()
i =  ()
i  ()
i . This energy induces a hierarchical organization of stored
prototypes ([1], see Figure 2). The set of prototypes f () g p
=1 are stored at the rst
level of the hierarchy and are usually called the ancestors. Each of them will have
q descendants f () g q
=1 . The parameter  ()
i measures the similarity between
ancestors and descendants. The rst term in eq (10), right, is the Hopeld energy
(6)-(7); the second is a new term that allows us to store as prototypes patterns
correlated with the f () g p
=1 ; this is the case if we want to store, as separate sets
of prototypes, shape only and color only representations computed from the same
view. This energy will have p+
P p
=1 q  minima, of which p absolute (ancestor level)
and
P p
=1 q  local (descendant level). For a complete discussion on the properties
of this energy, we refer the reader to [1, 4].
Here we are interested in using this energy in the SG-MRF framework shown in
Section 4. To this purpose, we show that the energy (6), with the connection
matrix (10), can be written as a function of scalar product between congurations
[4]:
E = 1
N
X
ij
"
1
N
p
X
=1
 ()
i  ()
j
 
1 +
q
X
=1
 ()
i  ()
j
!#
s i s j =
=
"
1
N 2
" p
X
=1
( ()  s) 2 +
p
X
=1
q
X
=1
( ()  s) 2
##
: (11)
The ultrametric energy (11) can be kernelized as done for the Hopeld energy and
thus can be used in a MRF framework. We call the resulting new MRF model
Ultrametric Spin Glass-Markov Random Fields (USG-MRF).
Now, consider the probabilistic appearance-based framework described in section 2.
Given a set of data samples d j for each object
class
 j ; j = 1; : : : k, we will extract
two kinds of feature vectors, fhs j
n j
g k
j=1 containing shape information and fhc j
n j
g k
j=1
containing color information. USG-MRF provides a straightforward manner to use
the Bayes classier (2) using both these representations separately. We will consider
the color features fhc j
n j
g k
j=1 at the ancestor level and the shape features fhs j
n j
g k
j=1
at the descendant level. The USG-MRF energy function will be
EUSGMRF =
p j
X
=1
[K c ( ~
hc ()
; hc)] 2
p j
X
=1
q
X
=1
[K s ( ~
hs ()
; hs)] 2 ; (12)
where f ~
hc ()
g p j
=1 will be the set of prototypes relative to the ancestor level, and
f ~
hs ()
g q
=1 ;  = 1; : : : p j the set of prototypes at the descendant level. These
prototypes are selected from the training data as described in section 3 for SG-
-MRF. K c is the generalized Gaussian kernel at the ancestor level, and K s is the
generalized Gaussian kernel at the descendant level. We stress that the kernel must

be the same at each level of the hierarchy, but can be dierent between levels (as
to say between ancestor and descendant). The Bayes classier based on USG-MRF
will be
j  = argmin
j
( p j
X
=1
[K c ( ~
hc ()
; hc)] 2
p j
X
=1
q
X
=1
[K s ( ~
hs ()
; hs)] 2
)
: (13)
Note that the parametric form of kernels is known (eq (9); thus, when (U)SG-MRF
is used in a Bayes classier for classication purposes, it permits to learn the kernel
to be used from the training data, with a leave-one-out strategy.
5 Experiments
In order to show the eectiveness of USG-MRF for appearance-based object recog-
nition, we perform several sets of experiments. All of them were ran on the COIL
database [9]; it consists of 7200 color images of 100 objects (72 views for object);
each image is of 128  128 pixels. The images were obtained by placing the objects
on a turntable and taking a view every 5 Æ . In all the experiments we performed,
the training set consisted of 12 views per object (one every 30 Æ ). The remaining
views constituted the test set.
Among the many representations proposed in literature, we chose a shape only
and color only representation, and we ran experiments using these representations
separated, concatenated together in a common feature vector and combined together
in the USG-MRF. The purpose of these experiments is to prove the eectiveness
of the USG-MRF model rather than select the optimal combination for the shape
and color representations. Thus, we limited the experiments to one shape only and
one color only representations; but USG-MRF can be applied to any other kind of
shape and/or color representation (see for instance [4]).
As color only representation, we chose two dimensional rg Color Histogram (CH),
with resolution of bin axis equal to 8 [13]. The CH was normalized to 1. As shape
only representation, we chose Multidimensional receptive Field Histograms (MFH)
[11], with two local characteristics based on Gaussian derivatives along x and y
directions, with  = 1:0 and resolution of bin axis equal to 8. The histograms were
normalized to 1. These two representations were used for performing the following
sets of experiments:
 Shape experiments: we ran the experiments using the shape features only.
Classication was performed using SG-MRF with the kernelized Hopeld energy
(6)-(7). The kernel parameters (a; b; ) were learned using a leave-one-out strategy.
The results were benchmarked with those obtained with a  2 and \ similarity mea-
sures, which proved to be very eective for this representation, and with SVM with
Gaussian kernel,  2 [0:001; 10] (here we report only the best results obtained).
 Color experiments: we ran the experiments using the color features only. Clas-
sication and benchmarking were performed as in the shape experiment.
 Color-Shape experiments: we ran the experiments using the color and shape
features concatenated together to form a unique feature vector. Again, classication
and benchmarking were performed as in the shape experiment.
 Ultrametric experiment: we ran a single experiment using the shape and color
representation disjoint in the USG-MRF framework. The kernel parameters relative

to each level (a s ; b s ;  s and a c ; b c ;  c ) are learned with the leave-one-out technique.
Results obtained with this approach cannot be directly benchmarked with other
similarity measures. Anyway, it is possible to compare the obtained results with
those of the previous experiments.
Table 1 reports the error rates obtained for the 4 sets of experiments.
Color (%) Shape (%) Color-Shape (%) Ultrametric (%)
 2 23.47 9.47 19.17
\ 25.68 24.94 21.72
SVM 19.78 25.3 18.38
SG-MRF 20.10 6.28 8.43 3.55
Table 1: Classication results; we report for each set of experiments the obtained
error rates.
Results presented in Table 1 show that for all series of experiments, for all repre-
sentations, SG-MRF always gave the best recognition result. Moreover, the overall
best recognition result is obtained with USG-MRF. USG-MRF has an increase of
performance of +2:73% with respect to SG-MRF, best result, and of +5:92% with
respect to  2 (best result obtained with a non SG-MRF technique). Table 2 shows
some examples of objects misclassied by SG-MRF and correctly classied by USG-
MRF. We see that USG-MRF classies correctly in cases where shape only or color
only gives the right answer (but not both, and not in the concatenated representa-
tion; Table 2, left and middle column), and also in cases where color only and shape
only don't classify correctly (Table 2, right column). These examples show clearly
that the better performance of USG-MRF is due to its hierarchical structure that
permits to use dierent kernels on dierent features, thus to weight their relevance
in a exible manner with respect to the considered application.
We remark once again that all the kernel parameters (thus ultimately the kernel
itself) are learned from the training data; to the best of our knowledge (U)SG-MRF
is the rst kernel method for vision application that doesn't select heuristically the
kernel to be used.
USG-MRF 1st match 1st match 1st match
SG MRF s 2nd match 1st match 3rd match
SG MRF c 1st match 2nd match 7th match
SG MRF sc 3rd match 2nd match 5th match
Table 2: Classication results for sample objects; USG-MRF classies always cor-
rectly even when color only (SG MRF s ), color only (SG MRF c ) and common
representation (SG MRF sc ) fail (right column).

6 Summary
In this paper we presented a kernel method that permits us to combine color and
shape information for appearance-based object recognition. It does not require us
to dene a new common representation, but use the power of kernels to combine
dierent representations together in an eective manner. This result is achieved
using results of statistical mechanics of Spin Glasses combined with Markov Random
Fields via kernel functions. Experiments conrm the eectiveness of the proposed
approach. Future work will explore the possibility to use dierent representations
for color and shape and to use this method for tackling other challenging problems
in object recognition, such as recognition of objects in heterogeneous background
and under dierent lighting conditions.
Acknowledgments
This work has been supported by the \Graduate Research Center of the University
of Erlangen-Nuremberg for 3D Image Analysis and Synthesis", and by the Founda-
tion BLANCEFLOR Boncompagni-Ludovisi.
References
[1] D. J. Amit, \Modeling Brain Function", Cambridge University Press, 1989.
[2] S. Belongie, J. Malik, J. Puzicha, \Matching Shapes", ICCV01, 454-461.
[3] B. Caputo, S. Bouattour, H. Niemann, \A new kernel method for robust appearance-
based object recognition: Spin Glass-Markov random elds", submitted to PR, avail-
able at http : ==www:ski:org=ALY uille l ab=.
[4] B. Caputo, Gy. Dorko, H. Niemann, \An ultrametric approach to object recognition",
submitted to VMV02, availabe at http : ==www:ski:org=ALY uille l ab=.
[5] A. Leonardis, H. Bischof, \Robust recognition using eigenimages", CVIU,78:99-118,
2000.
[6] J. Matas, R, Marik, J. Kittler, \On representation and matching of multi-coloured
objects", Proc ICCV95, 726-732, 1995.
[7] B. W. Mel, \SEEMORE: combining color, shape and texture histogramming in a
neurally-inspired approach to visual object recognition", NC, 9: 777-804, 1997
[8] J.W. Modestino, J. Zhang. \A Markov random eld model{based approach to image
interpretation". PAMI, 14(6),606{615,1992.
[9] Nene, S. A., Nayar, S. K., Murase, H., \Columbia Object Image Library (COIL-100)",
TR CUCS-006-96, Dept. Comp. Sc., Columbia University, 1996.
[10] Pontil, M., Verri, A. \Support Vector Machines for 3D Object Recognition", PAMI,
20(6):637-646, 1998.
[11] B. Schiele, J. L. Crowley, \Recognition without correspondence using multidimen-
sional receptive eld histograms", IJCV, 36(1),:31- 52, 2000.
[12] D. Slater, G. Healey, \Combining color and geometric information for the illumination
invariant recognition of 3-D objects", Proc ICCV95, 563-568, 1995.
[13] M. Swain, D. Ballard, \Color indexing",IJCV, 7(1):11-32, 1991.
[14] B. Scholkopf, A. J. Smola, Learning with kernels, 2002, the MIT Press, Cambridge,
MA.

