Modeling the Modulatory Eect of
Attention on Human Spatial Vision
Laurent Itti
Computer Science Department, Hedco Neuroscience Building HNB-30A,
University of Southern California, Los Angeles, CA 90089-2520, U.S.A.
Jochen Braun
nstitute of Neuroscience and School of Computing,
University of Plymouth, Plymouth Devon PL4 8AA, U.K.
Christof Koch
Computation and Neural Systems Program, MC 139-74,
California Institute of Technology, Pasadena, CA 91125, U.S.A.
Abstract
We present new simulation results, in which a computational model
of interacting visual neurons simultaneously predicts the modula-
tion of spatial vision thresholds by focal visual attention, for ve
dual-task human psychophysics experiments. This new study com-
plements our previous ndings that attention activates a winner-
take-all competition among early visual neurons within one cortical
hypercolumn. This \intensied competition" hypothesis assumed
that attention equally aects all neurons, and yielded two single-
unit predictions: an increase in gain and a sharpening of tuning
with attention. While both eects have been separately observed
in electrophysiology, no single-unit study has yet shown them si-
multaneously. Hence, we here explore whether our model could still
predict our data if attention might only modulate neuronal gain,
but do so non-uniformly across neurons and tasks. Specically, we
investigate whether modulating the gain of only the neurons that
are loudest, best-tuned, or most informative about the stimulus,
or of all neurons equally but in a task-dependent manner, may ac-
count for the data. We nd that none of these hypotheses yields
predictions as plausible as the intensied competition hypothesis,
hence providing additional support for our original ndings.
1 INTRODUCTION
Psychophysical studies as well as introspection indicate that we are not blind out-
side the focus of attention, and that we can perform simple judgments on objects
not being attended to [1], though those judgments are less accurate than in the

presence of attention [2, 3]. While attention thus appears not to be mandatory for
early vision, there is mounting experimental evidence from single-neuron electro-
physiology [4, 5, 6, 7, 8, 9, 10], human psychophysics [11, 12, 13, 14, 3, 2, 15, 16] and
human functional imaging experiments [17, 18, 19, 20, 21, 22, 23] that focal visual
attention modulates, top-down, activity in early sensory processing areas. In the
visual domain, this modulation can be either spatially-dened (i.e., neuronal activ-
ity only at the retinotopic location attended to is modulated) or feature-based (i.e.,
neurons with stimulus preference matching the stimulus attended to are enhanced
throughout the visual eld), or a combination of both [7, 10, 24].
Computationally, the modulatory eect of attention has been described as enhanced
gain [8, 10], biased [4] or intensied [14, 2] competition, enhanced spatial resolution
[3], sharpened neuronal tuning [5, 25] or as modulated background activity [19],
eective stimulus strength [26] or noise [15]. One theoretical di∆culty in trying
to understand the modulatory eect of attention in computational terms is that,
although attention profoundly alters visual perception, it is not equally important
to all aspects of vision. While electrophysiology demonstrates \increased ring
rates" with attention for a given task, psychophysics show \improved discrimination
thresholds" on some other tasks, and functional magnetic resonance imaging (fMRI)
reports \increased activation" for yet other tasks, the computational mechanism at
the origin of these observations remains largely unknown and controversial.
While most existing theories are associated to a specic body of data, and a spe-
cic experimental task used to engage attention in a given experiment, we have
recently proposed a unied computational account [2] that spans ve such tasks (32
thresholds under two attentional conditions, i.e., 64 datapoints in total). This the-
ory predicts that attention activates a winner-take-all competition among neurons
tuned to dierent orientations within a single hypercolumn in primary visual cortex
(area V1). It is rooted in new information-theoretic advances [27], which allowed us
to quantitatively relate single-unit activity in a computational model to human psy-
chophysical thresholds. A consequence of our \intensied competition hypothesis"
is that attention both increases the gain of early visual neurons (by a factor 3.3),
and sharpens their tuning for the orientation (by 40%) and spatial frequency (by
30%). While gain modulation has been observed in some of the single-unit studies
mentioned above [8, 10] (although much smaller eects are typically reported, on the
order of 10-15%, probably because these studies do not use dual-task paradigms and
thus poorly engage the attention of the animal towards or away from the stimulus
of interest), and tuning modulation has been observed in other single-unit studies
[5, 25], both gain and tuning modulation have not been simultaneously observed in
a single electrophysiological set of experiments [10].
In the present study, we thus investigate alternatives to our intensied competi-
tion hypothesis which only involve gain modulation. Our previous results [2] have
shown that both increased gain and sharper tuning were necessary to simultane-
ously account for our ve pattern discrimination tasks, if those modulatory eects
were to equally aect all visual neurons at the location of the stimulus and to be
equal for all tasks. Thus, we here extend our computational search space under two
new hypotheses: First, we investigate whether attention might only modulate the
gain of selected sub-populations of neurons (responding the loudest, best tuned, or
most informative about the stimulus) in a task-independent manner. Second, we
investigate whether attention might equally modulate the gain of all visual neurons
responding to the stimulus, but in a task-dependent manner. Thus, the goal of
the present study is to determine, using new computational simulations, whether
the modulatory eect of attention on early visual processing might be explained by
gain-only modulations, if such modulations are allowed to be su∆ciently complex

(aecting only select visual neurons, or task-dependent). Although attention cer-
tainly aects most stages of visual processing, we here continue to focus on early
vision, as it is widely justied by electrophysiological and fMRI evidence that some
modulation does happen very early in the processing hierarchy [5, 8, 9, 23].
2 PSYCHOPHYSICAL DATA
Our recent study [2] measured psychophysical thresholds for three pattern discrim-
ination tasks (contrast, orientation and spatial frequency discriminations), and two
spatial masking tasks (32 thresholds). We used a dual-task paradigm to measure
thresholds either when attention was fully available to the task of interest (presented
in the near periphery), or when it was poorly available because engaged elsewhere
by a concurrent attention-demanding task (a letter discrimination task at the center
of the display). The results are summarized in Fig. 1 and [2].
OrientationDiscrimination
C
Contrast
Dq
(∞)
0 0.2 0.4 0.6 0.8 1
0
2
4
6
8 *
Spatial
FrequencyDiscrimination B
*
0 0.2 0.4 0.6 0.8 1
0
0.1
0.2
0.3
Contrast
Dw
(octaves)
ContrastDiscrimination
A
Mask contrast
Target
contrast
0 10 ≠2
10 ≠1
10 ≠2
10 ≠1
ContrastMasking
1
D
Target
contrast
Mask q - Target q (∞)
0 20 40 60 80
0
0.1
0.2
0.3
0.4
ContrastMasking
2
E
1
0
0.1
0.2
0.3
0.4
2
0.5
Mask w / Target w
Target
contrast T
Stimulus
Perceptual Mask
200ms
Central task:
same or different?
Peripheral task:
threshold measurement
T T T T
T
F F
F
F
F
Fully Attended
Poorly Attended
Fully Attended
Poorly Attended
Figure 1: Psychophysical data from Lee et al. Central targets appeared at 0 0:8 ∆
eccentricity and measured 0:4 ∆ across. Peripheral targets appeared for 250 ms at 4 ∆
eccentricity, in a circular aperture of 1:5 ∆ . They were either sinusoidal gratings (B,
C) or vertical stripes whose luminance prole was given by the 6th derivative of a
Gaussian (A, D, E). Mask patterns were generated by superimposing 100 Gabor
lters, positioned randomly within the circular aperture (A, D, E). Thresholds
were established with an adaptive staircase method (80 trials per block). A complex
pattern of eects is observed, with a strong modulation of orientation and spatial
frequency discriminations (B, C), smaller modulation of contrast discriminations
(A), and modulation of contrast masking that depends on stimulus congurations
(D, E). These complex observations can be simultaneously accounted for by our
computational model of one hypercolumn in primary visual cortex.

3 COMPUTATIONAL MODEL
+
Stimulus
Noise
Noise
Noise
Statistically
Efficient
Decision
Stage
+
≠
+
≠
≠
≠
Linear filters Divisive inhibition
E l,q R l,q
Decision
The model developed to quantita-
tively account for this data comprises
three successive stages [14, 27]. In the
rst stage, a bank of Gabor-like linear
lters (12 orientations and 5 spatial
scales) analyzes a given visual loca-
tion, similarly to a cortical hypercol-
umn. In the second stage, lters non-
linearly interact through both a self-
excitation component, and a divisive
inhibition component that is derived
from a pool of similarly-tuned units. With E ; being the linear response from a
unit tuned to spatial period  and orientation , the response R ; after interactions
is given by (see [27] for additional details):
R ; = (A:E ; ) 
(S) ∆ +
X
( 0 ; 0 )2
W ; ( 0 ;  0 ) (A:E  0 ; 0 ) ∆
+B; (1)
where: W ; ( 0 ;  0 ) = exp
 (log( 0 ) log()) 2
2 2

( 0 ) 2
2 2


(2)
is a 2D Gaussian weighting function centered around (; ) whose widths are deter-
mined by the scalars   and   . The neurons are assumed to be noisy, with noise
variance V 2
;
given by a generalized Poisson model: V 2
;
= (R ; + ).
The third stage relates activity in the population of interacting noisy units to behav-
ioral discrimination performance. To allow us to quantitatively predict thresholds
from neural activity for any task, our decision stage assumes that observers perform
close to an unbiased e∆cient statistic, that is, the best possible estimator (in the
statistical estimation sense) of the characteristics of the stimulus given the noisy
neuronal responses. This methodology (described further in [27]) allows us to quan-
titatively compute thresholds in any behavioral situation, and eliminates the need
for task-dependent assumptions about the decision strategy used by the observers.
4 RESULTS and DISCUSSION
The 10 free model parameters (Fig. 2) were automatically adjusted to best t
the psychophysical data from all experiments, using a multidimensional down-
hill simplex with simulated annealing overhead (see [27]), running on our 16-
CPU Linux Beowulf system (16  733 MHz, 4 GB RAM, 0.5 TB disk; see
http://iLab.usc.edu/beo/). Parameters were simultaneously adjusted for both
attentional conditions; that is, the total t error was the sum of the error obtained
with the baseline set of parameters on the poorly attended data, and of the error
obtained with the same parameters plus some attentional perturbation on the fully
attended data. Thus, no bias was given to any of the two attentional conditions.
For the \separate ts" (Fig. 2), all parameters were allowed to dier with atten-
tion [2], while only the interaction parameters (; ∆) could dier in the \intensied
competition" case. The \loudest lter" was the one responding loudest to the en-
tire visual pattern presented (stimulus + mask), the \best-tuned lter" was that
responding best to the stimulus component alone, and the \most informative l-
ter" was that for which the Fisher information about the stimulus was highest (see

Model
Parameters
Discussion
Fully Poorly
Parameters
# (∞)
#   (oct)
#   (∞)
#   (oct)
B / A
S / A
#
# / R
#
#
#
#
max
3.78
3.42
9.69
0.44
23.01
0.81
0.30
10.12
0.17
0.03
1.85
1.80
13.19
0.36
23.90
0.18
1.10
8.05
0.01
0.11
n.s.
n.s.
n.s.
n.s.
n.s.
n.s.
n.s.
Separate Fits
##### #####
Intensified Competition
                 Fully    Poorly
Parameters
#   (∞)
#   (oct)
#   (∞)
#   (oct)
B / A
S / A
#
# / R
#
#
#
#
max
3.94
3.55
1.40
1.00
8.92
0.41
20.80
0.31
0.96
5.39
0.58
0.02
##### ####
Loudest Filter
# ≠
                 Fully           Poorly
Parameters
#   (∞)
#   (oct)
#   (∞)
#   (oct)
B / A
S / A
#
# / R
#
#
#
#
max
2.22
1.03
6.62
0.19
15.54
1.09
0.21
12.16
0.65
0.01
1.56
For
loudest
filter only!
Best≠tuned Filter
#### ≠
                 Fully           Poorly
Parameters
#   (∞)
#   (oct)
#   (∞)
#   (oct)
B / A
S / A
#
# / R
#
#
#
#
max
1.40
1.91
11.94
0.32
14.71
7.03
0.24
3.00
1.5e≠9
8635.52
1.99
For best≠tuned
filter only!
Most Informative Filter
# ###
Fully Poorly
Parameters
# (∞)
#   (oct)
#   (∞)
#   (oct)
B / A
S / A
#
# / R
#
#
#
#
max
1.45
1.04
9.70
0.31
39.15
0.42
0.66
0.00
3.4e≠4
0.01
1.05
For most
informative filter only!
Task Dependent
≠ ≠
                 Fully                 Poorly
Parameters
#
#
#   (∞)
#   (oct)
#   (∞)
#   (oct)
B / A
S / A
#
# / R
#
#
max
1.91 / 3.08 / 2.43
1.24
10.63
0.36
37.63
0.44
0.45
13.18
0.82
0.14
1.50
For
contrast / orientation / period
Top≠down Attention
[task≠ and filter≠independent]
+ +
+
. . .
. . .
Top≠down Attention
[task≠ and filter≠independent]
+ +
+
. . .
. . .
Top≠down Attention
[stimulus≠dependent; only affects filter responding
most to whole (target+mask) stimulus]
+ +
+
. . .
. . .
Top≠down Attention
[stimulus≠dependent; only affects filter
best tuned to target stimulus]
+ +
+
. . .
. . .
Top≠down Attention
[stimulus≠dependent; only affects filter
most informative about target stimulus]
+ +
+
. . .
. . .
Top≠down Attention
[affects all filters, but differently for each task]
+ +
+
. . .
. . .
≠ very good fit overall
≠ all parameters biologically
plausible
≠ attention significantly
modulates interactions
and noise
≠ very good fit overall
≠ all parameters biologically
plausible
≠ modulation of orientation
thresholds slightly under≠
estimated
≠ contrast masking with
variable mask orientation
not perfectly predicted
≠ no modulation of contrast
detection threshold
≠ no modulation of orient≠
ation thresholds
≠ no modulation of period
thresholds
≠ poor prediction of masking
≠ filter tuning too narrow
≠ gain modulation too large
≠ no modulation of orient≠
ation thresholds
≠ no modulation of period
thresholds
≠ contrast discrimination
and masking well fit
≠ only fit predicting broad
pooling in spatial period
≠ noise parameters unrealistic
≠ no contrast discrimination
"dipper"
≠ power≠law rather than
sigmoidal contrast resp≠
onse (S=0)
≠ modulation of orientation
thresholds slightly under≠
estimated
≠ noise parameter unrealistic
≠ very good fit overall
≠ gain modulation unreal≠
istically high, especially
for orientation discrimi≠
nation (filter gain when
attending to orientation
is > 20x poorly attended)
#, #:Interaction strength
# , # Filter tuning
#  , #  : Filter pooling
B, #: Dark noise
#: Light noise
S: Semisaturation
#
#
#
#
Attentional
manipulations
#
Figure 2: Attentional modulation hypotheses and corresponding model parameters.
See next page for the corresponding model predictions on our ve tasks, for the
hypotheses shown. The middle column shows which parameters were allowed to
dier with attention, and the best-t values for both attentional conditions.

Contrast
Increment
Spatial Frequency
Discrimination
Orientation
Discrimination
Contrast Masking,
Variable Mask q
Contrast Masking,
Variable Mask w
Mask contrast
Target
contrast
010 ≠2 10 ≠1
10 ≠2
10 ≠1
Fully attended
Poorly attended
Target
contrast
Mask q - Target q (∞)
020406080
0
0.1
0.2
0.3
0.4 Fully attended
Poorly attended
1
0
0.1
0.2
0.3
0.4
2
0.5
Mask w Target w
Target
contrast
Contrast
Dq
(∞)
00.2 0.40.6 0.8 1
0
2
4
6
8
00.2 0.40.6 0.81
0
0.1
0.2
0.3
Contrast
Dw
(octaves)
HHHH HHHHH HHHHH HHHH HHHHH
Mask contrast
Target
contrast
010 ≠2 10 ≠1
10 ≠2
10 ≠1
Fully attended
Poorly attended
Target
contrast
Mask q - Target q (∞)
020406080
0
0.1
0.2
0.3
0.4 Fully attended
Poorly attended
1
0
0.1
0.2
0.3
0.4
2
0.5
Mask w Target w
Target
contrast
Contrast
Dq
(∞)
00.2 0.40.6 0.8 1
0
2
4
6
8
00.2 0.40.6 0.81
0
0.1
0.2
0.3
Contrast
Dw
(octaves)
HHHH HHHH HHH HHH HHHH
HHH ≠≠≠H
Mask contrast
Target
contrast
010 ≠2 10 ≠1
10 ≠2
10 ≠1
Fully attended
Poorly attended
Target
contrast
Mask q - Target q (∞)
020406080
0
0.1
0.2
0.3
0.4 Fully attended
Poorly attended
1
0
0.1
0.2
0.3
0.4
2
0.5
Mask w Target w
Target
contrast
Contrast
Dq
(∞)
00.2 0.40.6 0.8 1
0
2
4
6
8
00.2 0.40.6 0.81
0
0.1
0.2
0.3
Contrast
Dw
(octaves)
HHHH ≠≠HHHHH HHHH
Mask contrast
Target
contrast
010 ≠2 10 ≠1
10 ≠2
10 ≠1
Fully attended
Poorly attended
Target
contrast
Mask q - Target q (∞)
020406080
0
0.1
0.2
0.3
0.4 Fully attended
Poorly attended
1
0
0.1
0.2
0.3
0.4
2
0.5
Mask w Target w
Target
contrast
Contrast
Dq
(∞)
00.2 0.40.6 0.8 1
0
2
4
6
8
00.2 0.40.6 0.81
0
0.1
0.2
0.3
Contrast
Dw
(octaves)
HH HHHHH HHH HHHHH HHHHH
Mask contrast
Target
contrast
010 ≠2 10 ≠1
10 ≠2
10 ≠1
Fully attended
Poorly attended
Target
contrast
Mask q - Target q (∞)
020406080
0
0.1
0.2
0.3
0.4 Fully attended
Poorly attended
1
0
0.1
0.2
0.3
0.4
2
0.5
Mask w Target w
Target
contrast
Contrast
Dq
(∞)
00.2 0.40.6 0.8 1
0
2
4
6
8
00.2 0.40.6 0.81
0
0.1
0.2
0.3
Contrast
Dw
(octaves)
HHH HHHHH HHHHH HHHHH HHHHH
Mask contrast
Target
contrast
010 ≠2 10 ≠1
10 ≠2
10 ≠1
Fully attended
Poorly attended
Target
contrast
Mask q - Target q (∞)
020406080
0
0.1
0.2
0.3
0.4 Fully attended
Poorly attended
1
0
0.1
0.2
0.3
0.4
2
0.5
Mask w Target w
Target
contrast
Contrast
Dq
(∞)
00.2 0.40.6 0.8 1
0
2
4
6
8
00.2 0.40.6 0.81
0
0.1
0.2
0.3
Contrast
Dw
(octaves)
Figure 3: Model predictions for the dierent attentional modulation hypotheses
studied. The dierent rows correspond to the dierent attentional manipulations
studied, as labeled in the previous gure. Ratings (stars below the plots) were
derived from the residual error of the ts.

[14, 27]). Finally, in the \task-dependent" case, the gain of all lters was aected
equally (parameter ), but with three dierent values for the contrast (discrimi-
nation and masking), orientation and spatial frequency tasks. Overall, very good
ts were obtained in the \separate ts" and \intensied competition" conditions
(as previously reported), as well as in the \most informative lter" and \task-
dependent" conditions (Fig. 3), while the two remaining hypotheses yielded very
poor predictions of orientation and spatial frequency discriminations. In the \most
informative lter" case, the dipper in the contrast increment thresholds was missing
because the nonlinear response function of the neurons converged to a power law
rather than the usually observed sigmoid [27]; thus, this hypothesis lost some of
its appeal because of its lower biological plausibility. More importantly, a careful
analysis of the very promising results for the \task-dependent" case also revealed
their low biological plausibility, with a gain modulation in excess of 20-fold being
necessary to explain the orientation discrimination data (Fig. 2).
In summary, we found that none of the simpler (gain only) attentional manipula-
tions studied here could explain as well the psychophysical data as our previous ma-
nipulation, \intensied competition," which implied that attention both increases
the gain and sharpens the tuning of early visual neurons. Two of the four new
manipulations studied yielded good quantitative model predictions: aecting the
gain of the lter most informative about the target stimulus, and aecting the gain
of all lters in a task-dependent manner. In both cases, however, some of the in-
ternal model parameters associated with the ts were biologically unrealistic, thus
reducing the plausibility of these two hypotheses. In all manipulations studied, the
greatest di∆culty was in trying to account for the orientation and spatial frequency
discrimination data without unrealistically high gain changes (greater than 20-fold).
Our results hence provide additional evidence for the hypothesis that sharpening
of tuning may be necessary to account for these thresholds, as was originally sug-
gested by our separate ts and our intensied competition hypothesis and has been
recently supported by new investigations [16].
Acknowledgements
This research was supported by the National Eye Institute, the National Science
Foundation, the NSF-supported ERC center at Caltech, the National Institutes for
Mental Health, and startup funds from the Charles Lee Powell Foundation and the
USC School of Engineering.
References
[1] Braun J & Sagi D. Percept Psychophys, 1990;48(1):45{58.
[2] Lee DK, Itti L, Koch C et al . Nat Neurosci , 1999;2(4):375{81.
[3] Yeshurun Y & Carrasco M. Nature, 1998;396(6706):72{75.
[4] Moran J & Desimone R. Science, 1985;229(4715):782{4.
[5] Spitzer H, Desimone R & Moran J. Science, 1988;240(4850):338{40.
[6] Chelazzi L, Miller EK, Duncan J et al . Nature, 1993;363(6427):345{7.
[7] Motter BC. J Neurosci , 1994;14(4):2178{89.
[8] Treue S & Maunsell JH. Nature, 1996;382(6591):539{41.
[9] Luck SJ, Chelazzi L, Hillyard SA et al . J Neurophysiol , 1997;77(1):24{42.
[10] Treue S & Trujillo JCM. Nature, 1999;399(6736):575{579.
[11] Nakayama K & Mackeben M. Vision Res, 1989;29(11):1631{47.
[12] Bonnel AM, Stein JF & Bertucci P. Q J Exp Psychol A, 1992;44(4):601{26.
[13] Lee DK, Koch C & Braun J. Vision Res, 1997;37(17):2409{18.

[14] Itti L, Braun J, Lee DK et al . In NIPS*11 . MIT Press, 1999; pp. 789{795.
[15] Dosher BA & Lu ZL. Vision Res, 2000;40(10-12):1269{1292.
[16] Carrasco M, Penpeci-Talgar C & Eckstein M. Vision Res, 2000;40(10-12):1203{1215.
[17] Corbetta M, Miezin FM, Dobmeyer S et al . Science, 1990;248(4962):1556{9.
[18] Rees G, Frackowiak R & Frith C. Science, 1997;275(5301):835{8.
[19] Chawla D, Rees G & Friston KJ. Nat Neurosci , 1999;2(7):671{676.
[20] Brefczynski JA & DeYoe EA. Nat Neurosci , 1999;2(4):370{374.
[21] Corbetta M, Kincade JM, Ollinger JM et al . Nat Neurosci , 2000;3(3):292{297.
[22] Kanwisher N & Wojciulik E. Nat Rev Neurosci , 2000;1:91{100.
[23] Ress D, Backus BT & Heeger DJ. Nat Neurosci , 2000;3(9):940{945.
[24] Barcelo F, Suwazono S & Knight RT. Nat Neurosci , 2000;3(4):399{403.
[25] Desimone R & Duncan J. Annu Rev Neurosci , 1995;18:193{222.
[26] Reynolds JH, Pasternak T & Desimone R. Neuron, 2000;26(3):703{714.
[27] Itti L, Koch C & Braun J. J Opt Soc Am A, 2000;17(11):1899{1917.

