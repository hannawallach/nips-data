A hierarchical model of complex cells in
visual cortex for the binocular perception
of motion-in-depth
Silvio P. Sabatini, Fabio Solari, Giulia Andreani,
Chiara Bartolozzi, and Giacomo M. Bisio
Department of Biophysical and Electronic Engineering
University of Genoa, I-16145 Genova, ITALY
silvio@dibe.unige.it
Abstract
A cortical model for motion-in-depth selectivity of complex cells in
the visual cortex is proposed. The model is based on a time ex-
tension of the phase-based techniques for disparity estimation. We
consider the computation of the total temporal derivative of the
time-varying disparity through the combination of the responses of
disparity energy units. To take into account the physiological plau-
sibility, the model is based on the combinations of binocular cells
characterized by dierent ocular dominance indices. The resulting
cortical units of the model show a sharp selectivity for motion-in-
depth that has been compared with that reported in the literature
for real cortical cells.
1 Introduction
The analysis of a dynamic scene implies estimates of motion parameters to infer
spatio-temporal information about the visual world. In particular, the perception
of motion-in-depth (MID), i.e. the capability of discriminating between forward
and backward movements of objects from an observer, has important implications
for navigation in dynamic environments. In general, a reliable estimate of motion-
in-depth can be gained by considering the dynamic stereo correspondence problem
in the stereo image signals acquired by a binocular vision system. Fig. 1 shows
the relationships between an object moving in the 3-D space and its geometrical
projections in the right and left retinas. In a rst approximation, the positions of
corresponding points are related by a 1-D horizontal shift, the disparity, along the
direction of the epipolar lines. Formally, the left and right observed intensities from
the two eyes, respectively I L (x) and I R (x), result related as I L (x) = I R [x + ∆(x)],
where ∆(x) is the horizontal binocular disparity. If an object moves from P to
Q its disparity changes and projects dierent velocities (v L , vR ) on the retinas.

F
P
Q
D
Q' P'
Q'
v L v R
P'
a
x L x R
v Z
t
t+ t
D
Z P
Z Q
d
(
t
)
=
(
x
P
L
-
x
P
R
)
ª
a
(
D
-
Z
P
)
/
D
2
d
(
t
+
D
t
)
=
(
x
Q
L
-
x
Q
R
)
ª
a
(
D
-
Z
Q
)
/
D
2
V
Z
ª
D
2
/
a
D
d
D
t
D
d
d
(
t
+
D
t
)
-
d
(
t
D
t
D
t
=
=
=
(
x
Q
L
-
x
P
L
)
-
(
x
Q
R
-
x
P
R
)
D
t
v
L
-
v
R
V
Z
ª
(
v
L
-
v
R
)
D
2
/
a
Figure 1: The dynamic stereo correspondence problem. A moving object in the 3-D
space projects dierent trajectories onto the left and right retinas. The dierences
between the two trajectories carry information about motion-in-depth.
Thus, the Z component of the object's motion (i.e., its motion-in-depth) VZ can
be approximated in two ways [1]: (1) by the rate of change of disparity, and (2)
by the dierence between retinal velocities, as it is evidenced in the box in Fig. 1.
The predominance of one measure on the other one corresponds to dierent hy-
potheses on the architectural solutions adopted by visual cortical cells to encode
dynamic 3-D visual information. Recently, numerous experimental and computa-
tional studies (see e.g., [2] [3] [4] [5]) addressed this issue, by analyzing the binocular
spatio-temporal properties of simple and complex cells. The fact that the resulting
disparity tuning does not vary with time, and that most of the cells in the pri-
mary visual cortex have the same motion preference for the two eyes, led to the
conclusion that these cells are not tuned to motion-in-depth. In this paper, we
demonstrate that, within a phase-based disparity encoding scheme, such cells relay
phase temporal derivative components that can be combined, at a higher level, to
yield a specic motion-in-depth selectivity. The rationale of this statement relies
upon analytical considerations on phase-based dynamic stereopsis, as a time ex-
tension of the well-known phase-based techniques for disparity estimation [6] [7].
The resulting model is based on the computation of the total temporal derivative of
the disparity through the combination of the outputs of binocular disparity energy
units [4] [5] characterized by dierent ocular dominance indices. Since each energy
unit is just a binocular Adelson and Bergen's motion detector, this establishes a
link between the information contained in the total rate of change of the binocular

disparity and that held by the interocular velocity dierences.
2 Phase-based dynamic stereopsis
In the last decades, a computational approach for stereopsis, that rely on the phase
information contained in the spectral components of the stereo image pair, has been
proposed [6] [7]. Spatially-localized phase measures on the left and right images can
be obtained by ltering operations with a complex-valued quadrature pair of Gabor
lters h(x; k 0
) = e x 2 = 2
e ik0 x , where k 0
is the peak frequency of the lter and 
relates to its spatial extension. The resulting convolutions with the left and right
binocular signals can be expressed as Q(x) = (x)e i(x) = C(x) + iS(x) where
(x) =
p
C 2 (x) + S 2 (x) and (x) = arctan (S(x)=C(x)) denote their amplitude
and phase components, respectively, and C(x) and S(x) are the responses of the
quadrature pair of lters. Hence, binocular disparity can be predicted by ∆(x) =
[ L (x)  R (x)]=k(x) where k(x) = [ L
x (x) + R
x (x)]=2, with  x spatial derivative of
phase , is the average instantaneous frequency of the bandpass signal, that, under
a linear phase model, can be approximated by the peak frequency of the Gabor lter
k 0 . Extending to time domain, the disparity of a point moving with the motion
eld can be estimated by:
∆[x(t); t] =  L [x(t); t]  R [x(t); t]
k 0
(1)
where phase components are computed from the spatiotemporal convolutions of the
stereo image pair Q(x; t) = C(x; t) + iS(x; t) with directionally tuned Gabor lters
with a central frequency p = (k 0 ; ! 0 ). For spatiotemporal locations where linear
phase approximation still holds ( ' k 0 x + ! 0 t), the phase dierences in Eq. (1)
provide only spatial information, useful for reliable disparity estimates.
2.1 Motion-in-depth
If disparity is dened with respect to the spatial coordinate xL , by dierentiating
with respect to time, its total rate of variation can be written as
d∆
dt
= @∆
@t
+ vL
k 0
 L
x  R
x

(2)
where vL is the horizontal component of the velocity signal on the left retina. Con-
sidering the conservation property of local phase measurements [8], image velocities
can be computed from the temporal evolution of constant phase contours, and thus:
 L
x =  L
t
v L
and  R
x =  R
t
vR
(3)
with  t = @
@t . Combining Eq. (3) with Eq. (2) we obtain d∆=dt = (v R v L ) R
x =k 0 ,
where (v R v L ) is the phase-based interocular velocity dierence along the epipolar
lines. When the spatial tuning frequency of the Gabor lter k 0
approaches the
instantaneous spatial frequency of the left and right convolution signals one can
derive the following approximated expressions:
d∆
dt
'
@∆
@t
=  L
t  R
t
k 0
' vR vL (4)

The partial derivative of the disparity can be directly computed by convolutions
(S; C) of stereo image pairs and by their temporal derivatives (S t ; C t ):
@∆
@t
=

S L
t C L S L C L
t
(S L ) 2 + (C L ) 2
S R
t C R S R C R
t
(S R ) 2 + (C R ) 2

1
k 0
(5)
thus avoiding explicit calculation and dierentiation of phase, and the attendant
problem of phase unwrapping. Considering that, at rst approximation (S L ) 2 +
(C L ) 2 ' (S R ) 2 + (C R ) 2 and that these terms are scantly discriminant for motion-
in-depth, we can formulate the cortical model taking into account the numerator
terms only.
2.2 The cortical model
If one prelters the image signal to extract some temporal frequency sub-band,
S(x; t) ' g  S(x; t) and C(x; t) ' g  C(x; t), and evaluates the temporal changes
in that sub-band, dierentiation can be attained by convolutions on the data with
appropriate bandpass temporal lters:
S 0 (x; t) ' g 0  S(x; t) ; C 0 (x; t) ' g 0  C(x; t) :
S 0 and C 0 approximate S t and C t , respectively, if g and g 0 are a quadrature pair of
temporal lters, e.g.: g(t) = e t= sin ! 0 t and g 0 (t) = e t= cos ! 0 t. From a mod-
eling perspective, that approximation allows us to express derivative operations in
terms of convolutions with a set of spatio-temporal lters, whose shapes resemble
those of simple cell receptive elds (RFs) of the primary visual cortex. Though, it
is worthy to note that a direct interpretation of the computational model is not bio-
logically plausible. Indeed, in the computational scheme (see Eq. (5)), the temporal
variations of phases are obtained by processing monocular images separately and
then the resulting signals are binocularly combined to give at an estimate of motion-
in-depth in each spatial location. To employ binocular RFs from the beginning, as
they exist for most of the cells in the visual cortex, we manipulated the numerator
by rewriting it as the combination of terms characterized by a dominant contribu-
tion for the ipsilateral eye and a non-dominant contribution for the controlateral
eye. These contributions are referable to binocular disparity energy units [5] built
from two pairs of binocular direction selective simple cells with left and right RFs
weighted by an ocular dominance index  2 [0; 1]. The "tilted" spatio-temporal RFs
of simple cells of the model are obtained by combining separable RFs according to
an Adelson and Bergen's scheme [9]. It can be demonstrated that the information
about motion-in-depth can be obtained with a minimum number of eight binocular
simple cells, four with a left and four with a right ocular dominance, respectively
(see Fig. 2):
S 1
= (1 )(C L
t + S L ) (C R S R
t ) ; S 2
= (1 )(C L + S L
t ) + (C R
t + S R )
S 3 = (1 )(C L
t S L ) (C R + S R
t ) ; S 4 = (1 )(C L + S L
t ) + (C R
t S R )
S 5 = (C L
t + S L ) (1 )(C R S R
t ) ; S 6 = (C L S L
t ) + (1 )(C R
t + S R )
S 7 = (C L
t S L ) (1 )(C R + S R
t ) ; S 8 = (C L + S L
t ) + (1 )(C R
t S R )
C 11 = S 2
1
+ S 2
2
; C 12 = S 2
3
+ S 2
4
; C 13 = S 2
5
+ S 2
6
; C 14 = S 2
7
+ S 2
8

C 21 = C 12 C 11 ; C 22 = C 13 C 14
C 3 = (1 2)(S L
t C L S L C L
t S R
t C R + S R C R
t ) :
The output of the higher complex cell in the hierarchy (C 3 ) truly encodes motion-
in-depth information. It is worthy to note that for a balanced ocular dominance
( = 0:5) the cell looses its selectivity.
3 Results
To assess model performances we derived cells' responses to drifting sinusoidal grat-
ings with dierent speeds in the left and right eye. The spatial frequency of the
gratings has been chosen as central to the RF's bandwidth. For each layer, the
tuning characteristics of the cells are analyzed as sensitivity maps in the (x L xR )
and (v L v R ) domains for the static and dynamic properties, respectively. The
(x L xR ) represents the binocular RF [5] of a cell, evidencing its disparity tuning.
The (v L vR ) response represents the binocular tuning curve of the velocities along
the epipolar lines. To better evidence motion-in-depth sensitivity, we represent as
polar plots, the responses of the model cells with respect to the interocular veloc-
ities ratio for 12 dierent motion trajectories in depth (labeled 1 to 12) [10]. The
cells of the cortical model exhibit properties and typical proles similar to those
observed in the visual cortex [5] [10]. The middle two layers (see insets A and B
in Fig. 2) exhibit a strong selectivity to static disparity, but no specic tuning to
motion-in-depth. On the contrary, the output cell C 3 shows a narrow tuning to the
Z direction of the object's motion, while lacking disparity tuning (see inset C in
Fig. 2).
To consider more biologically plausible RFs for the simple cells, we included a
coe∆cient  in the scheme used to obtain tilted RFs in the space-time domain (e.g.
C + S t ). This coe∆cient takes into account the simple cell response to the non-
preferred direction. We analytically demonstrated (results not shown here) that
the resulting eect is a constant term that multiplies the cortical model output.
In this way, the model is based on more realistic simple cells without lacking its
functionality, provided that the basic direction selective units maintain a signicant
direction selective index. To analyze the eect of the architectural parameters on
the model performance, we systematically varied the ocular dominance index  and
introduced a weight  representing the inhibition strength of the aerent signals
to the complex cells in layer 2. The resulting direction-in-depth polar plots are
shown in Fig. 3. The  parameter yields a strong eect on the response prole:
if  = 0:5 there is no direction-in-depth selectivity; according that  > 0:5 or
 < 0:5 cells exhibit a tuning to opposite directions in depth. As  approaches the
boundary values 0 or 1 the binocular model turns to a monocular one. A decrease
of the inhibition strength  yields cells characterized by a less selective response to
direction-in-depth, whereas an increase of  diminishes their response amplitude.
4 Discussion and conclusions
There are at least two binocular cues that can be used to determine the MID
[1]: binocular combination of monocular velocity signals or the rate of change of
retinal disparity. Assuming a phase-based disparity encoding scheme [6], we demon-
strated that information held in the interocular velocity dierence is the same of

l
a
y
e
r
2
(
)
2
(
)
2
(
)
2
(
)
2
(
)
2
(
)
2
)
2
(
)
2
o
c
u
l
a
r
d
o
m
i
n
a
n
c
e
c
o
l
u
m
n
(
r
i
g
h
t
)
C
o
c
u
l
a
d
o
m
i
n
a
n
c
e
c
o
l
u
m
n
(
l
e
f
t
)
t
x
A
X
L
X
R
B
V
L
V
R
X
L
X
R
V
L
V
R
X
R
V
L
V
R
3
6
9
1
2
3
6
9
1
3
6
9
1
2
X
L
S
3
S
1
S
2
S
4
S
8
S
5
S
7
S
6
C
1
1
C
C
1
3
C
C
2
1
C
2
2
C
3
l
a
y
e
r
1
l
a
y
e
r
3
Figure 2: Functional representation of the proposed cortical architecture. Each
branch groups cells belonging to an ocular dominance column. The aerent sig-
nals from left and right ocular dominance columns are combined in layer 3. The
basic units are binocular simple cells tuned to motion directions (S 1 ; : : : ; S 8 ). The
responses of the complex cells in layers 1, 2 and 3 are obtained by linear and non-
linear combinations of the outputs of those basic units. See text. White squares
denote excitatory synapses whereas black squares denote inhibitory ones.

 = 0:3
 = 0:5  = 1:0  = 2:0
3
6
9
12
3
6
9
12
3
6
9
12
 = 0:7 3
6
9
12
3
6
9
12
3
6
9
12
 = 0:9 3
6
9
12
3
6
9
12
3
6
9
12
Figure 3: Eects on the direction-in-depth selectivity of the systematic variation
of the model's parameters  and . The responses are normalized to the largest
amplitude value.
that derived by the evaluation of the total derivative of the binocular disparity. The
resulting computation relies upon spatio-temporal dierentials of the left and right
retinal phases that can be approximated by linear ltering operations with spatio-
temporal RFs. Accordingly, we proposed a cortical model for the generation of
binocular motion-in-depth selective cells as a hierarchical combination of binocular
energy complex cells. It is worth noting that the phase response and the associ-
ated characteristic disparity of simple and complex cells in layers 1 and 2 do not
change with time, but the amplitudes of their responses carry information on tem-
poral phase derivatives, that can be related to both retinal velocities and temporal
changes in disparity. Moreover, the model evidences the dierent roles of simple
and complex cells. Simple cells provide a Gabor-like spatio-temporal transforma-
tion of the visual space, on which to base a variety of visual functions (perception
of form, depth, motion). Complex cells, by proper combinations of the same signals
provided by simple cells, actively eliminate sensitivity to a selected set of param-
eters, thus becoming specically tuned to dierent features, such as disparity but
not motion-in-depth (layer 1 and 2), motion-in-depth but not disparity (layer 3).

Acknowledgments
This work was partially supported by the UNIGE-2000 Project \Spatio-temporal
Operators for the Analysis of Motion in Depth from Binocular Images".
References
[1] J. Harris and S. N.J. Watamaniuk. Speed discrimination of Motion-in depth
using binocular cues. Vision Research, 35(7):885{896, 1995.
[2] N. Qian and S. Mikaelian. Relationship between phase and energy methods for
disparity computation. Neural Comp., 12(2):279{292, 2000.
[3] Y. Chen, Y. Wang, and N. Qian. Modelling V1 disparity tuning to time-varying
stimuli. J. Neurophysiol., pages 504{600, 2001.
[4] D. J. Fleet, H. Wagner, and D. J. Heeger. Neural encoding of binocular diparity:
energy models, position shift and phase shift. Vision Research, 17:345{398,
1996.
[5] I. Ohzawa, G.C. DeAngelis, and R.D. Freeman. Encoding of binocular disparity
by complex cells in the cat's visual cortex. J. Neurophysiol., 77:2879{2909,
1997.
[6] T.D. Sanger. Stereo disparity computation using Gabor lters. Biol. Cybern.,
59:405{418, 1988.
[7] D.J. Fleet, A.D. Jepson, and M. Jenkin. Phase-based disparity measurements.
CVGIP: Image Understanding, 53:198{210, 1991.
[8] D. J. Fleet and A. D. Jepson. Computation of component image velocity from
local phase information. International Journal of Computer Vision, 1:77{104,
1990.
[9] E.H. Adelson and J.R. Bergen. Spatiotemporal energy models for the percep-
tion of motion. J. Opt. Soc. Amer., 2:284{321, 1985.
[10] W. Spileers, G.A. Orban, B. Gulyas, and H. Maes. Selectivity of cat area
18 neurons for direction and speed in depth. J. Neurophysiol., 63(4):936{954,
1990.

