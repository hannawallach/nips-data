Analysis of Sparse Bayesian Learning
Anita C. Faul Michael E. Tipping
Microsoft Research
St George House, 1 Guildhall St
Cambridge CB2 3NH, U.K.
Abstract
The recent introduction of the `relevance vector machine' has eec-
tively demonstrated how sparsity may be obtained in generalised
linear models within a Bayesian framework. Using a particular
form of Gaussian parameter prior, `learning' is the maximisation,
with respect to hyperparameters, of the marginal likelihood of the
data. This paper studies the properties of that objective func-
tion, and demonstrates that conditioned on an individual hyper-
parameter, the marginal likelihood has a unique maximum which
is computable in closed form. It is further shown that if a derived
`sparsity criterion' is satised, this maximum is exactly equivalent
to `pruning' the corresponding parameter from the model.
1 Introduction
We consider the approximation, from a training sample, of real-valued functions,
a task variously referred to as prediction, regression, interpolation or function ap-
proximation. Given a set of data fxn ; t n g N
n=1 the `target' samples t n = f(xn ) +  n
are conventionally considered to be realisations of a deterministic function f , po-
tentially corrupted by some additive noise process. This function f will be modelled
by a linearly-weighted sum of M xed basis functions f m (x)g M
m=1 :
b
f(x) =
M
X
m=1
wmm (x); (1)
and the objective is to infer values of the parameters/weights fwm g M
m=1 such that
b
f is a `good' approximation of f .
While accuracy in function approximation is generally universally valued, there has
been signicant recent interest [2, 9, 3, 5]) in the notion of sparsity, a consequence
of learning algorithms which set signicant numbers of the parameters wm to zero.
A methodology which eectively combines both these measures of merit is that of
`sparse Bayesian learning', briey reviewed in Section 2, and which was the ba-
sis for the recent introduction of the relevance vector machine (RVM) and related
models [6, 1, 7]. This model exhibits some very compelling properties, in particular
a dramatic degree of sparseness even in the case of highly overcomplete basis sets

(M  N ). The sparse Bayesian learning algorithm essentially involves the max-
imisation of a marginalised likelihood function with respect to hyperparameters in
the model prior. In the RVM, this was achieved through re-estimation equations,
the behaviour of which was not fully understood. In this paper we present further
relevant theoretical analysis of the properties of the marginal likelihood which gives
a much fuller picture of the nature of the model and its associated learning proce-
dure. This is detailed in Section 3, and we close with a summary of our ndings and
discussion of their implications in Section 4 (and which, to avoid repetition here,
the reader may wish to preview at this point).
2 Sparse Bayesian Learning
We now very briey review the methodology of sparse Bayesian learning, more
comprehensively described elsewhere [6]. To simplify and generalise the exposition,
we omit to notate any functional dependence on the inputs x and combine quantities
dened over the training set and basis set within N - and M-vectors respectively.
Using this representation, we rst write the generative model as:
t = f + ; (2)
where t = (t 1 ; : : : ; t N ) T , f = (f 1 ; : : : ; fN ) T and  = ( 1 ; : : : ;  N ) T . The approximator
is then written as:
b f = w; (3)
where  = [ 1 : : :  M ] is a general N M design matrix with column vectors  m
and w = (w 1 ; : : : ; wM ) T . Recall that in the context of (1), nm = m (xn ) and
b f = f b
f(x 1 ); : : : b
f(xN )g T .
The sparse Bayesian framework assumes an independent zero-mean Gaussian noise
model, with variance  2 , giving a multivariate Gaussian likelihood of the target
vector t:
p(tjw;  2 ) = (2) N=2  N exp
(
kt b f k 2
2 2
)
: (4)
The prior over the parameters is mean-zero Gaussian:
p(wj) = (2) M=2
M
Y
m=1
 1=2
m exp
 mw 2
m
2

; (5)
where the key to the model sparsity is the use of M independent hyperparameters
 = ( 1 ; : : : ; M ) T , one per weight (or basis vector), which moderate the strength
of the prior. Given , the posterior parameter distribution is Gaussian and given
via Bayes' rule as p(wjt; ) = N (wj; ) with
 = (A +  2  T ) 1  =  2  T t; (6)
and A dened as diag ( 1 ; : : : ; M ). Sparse Bayesian learning can then be formu-
lated as a type-II maximum likelihood procedure, in that objective is to maximise
the marginal likelihood, or equivalently, its logarithm L() with respect to the hy-
perparameters :
L() = log p(tj;  2 ) = log
Z 1
1
p(tjw;  2 ) p(wj) dw; (7)
= 1
2

N log 2 + log jCj + t T C 1 t

; (8)
with C =  2 I +A 1  T .

Once most-probable values MP have been found 1 , in practice they can be plugged
into (6) to give a posterior mean (most probable) point estimate for the parameters
 MP and from that a mean nal approximator: b f MP =  MP .
Empirically, the local maximisation of the marginal likelihood (8) with respect to
 has been seen to work highly eectively [6, 1, 7]. Accurate predictors may be
realised, which are typically highly sparse as a result of the maximising values of
many hyperparameters being innite. From (6) this leads to a parameter posterior
innitely peaked at zero for many weights wm with the consequence that  MP
correspondingly comprises very few non-zero elements.
However, the learning procedure in [6] relied upon heuristic re-estimation equations
for the hyperparameters, the behaviour of which was not well characterised. Also,
little was known regarding the properties of (8), the validity of the local maximisa-
tion thereof and importantly, and perhaps most interestingly, the conditions under
which -values would become innite. We now give, through a judicious re-writing
of (8), a more detailed analysis of the sparse Bayesian learning procedure.
3 Properties of the Marginal Likelihood L()
3.1 A convenient re-writing
We re-write C from (8) in a convenient form to analyse the dependence on a single
hyperparameter  i :
C =  2 I +
X
m
m m  T
m ; =  2 I +
X
m6=i
 1
m  m  T
m +  1
i  i  T
i ;
= C i +  1
i  i  T
i ; (9)
where we have dened C i =  2 I+ P
m6=i  1
m  m  T
m as the covariance matrix with
the inuence of basis vector  i removed, equivalent also to  i = 1.
Using established matrix determinant and inverse identities, (9) allows us to write
the terms of interest in L() as:
jCj = jC i j j1 +  1
i  T
i C 1
i  i j; (10)
C 1 = C 1
i
C 1
i  i  T
i C 1
i
 i +  T
i C 1
i  i
; (11)
which gives
L() = 1
2
h
N log(2) + log jC i j + t T C 1
i t
log  i + log( i +  T
i C 1
i  i ) ( T
i C 1
i t) 2
 i +  T
i C 1
i  i
i
;
= L( i ) + 1
2
h
log  i log( i +  T
i C 1
i  i ) +
( T
i C 1
i t) 2
 i +  T
i C 1
i  i
i
;
= L( i ) + `( i ); (12)
where L( i ) is the log marginal likelihood with  i (and thus w i and  i ) removed
from the model and we have now isolated the terms in  i in the function `( i ).
1 The most-probable noise variance  2
MP can also be directly and successfully estimated
from the data [6], but for clarity in this paper, we assume without prejudice to our results
that its value is xed.

3.2 First derivatives of L()
Previous results. In [6], based on earlier results from [4], the gradient of the
marginal likelihood was computed as:
@L()
@ i
= 1
2
 1
 i
 2
i  ii

; (13)
with  i the i-th element of  and  ii the i-th diagonal element of . This then leads
to re-estimation updates for  i in terms of  i and  ii where, disadvantageously,
these latter terms are themselves functions of  i .
A new, simplied, expression. In fact, by instead dierentiating (12) directly,
(13) can be seen to be equivalent to:
@L()
@ i
= @`( i )
@ i
= 1
2
"
1
 i
1
 i +  T
i C 1
i  i
( T
i C 1
i t) 2
( i +  T
i C 1
i  i ) 2
#
; (14)
where advantageously,  i now occurs only explicitly since C i is independent of  i .
For convenience, we combine terms and re-write (14) as:
@L()
@ i
=  1
i S 2
i (Q 2
i S i )
2( i + S i ) 2 ; (15)
where, for simplication of this and forthcoming expressions, we have dened:
Q i ,  T
i C 1
i t; S i ,  T
i C 1
i  i : (16)
The term Q i can be interpreted as a `quality' factor: a measure of how well  i
increases L() by helping to explain the data, while S i is a `sparsity' factor which
measures how much the inclusion of  i serves to decrease L() through `inating'
C (i.e. adding to the normalising factor).
3.3 Stationary points of L()
Equating (15) to zero indicates that stationary points of the marginal likelihood
occur both at  i = +1 (note that, being an inverse variance,  i must be positive)
and for:
 i = S 2
i
Q 2
i S i
; (17)
subject to Q 2
i > S i as a consequence again of  i > 0.
Since the right-hand-side of (17) is independent of  i , we may nd the stationary
points of `( i ) analytically without iterative re-estimation. To nd the nature of
those stationary points, we consider the second derivatives.
3.4 Second derivatives of L()
3.4.1 With respect to  i
Dierentiating (15) a second time with respect to  i gives:
@ 2 L()
@ 2
i
=  2
i S 2
i ( i + S i ) 2 2( i + S i )

 1
i S 2
i (Q 2
i S i )

2( i + S i ) 4 ; (18)
and we now consider (18) for both nite- and innite- i stationary points.

Finite . In this case, for stationary points given by (17), we note that the second
term in the numerator in (18) is zero, giving:
@ 2 L()
@ 2
i
     i = S 2
i
Q 2
i S i
= S 2
i
2 2
i ( i + S i ) 2 : (19)
We see that (19) is always negative, and therefore `( i ) has a maximum, which
must be unique, for Q 2
i S i > 0 and  i given by (17).
Innite . For this case, (18) and indeed, all further derivatives, are uninforma-
tively zero at  i = 1, but from (15) we can see that as  i ! 1, the sign of the
gradient is given by the sign of (Q 2
i S i ).
If Q 2
i S i > 0, then the gradient at  i = 1 is negative so as  i decreases `( i )
must increase to its unique maximum given by (17). It follows that  i = 1 is thus
a minimum. Conversely, if Q 2
i S i < 0,  i = 1 is the unique maximum of `( i ).
If Q 2
i S i = 0, then this maximum and that given by (17) coincide.
We now have a full characterisation of the marginal likelihood as a function of a
single hyperparameter, which is illustrated in Figure 1.
10 -7
10 0
10 7
Q 2 >S
a i
log
marginal
likelihood
10 -7
10 0
10 7
Q 2 <S
Figure 1: Example plots of `( i
) against  i
(on a log scale) for Q 2
i
> S i
(left),
showing the single maximum at nite  i
, and Q 2
i
< S i
(right), showing the
maximum at  i
= 1.
3.4.2 With respect to  j , j 6= i
To obtain the o-diagonal terms of the second derivative (Hessian) matrix, it is
convenient to manipulate (15) to express it in terms of C. From (11) we see that
 T
i C 1 t =  i Q i
 i + S i
; and  T
i C 1  i =  i S i
 i + S i
: (20)
Utilising these identities in (15) gives:
@L()
@ i
= 1
2 2
i

 T
i C 1  i ( T
i C 1 t) 2

: (21)
We now write:
@ 2 L()
@ i @ j
= r 2
ij + Æ ij r 2
ii ; (22)

where Æ ij is the Kronecker `delta' function, allowing us to separate out the additional
(diagonal) term that appears only when i = j.
Writing, similarly to (9) earlier, C = C j +  1
j  j  T
j , substituting into (21) and
dierentiating with respect to  j gives:
r 2
ij = 1
2 2
i
"
( T
i C 1
j  j ) 2
( j +  T
j C 1
j  j ) 2
2( T
i C 1 t) ( T
i C 1
j  j )( T
j C 1
j t)
( j +  T
j C 1
j  j ) 2
#
;
=
 T
i C 1
j  j
2 2
i ( j +  T
j C 1
j  j ) 2
h
 T
i C 1
j  j 2( T
i C 1 t)( T
j C 1
j t)
i
;
=  T
i C 1  j
2 2
i  2
j
h
 T
i C 1  j 2( T
i C 1 t)( T
j C 1 t)
i
; (23)
while we have
r 2
ii = 1
 3
i
h
 T
i C 1  i ( T
i C 1 t) 2
i
: (24)
If all hyperparameters  i are individually set to their maximising values, i.e.  =
MP such that all @L()=@ i = 0, then even if all @ 2 L()=@ 2
i are negative, there
may still be a non-axial direction in which the likelihood could be increasing. We
now rule out this possibility by showing that the Hessian is negative semi-denite.
First, we note from (21) that if @L()=@ i = 0, r 2
ii = 0. Then, if v is a generic
nonzero direction vector:
v T
 @ 2 L()
@ i @ j

v = 1
2
M
X
i=1
M
X
j=1
v i v j
 2
i  2
j
h
(C 1=2  i ) T (C 1=2  j )
i 2
  M
X
i=1
jv i j
 2
i
j T
i C 1 tj kC 1=2  i k
! 2
;
 1
2
  M
X
i=1
jv i j
 2
i
kC 1=2  i k 2
! 2
  M
X
i=1
jv i j
 2
i
j T
i C 1 tj kC 1=2  i k
! 2
; (25)
where we use the Cauchy-Schwarz inequality. If the gradient vanishes, then for all
i = 1; : : : ; M either  i = 1, or from (21),  T
i C 1  i = ( T
i C 1 t) 2 . It follows
directly from (25) that the Hessian is negative semi-denite, with (25) only zero
where v is orthogonal to all nite  values.
4 Summary
Sparse Bayesian learning proposes the iterative maximisation of the marginal like-
lihood function L() with respect to the hyperparameters . Our analysis has
shown the following:
I. As a function of an individual hyperparameter  i , L() has a unique maximum
computable in closed-form. (This maximum is, of course, dependent on the
values of all other hyperparameters.)

II. If the criterion Q 2
i S i (dened in Section 3.2) is negative, this maximum
occurs at  i = 1, equivalent to the removal of basis function i from the
model.
III. The point where all individual marginal likelihood functions `( i ) are max-
imised is a joint maximum (not necessarily unique) over all  i .
These results imply the following consequences.
 From I, we see that if we update, in any arbitrary order, the  i parameters
using (17), we are guaranteed to increase the marginal likelihood at each
step, unless already at a maximum. Furthermore, we would expect these
updates to be more eÆcient than those given in [6], which individually only
increase, not maximise, `( i ).
 Result III indicates that sequential optimisation of individual  i cannot
lead to a stationary point from which a joint maximisation over all  may
have escaped. (i.e. the stationary point is not a saddle point.)
 The result II conrms the qualitative argument and empirical observation
that many  i ! 1 as a result of the optimisation procedure in [6]. The
inevitable implication of nite numerical precision prevented the genuine
sparsity of the model being veried in those earlier simulations.
 We conclude by noting that the maximising hyperparameter solution (17)
remains valid if  i is already innite. This means that basis functions not
even in the model can be assessed and their corresponding hyperparameters
updated if desired. So as well as the facility to increase L() through
the `pruning' of basis functions if Q 2
i S i  0, new basis functions can
be introduced if  i = 1 but Q 2
i S i > 0. This has highly desirable
computational consequences which we are exploiting to obtain a powerful
`constructive' approximation algorithm [8].
References
[1] C. M. Bishop and M. E. Tipping. Variational relevance vector machines. In C. Boutilier
and M. Goldszmidt, editors, Proceedings of the 16th Conference on Uncertainty in
Articial Intelligence, pages 46{53. Morgan Kaufmann, 2000.
[2] S. Chen, D. L. Donoho, and M. A. Saunders. Atomic decomposition by basis pursuit.
Technical Report 479, Department of Statistics, Stanford University, 1995.
[3] Y. Grandvalet. Least absolute shrinkage is equivalent to quadratic penalisation. In
L. Niklasson, M. Boden, and T. Ziemske, editors, Proceedings of the Eighth Interna-
tional Conference on Articial Neural Networks (ICANN98), pages 201{206. Springer,
1998.
[4] D. J. C. MacKay. Bayesian interpolation. Neural Computation, 4(3):415{447, 1992.
[5] A. J. Smola, B. Scholkopf, and G. Ratsch. Linear programs for automatic accuracy
control in regression. In Proceedings of the Ninth International Conference on Articial
Neural Networks, pages 575{580, 1999.
[6] M. E. Tipping. The Relevance Vector Machine. In S. A. Solla, T. K. Leen, and K.-R.
Muller, editors, Advances in Neural Information Processing Systems 12, pages 652{658.
MIT Press, 2000.
[7] M. E. Tipping. Sparse kernel principal component analysis. In Advances in Neural
Information Processing Systems 13. MIT Press, 2001.
[8] M. E. Tipping and A. C. Faul. Bayesian pursuit. Submitted to NIPS*01.
[9] V. N. Vapnik. Statistical Learning Theory. Wiley, 1998.

