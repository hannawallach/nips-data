Fast Parameter Estimation
Using Green's Functions
K. Y. Michael Wong
Department of Physics
Hong Kong University
of Science and Technology
Clear Water Bay, Hong Kong
phkywong@ust.hk
Fuli Li
Department of Applied Physics
Xian Jiaotong University
Xian, China 710049
li@xjtu.edu.cn
Abstract
We propose a method for the fast estimation of hyperparameters
in large networks, based on the linear response relation in the cav-
ity method, and an empirical measurement of the Green's func-
tion. Simulation results show that it is e∆cient and precise, when
compared with cross-validation and other techniques which require
matrix inversion.
1 Introduction
It is well known that correct choices of hyperparameters in classication and regres-
sion tasks can optimize the complexity of the data model, and hence achieve the
best generalization [1]. In recent years various methods have been proposed to esti-
mate the optimal hyperparameters in dierent contexts, such as neural networks [2],
support vector machines [3, 4, 5] and Gaussian processes [5]. Most of these meth-
ods are inspired by the technique of cross-validation or its variant, leave-one-out
validation. While the leave-one-out procedure gives an almost unbiased estimate
of the generalization error, it is nevertheless very tedious. Many of the mentioned
attempts aimed at approximating this tedious procedure without really having to
sweat through it. They often rely on theoretical bounds, inverses to large matrices,
or iterative optimizations.
In this paper, we propose a new approach to hyperparameter estimation in large
systems. It is known that large networks are mean-eld systems, so that when one
example is removed by the leave-one-out procedure, the background adjustment
can be analyzed by a self-consistent perturbation approach. Similar techniques
have been applied to the neural network [6], Bayesian learning [7] and the support
vector machine [5]. They usually involve a macroscopic number of unknown vari-
ables, whose solution is obtained through the inversion of a matrix of macroscopic
size, or iteration. Here we take a further step to replace it by a direct measurement
of the Green's function via a small number of learning processes. The proposed
procedure is fast since it does not require repetitive cross-validations, matrix in-
versions, nor iterative optimizations for each set of hyperparaemters. We will also
present simulation results which show that it is an excellent approximation.

The proposed technique is based on the cavity method, which was adapted from
disordered systems in many-body physics. The basis of the cavity method is a
self-consistent argument addressing the situation of removing an example from the
system. The change on removing an example is described by the Green's function,
which is an extremely general technique used in a wide range of quantum and
classical problems in many-body physics [8]. This provides an excellent framework
for the leave-one-out procedure. In this paper, we consider two applications of
the cavity method to hyperparameter estimation, namely the optimal weight decay
and the optimal learning time in feedforward networks. In the latter application,
the cavity method provides, as far as we are aware of, the only estimate of the
hyperparameter beyond empirical stopping criteria and brute force cross-validation.
2 Steady-State Hyperparameter Estimation
Consider the network with adjustable parameters ~
w. An energy function E is
dened with respect to a set of p examples with inputs and outputs respectively
given by ~   and y  ,  = 1;    ; p, where ~   is an N-dimensional input vector with
components  
j , j = 1;    ; N , and N  1 is macroscopic. We will rst focus on
the dynamics of a single-layer feedforward network and generalize the results to
multilayer networks later. In single-layer networks, E has the form
E =
X

(x  ; y  ) +R(~w): (1)
Here (x  ; y  ) represents the error function with respect to example . It is ex-
pressed in terms of the activation x   ~
w  ~   . R(~w) represents a regularization
term which is introduced to limit the complexity of the network and hence enhance
the generalization ability. Learning is achieved by the gradient descent dynamics
dw j (t)
dt
= 1
N
@E
@w j
: (2)
The time-dependent Green's function G jk (t; s) is dened as the response of the
weight w j at time t due to a unit stimulus added at time s to the gradient term with
respect to weight w k , in the limit of a vanishing magnitude of the stimulus. Hence
if we compare the evolution of w j (t) with another system ~
w j (t) with a continuous
perturbative stimulus ∆h j (t), we would have
d ~
w j (t)
dt
= 1
N
@E
@ ~
w j
+ ∆h j (t); (3)
and the linear response relation
~
w j (t) = w j (t) +
X
k
Z
dsG jk (t; s)∆h k (s): (4)
Now we consider the evolution of the network w n
j (t) in which example  is omitted
from the training set. For a system learning macroscopic number of examples, the
changes induced by the omission of an example are perturbative, and we can assume
that the system has a linear response. Compared with the original network w j (t),
the gradient of the error of example  now plays the role of the stimulus in (3).
Hence we have
w n
j (t) = w j (t) + 1
N
X
k
Z
dsG jk (t; s) 
k
@(x  (s); y  )
@x  (s) : (5)

Multiplying both sides by  
j and summing over j, we obtain
h  (t) = x  (t) +
Z
ds
2
4 1
N
X
jk
 
j G jk (t; s) 
k
3
5 @(x  (s); y  )
@x  (s) : (6)
Here h  (t)  ~
w n (t)  ~   is called the cavity activation of example . When the
dynamics has reached the steady state, we arrive at
h  = x  + 
@(x  ; y  )
@x  ; (7)
where  = lim t!1
R
ds[
P
jk  
j G jk (t; s) 
k ]=N is the susceptibility.
At time t, the generalization error is dened as the error function averaged over the
distribution of input ~ , and their corresponding output y, i.e.,
 g (t) =
Z
d ~ P ( ~
)
Z
dyP (yj)(x; y); (8)
where x  ~
w  ~
 is the network activation. The leave-one-out generalization error is
an estimate of  g given in terms of the cavity activations h  by ^  g =
P
 (h  ; y  )=p.
Hence if we can estimate the Green's function, the cavity activation in (7) provides
a convenient way to estimate the leave-one-out generalization error without really
having to undergo the validation process.
While self-consistent equations for the Green's function have been derived using
diagrammatic methods [9], their solutions cannot be computed except for the spe-
cic case of time-translational invariant Green's functions, such as those in Adaline
learning or linear regression. However, the linear response relation (4) provides a
convenient way to measure the Green's function in the general case. The basic idea
is to perform two learning processes in parallel, one following the original process
(2) and the other having a constant stimulus as in (3) with ∆h j (t) = ∆ jk , where
∆ jk is the Kronecka delta. When the dynamics has reached the steady state, the
measurement ~
w j w j yields the quantity 
P
k
R
dsG jk (t; s).
A simple averaging procedure, replacing all the pairwise measurements between the
stimulation node k and observation node j, can be applied in the limit of large
N . We rst consider the case in which the inputs are independent and normalized,
i.e., h j i = 0, h j  k i = ∆ jk . In this case, it has been shown that the o-diagonal
Green's functions can be neglected, and the diagonal Green's functions become self-
averaging, i.e., G jk (t; s) = G(t; s)∆ jk , independent of the node labels [9], rendering
 = lim t!1
R
dsG(t; s).
In the case that the inputs are correlated and not normalized, we can apply standard
procedures of whitening transformation to make them independent and normalized
[1]. In large networks, one can use the diagrammatic analysis in [9] to show that
the (unknown) distribution of inputs does not change the self-averaging property of
the Green's functions after the whitening transformation. Thereafter, the measure-
ment of Green's functions proceeds as described in the simpler case of independent
and normalized inputs. Since hyperparameter estimation usually involves a series
of computing ^ g at various hyperparameters, the one-time preprocessing does not
increase the computational load signicantly.
Thus the susceptibility  can be measured by comparing the evolution of two pro-
cesses: one following the original process (2), and the other having a constant
stimulus as in (3) with ∆h j (t) =  for all j. When the dynamics has reached the
steady state, the measurement h ~
w j w j i yields the quantity .

We illustrate the extension to two-layer networks by considering the committee ma-
chine, in which the error function takes the form (
P
a f(x a ); y), where a = 1;    ; n h
is the label of a hidden node, x a  ~
w a  ~
 is the activation at the hidden node a,
and f represents the activation function. The generalization error is thus a function
of the cavity activations of the hidden nodes, namely, ^  g =
P
 (
P
a f(h 
a ); y  )=p,
where h 
a = ~
w n
a  ~   . When the inputs are independent and normalized, they are
related to the generic activations by
h 
a = x 
a +
X
b
 ab
@(
P
c f(x 
c ); y  )
@x 
b
; (9)
where  ab = lim t!1
R
dsG ab (t; s) is the susceptibility tensor. The Green's function
G ab (t; s) represents the response of a weight feeding hidden node a due to a stimulus
applied at the gradient with respect to a weight feeding node b. It is obtained by
monitoring n h + 1 learning processes, one being original and each of the other n h
processes having constant stimuli at the gradients with respect to one of the hidden
nodes, viz.,
d ~
w (b)
aj (t)
dt
= 1
N
@E
@ ~
w (b)
aj
+ ∆ ab ; b = 1;    ; n h : (10)
When the dynamics has reached the steady state, the measurement h ~
w (b)
aj w aj i
yields the quantity  ab .
We will also compare the results with those obtained by extending the analysis of
linear unlearning leave-one-out (LULOO) validation [6]. Consider the case that the
regularization R(~w) takes the form of a weight decay term, R(~w) = N
P
ab  ab ~
w a 
~
w b =2. The cavity activations will be given by
h 
a = x 
a +
X
b
  1
N
P
jk  
j ( +Q) 1
aj;bk  
k
1  00

N
P
cjdk  
j f 0 (x 
c )( +Q) 1
cj;dk f 0 (x 
d ) 
k
!
@(
P
c f(x 
c ); y  ))
@x 
b
;
(11)
where  00
 represents the second derivative of  with respect to the student output
for example , and the matrix  aj;bk =  ab ∆ jk and Q is given by
Q aj;bk = 1
N
X

 
j f 0 (x 
a )f 0 (x 
b ) 
k : (12)
The LULOO result of (11) diers from the cavity result of (9) in that the suscep-
tibility  ab now depends on the example label , and needs to be computed by
inverting the matrix  + Q. Note also that second derivatives of the error term
have been neglected.
To verify the proposed method by simulations, we generate examples from a noisy
teacher network which is a committee machine
y  =
nh
X
a=1
erf
 1
p
2
~
B a  ~
 

+ z : (13)
Here ~
B a is the teacher vector at the hidden node a.  is the noise level.  
j and
z  are Gaussian variables with zero means and unit variances. Learning is done by
the gradient descent of the energy function
E =
X

1
2
"
y 
X
a
erf
 1
p
2 ~
w a  ~  
 # 2
+ 1
2 N
X
a
w 2
a (14)

and the weight decay parameter  is the hyperparameter to be optimized. The
generalization error  g is given by
 g =
*
1
2
" X
a
erf
 1
p
2
~
B a  ~ 

+ z
X
a
erf
 1
p
2 ~
w a  ~

 # 2 +
; (15)
where the averaging is performed over the distribution of input ~  and noise z. It can
be computed analytically in terms of the inner products Q ab = ~
w a  ~
w b , T ab = ~
B a  ~
B b
and R ab = ~
B a  ~
w b [10]. However, this target result is only known by the teacher,
since T ab and R ab are not accessible by the student.
Figure 1 shows the simulation results of 4 randomly generated samples. Four results
are compared: the target generalization error observed by the teacher, and those
estimated by the cavity method, cross-validation and extended LULOO. It can
be seen that the cavity method yields estimates of the optimal weight decay with
comparable precision as the other methods.
For a more systematic comparison, we search for the optimal weight decay in 10 sam-
ples using golden section search [11] for the same parameters as in Fig. 1. Compared
with the target results, the standard deviations of the estimated optimal weight de-
cays are 0.3, 0.25 and 0.24 for the cavity method, sevenfold cross-validation and
extended LULOO respectively. In another simulation of 80 samples of the single-
layer perceptron, the estimated optimal weight decays have standard deviations of
1.2, 1.5 and 1.6 for the cavity method, tenfold cross-validation and extended LU-
LOO respectively (the parameters in the simulations are N = 500, p = 400 and 
ranging from 0.98 to 2.56).
To put these results in perspective, we mention that the computational resources
needed by the cavity method is much less than the other estimations. For example,
in the single-layer perceptrons, the CPU time needed to estimate the optimal weight
decay using the golden section search by the teacher, the cavity method, tenfold
cross-validation and extended LULOO are in the ratio of 1 : 1.5 : 3.0 : 4.6.
Before concluding this section, we mention that it is possible to derive an expression
of the gradient d^ g =d of the estimated generalization error with respect to the
weight decay. This provides us an even more powerful tool for hyperparameter
estimation. In the case of the search for one hyperparameter, the gradient enables
us to use the binary search for the zero of the gradient, which converges faster
than the golden section search. In the single-layer experiment we mentioned, its
precision is comparable to vefold cross-validations, and its CPU time is only 4%
more than the teacher's search. Details will be presented elsewhere. In the case of
more than one hyperparameters, the gradient information will save us the need for
an exhaustive search over a multidimensional hyperparameter space.
3 Dynamical Hyperparameter Estimation
The second example concerns the estimation of a dynamical hyperparameter,
namely the optimal early stopping time, in cases where overtraining may plague
the generalization ability at the steady state. In perceptrons, when the examples
are noisy and the weight decay is weak, the generalization error decreases in the
early stage of learning, reaches a minimum and then increases towards its asymp-
totic value [12, 9]. Since the early stopping point sets in before the system reaches
the steady state, most analyses based on the equilibrium state are not applicable.
Cross-validation stopping has been proposed as an empirical method to control
overtraining [13]. Here we propose the cavity method as a convenient alternative.

0.40
0.46
0.52
generalization
error
target
cavity
LULOO
c-v
0 1
weight decay l
0.40
0.46
generalization
error
0 1 2
weight decay l
(a) (b)
(c) (d)
Figure 1: (a-d) The dependence of the generalization error of the multilayer percep-
tron on the weight decay for N = 200, p = 700, n h = 3,  = 0:8 in 4 samples. The
solid symbols locate the optimal weight decays estimated by the teacher (circle), the
cavity method (square), extended LULOO (diamond) and sevenfold cross-validation
(triangle).
In single-layer perceptrons, the cavity activations of the examples evolve according
to (6), enabling us to estimate the dynamical evolution of the estimated general-
ization error when learning proceeds. The remaining issue is the measurement of
the time-dependent Green's function. We propose to introduce an initial homoge-
neous stimulus, that is, ∆h j (t) = ∆(t) for all j. Again, assuming normalized and
independent inputs with h j i = 0 and h j  k i = ∆ jk , we can see from (4) that the
measurement h ~
w j (t) w j (t)i yields the quantity G(t; 0).
We will rst consider systems that are time-translational invariant, i.e., G(t; s) =
G(t s; 0). Such are the cases for Adaline learning and linear regression [9], where
the cavity activation can be written as
h  (t) = x  (t) +
Z
dsG(t s; 0) @(x  (s); y  )
@x  (s) : (16)
This allows us to estimate the generalization error ^  g (t) via ^  g (t) =
P
 (h  (t); y  )=p, whose minimum in time determines the early stopping point.
To verify the proposed method in linear regression, we randomly generate exam-
ples from a noisy teacher with y  = ~
B  ~   + z . Here ~
B is the teacher vec-
tor with B 2 = 1.  
j and z  are independently generated with zero means and
unit variances. Learning is done by the gradient descent of the energy function
E(t) =
P
 (y  ~
w(t)  ~
  ) 2 =2. The generalization error  g (t) is the error av-
eraged over the distribution of input ~  and their corresponding output y, i.e.,
 g (t) = h( ~
B  ~  + z ~
w  ~ ) 2 =2i. As far as the teacher is concerned,  g (t) can
be computed as  g (t) = (1 2R(t) + Q(t) +  2 )=2. where R(t) = ~
w(t)  ~
B and
Q(t) = w(t) 2 .
Figure 2 shows the simulation results of 6 randomly generated samples. Three re-
sults are compared: the teacher's estimate, the cavity method and cross-validation.
Since LULOO is based on the equilibrium state, it cannot be used in the present

context. Again, we see that the cavity method yields estimates of the early stop-
ping time with comparable precision as cross-validation. The ratio of the CPU time
between the cavity method and vefold cross-validation is 1 : 1.4.
For nonlinear regression and multilayer networks, the Green's functions are not
time-translational invariant. To estimate the Green's functions in this case, we have
devised another scheme of stimuli. Preliminary results for the determination of the
early stopping point are satisfactory and nal results will be presented elsewhere.
0.7
0.9
1.1
generalization
error
target
cavity
c-v
0 2
time t
0.7
0.9
generalization
error
0 2
time t
0 2 4
time t
(a) (b) (c)
(d) (e) (f)
Figure 2: (a-f) The evolution of the generalization error of linear regression for
N = 500, p = 600 and  = 1. The solid symbols locate the early stopping points
estimated by the teacher (circle), the cavity method (square) and vefold cross-
validation (diamond).
4 Conclusion
We have proposed a method for the fast estimation of hyperparameters in large
networks, based on the linear response relation in the cavity method, combined
with an empirical method of measuring the Green's function. Its e∆ciency depends
on the independent and identical distribution of the inputs, greatly reducing the
number of networks to be monitored. It does not require the validation process
or the inversion of matrices of macroscopic size, and hence its speed compares
favorably with cross-validation and other perturbative approaches such as extended
LULOO. For multilayer networks, we will explore further speedup of the Green's
function measurement by multiplexing the stimuli to the dierent hidden units into
a single network, to be compared with a reference network. We will also extend the
technique to other benchmark data to study its applicability.
Our initial success indicates that it is possible to generalize the method to more
complicated systems in the future. The concept of Green's functions is very general,
and its measurement by comparing the states of a stimulated system with a reference
one can be adopted to general cases with suitable adaptation. Recently, much
attention is paid to the issue of model selection in support vector machines [3, 4, 5].
It would be interesting to consider how the proposed method can contribute to these
cases.

Acknowledgements
We thank C. Campbell for interesting discussions and H. Nishimori for encourage-
ment. This work was supported by the grant HKUST6157/99P from the Research
Grant Council of Hong Kong.
References
[1] C. M. Bishop, Neural Networks for Pattern Recognition, Clarendon Press, Oxford
(1995).
[2] G. B. Orr and K.-R. Muller, eds., Neural Networks: Tricks of the Trade, Springer,
Berlin (1998).
[3] O. Chapelle and V. N. Vapnik, Advances in Neural Information Processing Systems
12, S. A. Solla, T. K. Leen and K.-R. Muller, eds., MIT Press, Cambridge, 230 (2000).
[4] S. S. Keerthi, Technical Report CD-01-02,
http://guppy.mpe.nus.edu.sg/ mpessk/nparm.html (2001).
[5] M. Opper and O. Winther, Advances in Large Margin Classiers, A. J. Smola, P.
Bartlett, B. Scholkopf and D. Schuurmans, eds., MIT Press, Cambridge, 43 (1999).
[6] J. Larsen and L. K. Hansen, Advances in Computational Mathematics 5, 269 (1996).
[7] M. Opper and O. Winther, Phys. Rev. Lett. 76, 1964 (1996).
[8] A. L. Fetter and J. D. Walecka, Quantum Theory of Many-Particle Systems, McGraw-
Hill, New York (1971).
[9] K. Y. M. Wong, S. Li and Y. W. Tong, Phys. Rev. E 62, 4036 (2000).
[10] D. Saad and S. A. Solla, Phys. Rev. Lett. 74, 4337 (1995).
[11] W. H. Press, B. P. Flannery, S. A. Teukolsky and W. T. Vetterling, Numerical
Recipes in C: The Art of Scientic Computing, Cambridge University Press, Cam-
bridge (1990).
[12] A. Krogh and J. A. Hertz, J. Phys. A 25, 1135 (1992).
[13] S. Amari, N. Murata, K.-R. Muller, M. Finke and H. H. Yang, IEEE Trans. on Neural
Networks 8, 985 (1997).

