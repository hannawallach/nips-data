Universality and individuality in a neural
code
Elad Schneidman, 1;2 Naama Brenner, 3 Naftali Tishby, 1;3
Rob R. de Ruyter van Steveninck, 3 William Bialek 3
1 School of Computer Science and Engineering, Center for Neural Computation and
2 Department of Neurobiology, Hebrew University, Jerusalem 91904, Israel
3 NEC Research Institute, 4 Independence Way, Princeton, New Jersey 08540, USA
felads,tishbyg@cs.huji.ac.il, fbialek,ruyter,naamag@research.nj.nec.com
Abstract
The problem of neural coding is to understand how sequences of
action potentials (spikes) are related to sensory stimuli, motor out-
puts, or (ultimately) thoughts and intentions. One clear question
is whether the same coding rules are used by dierent neurons, or
by corresponding neurons in dierent individuals. We present a
quantitative formulation of this problem using ideas from informa-
tion theory, and apply this approach to the analysis of experiments
in the y visual system. We nd signicant individual dierences
in the structure of the code, particularly in the way that tempo-
ral patterns of spikes are used to convey information beyond that
available from variations in spike rate. On the other hand, all the
ies in our ensemble exhibit a high coding e∆ciency, so that every
spike carries the same amount of information in all the individuals.
Thus the neural code has a quantiable mixture of individuality
and universality.
1 Introduction
When two people look at the same scene, do they see the same things? This basic
question in the theory of knowledge seems to be beyond the scope of experimental
investigation. An accessible version of this question is whether dierent observers of
the same sense data have the same neural representation of these data: how much
of the neural code is universal, and how much is individual?
Dierences in the neural codes of dierent individuals may arise from various
sources: First, dierent individuals may use dierent `vocabularies' of coding sym-
bols. Second, they may use the same symbols to encode dierent stimulus features.
Third, they may have dierent latencies, so they `say' the same things at slightly
dierent times. Finally, perhaps the most interesting possibility is that dierent
individuals might encode dierent features of the stimulus, so that they `talk about
dierent things'.
If we are to compare neural codes we must give a quantitative denition of similarity
or divergence among neural responses. We shall use ideas from information theory

[1, 2] to quantify the the notions of distinguishability, functional equivalence and
content in the neural code. This approach does not require a metric either on the
space of stimuli or on the space of neural responses (but see [3]); all notions of
similarity emerge from the statistical structure of the neural responses.
We apply these methods to analyze experiments on an identied motion sensitive
neuron in the y's visual system, the cell H1 [4]. Many invertebrate nervous systems
have cells that can be named and numbered [5]; in many cases, including the motion
sensitive cells in the y's lobula plate, a small number of neurons is involved in
representing a similarly identiable portion of the sensory world. It might seem
that in these cases the question of whether dierent individuals share the same
neural representation of the visual world would have a trivial answer. Far from
trivial, we shall see that the neural code even for identied neurons in ies has
components which are common among ies and signicant components which are
individual to each y.
2 Distinguishing ies according to their spike patterns
Nine dierent ies are shown precisely the same movie, which is repeated many times
for each y (Figure 1a). As we show the movie we record the action potentials from
the H1 neuron. 1 The details of the stimulus movie should not have a qualitative
impact on the results, provided that the movie is su∆ciently long and rich to drive
the system through a reasonable and natural range of responses. Figure 1b shows a
portion of the responses of the dierent ies to the visual stimulus { the qualitative
features of the neural response on long time scales ( 100 ms) are common to almost
all the ies, and some aspects of the response are reproducible on a (few) millisecond
time scale across multiple presentations of the movie to each y. Nonetheless the
responses are not identical in the dierent ies, nor are they perfectly reproduced
from trial to trial in the same y.
To analyze similarities and dierences among the neural codes, we begin by dis-
cretizing the neural response into time bins of size t = 2 ms. At this resolution
there are almost never two spikes in a single bin, so we can think of the neural
response as a binary string, as in Fig. 1c-d. We examine the response in blocks or
windows of time having length T , so that an individual neural response becomes
a binary `word' W with T=t 'letters'. Clearly, any xed choice of T and t is
arbitrary, and so we explore a range of these parameters.
Figure 1f shows that dierent ies `speak' with similar but distinct vocabularies.
We quantify the divergence among vocabularies by asking how much information
the observation of a single word W provides about the identity of its source, that
is about the identity of the y which generates this word:
I(W ! identity; T ) =
N
X
i=1
P i
X
W
P i (W ) log 2
 P i (W )
P ens (W )

bits; (1)
1 The stimulus presented to the ies is a rigidly moving pattern of vertical bars, ran-
domly dark or bright, with average intensity 
I  100 mW=(m 2  sr). The pattern position
was dened by a pseudorandom sequence, simulating a diusive motion or random walk.
Recordings were made from the H1 neuron of immobilized ies, using standard methods.
We draw attention to three points relevant for the present analysis: (1) The ies are freshly
caught female Calliphora, so that our `ensemble of ies' approaches a natural ensemble.
(2) In each y we identify the H1 cell as the unique spiking neuron in the lobula plate
that has a combination of wide eld sensitivity, inward directional selectivity for horizon-
tal motion, and contralateral projection. (3) Recordings are rejected only if raw electrode
signals are excessively noisy or unstable.

-200
0
200
Velocity
(
∞
/s)
Stimulus
0 0 1 0 0 0
Trial
Fly 1
3306 3318
0 1 0 0 0 1
Time (ms)
Trial
Fly 6
3 3.1 3.2 3.3 3.4 3.5
Time (s)
Fly 9
Fly 8
Fly 7
Fly 6
Fly 5
Fly 4
Fly 3
Fly 2
Fly 1
Spike trains
0.3
0.2
0.1
0
0.1
0.2
0.3
word
probability P Fly 1 (W|t=3306)
P Fly 6 (W|t=3306)
Word distribution @ t
0 20 40 60
0.7
0.6
0.04 0.02
0
0.02
0.04
0.6
0.7
/ /
/ /
binary word value
word
probability P Fly 1 (W)
P Fly 6 (W)
Total word distribution
a
b
c
d
e
f
Figure 1: Dierent ies' spike trains and word statistics. (a) All ies view the
same random vertical bar pattern moving across their visual eld with a time dependent
velocity, part of which is shown. In the experiment, a 40 sec waveform is presented
repeatedly, 90 times. (b) A set of 45 response traces to the part of the stimulus shown
in (a) from each of the 9 ies. The traces are taken from the segment of the experiment
where the transient responses have decayed. (c) Example of construction of the local word
distributions. Zooming in on a segment of the repeated responses of y 1 to the visual
stimuli, the y's spike trains are divided into contiguous 2 ms bins, and the spikes in each
of the bins are counted. For example, we get the 6 letter words that the y used at time
3306 ms into the input trace. (d) Similar as (c) for y 6. (e) The distributions of words
that ies 1 and 6 used at time t = 3306 ms from the beginning of the stimulus. The time
dependent distributions, P 1 (W jt = 3306 ms) and P 6 (W jt = 3306 ms) are presented as a
function of the binary value of the actual 'word', e.g., binary word value 0 17 0 stands for
the word 0 010001 0 . (f) Collecting the words that each of the ies used through all of the
visual stimulus presentations, we get the total word distributions for ies 1 and 6, P 1 (W )
and P 6 (W ).
where P i = 1=N is the a priori probability that we are recording from y i, P i (W )
is the probability that y i will generate (at some time) the word W in response
to the stimulus movie, and P ens (W ) is the probability that any y in the whole
ensemble of ies would generate this word,
P ens (W ) =
N
X
i=1
P i P i (W ): (2)
The measure I(W ! identity; T ) has been discussed by Lin [11] as the `Jensen{
Shannon divergence' D JS among the distributions P i (W ). 2
2 Unlike the Kullback{Leibler divergence [2] (the 'standard' choice for measuring dissim-
ilarity among distributions), the Jensen{Shannon divergence is symmetric, and bounded
(see also [12]). Moreover, DJS can be used to bound other measures of similarity, such as
the optimal or Bayesian probability of identifying correctly the origin of a sample.

We nd that information about identity is accumulating at more or less constant
rate well before the undersampling limits of the experiment are reached (Fig. 2a).
Thus I(W ! identity; T )  R(W ! identity)  T ; R(W ! identity)  5 bits/s,
with a very weak dependence on the time resolution t. Since the mean spike rate
can be measured by counting the number of 1s in each word W , this information
includes the dierences in ring rate among the dierent ies.
Even if ies use very similar vocabularies, they may dier substantially in the way
that they associate words with particular stimulus features. Since we present the
stimulus repeatedly to each y, we can specify the stimulus precisely by noting the
time relative to the beginning of the stimulus. We can therefore consider the word
W that the i th y will generate at time t. This word is drawn from the distribution
P i (W jt) which we can sample, as in Fig. 1c{e, by looking across multiple presen-
tations of the same stimulus movie. In parallel with the discussion above, we can
measure the information that the word W observed at known t gives us about the
identity of the y,
I(W ! identityjt; T ) =
N
X
i=1
P i
X
W
P i (W jt) log 2
 P i (W jt)
P ens (W jt)

; (3)
where the distribution of words used at time t by the whole ensemble of ies is
P ens (W jt) =
N
X
i=1
P i P i (W jt): (4)
The natural quantity is an average over all times t,
I(fW; tg ! identity; T ) = hI(W ! identityjt; T )i t bits; (5)
where h  i t denotes an average over t.
Figure 2b shows a plot of I(fW; tg ! identity; T )=T as a function of the observation
time window of size T . Observing both the spike train and the stimulus together
provides 32  1 bits=s about the identity of the y. This is more than six times as
much information as we can gain by observing the spike train alone, and corresponds
to gaining one bit in  30 ms; correspondingly, a typical pair of ies in our ensemble
can be distinguished reliably in  30 ms. This is the time scale on which ies actually
use their estimates of visual motion to guide their ight during chasing behavior
[6], so that the neural codes of dierent individuals are distinguishable on the time
scales relevant to behavior.
3 Dierent ies encode dierent amounts of information
about the same stimulus
Having seen that we can distinguish reliably among individual ies using relatively
short samples of the neural response, we turn to ask whether these substantial
dierences among codes have an impact on the ability of these cells to convey
information about the visual stimulus. As discussed in Refs. [7, 8], the information
which the neural response of the i th y provides about the stimulus, I i (W ! s(t); T ),
is determined by the same probability distributions dened above: 3
I i (W ! s(t); T ) =
* X
W
P i (W jt) log 2
 P i (W jt)
P i (W )
 +
t
: (6)
3 Again we note that our estimate of the information rate itself is independent of any
metric in the space of stimuli, nor does it depend on assumptions about which stimulus
features are most important in the code.

0 5 10 15 20 25 30
0
0.01
0.02
0.03
0.04
0.05
Word length (msec)
Info
about
identity
(bits/msec)
Fly 1 vs mixture
Fly 6 vs mixture
0 5 10 15 20 25 30
Word length (msec)
Fly 1 vs mixture
Fly 6 vs mixture
a b
Figure 2: Distinguishing one y from others based on spike trains. (a) The
average rate of information gained about the identity of a y from its word distribution,
as a function of the word size used (middle curve). The information rate is saturated
even before we reach the maximal word length used. Also shown is the average rate of
information that the word distribution of y 1 (and 6) gives about its identity, compared
with the word distribution mixture of all of the ies. The connecting line is used for
clarication only. (b) Similar to (a), we compute the average amount of information that
the distribution of words the y used at a specic point in time gives about its identity.
Averaging over all times, we show the amount of information gained about the identity of
y 1 (and 6) based on its time dependent word distributions, and the average over the 9
ies (middle curve). Error bars were calculated as in [8]. A \baseline calculation", where
we subdivided the spike trains of one y into articial new individuals, and compared their
spike trains, gave signicantly smaller values (not shown).
Figure 3a shows that the ies in our ensemble span a range of information rates
from  50 to  150 bits=s. This threefold range of information rates is correlated
with the range of spike rates, so that each of the cells transmits nearly a constant
amount of information per spike, 2:39  0:24 bits=spike. This universal e∆ciency
(10% variance over the population, despite three fold variations in total spike rate),
reects that cells with higher ring rates are not generating extra spikes at random,
but rather each extra spike is equally informative about the stimulus.
Although information rates are correlated with spike rates, this does not mean
that information is carried by a \rate code" alone. To address the rate/timing
distinction we compare the total information rate in Fig. 3a, which includes the
detailed structure of the spike train, with the information carried in the temporal
modulations of the spike rate. As explained in Ref. [10], the information carried by
the arrival time of a single spike can be written as an integral over the time variations
of the spike rate, and multiplying by the number of spikes gives us the expected
information rate if spikes contribute independently; information rates larger than
this represent synergy among spikes, or extra information in the temporal patterns
of spike. For all the ies in our ensemble, the total rate at which the spike train
carries information is substantially larger than the `single spike' information|2:39
vs. 1:64 bits/spike, on average. This extra information is carried in the temporal
patterns of spikes (Fig. 3b).
4 A universal codebook?
Even though ies dier in the structures of their neural responses, distinguishable
responses could be functionally equivalent. Thus it might be that all ies could be

0 20 40 60
0
20
40
60
80
100
Firing rate (spikes/sec)
Extra
information
from
temporal
structure
(%)
0 20 40 60
0
50
100
150
Firing rate (spikes/sec)
Information
about
stimulus
(bits/sec)
a b
Figure 3: The information about the stimulus that a y's spike train carries
is correlated with ring rate, and yet a signicant part is in the temporal
structure. (a) The rate at the H1 spike train provides information about the visual
stimulus is shown as a function of the average spike rate, with each y providing a single
data point The linear t of the data points for the 9 ies corresponds to a universal rate
of 2:39  0:24 bits=spike, as noted in the text. (b) The extra amount of information that
the temporal structure of the spike train of each of the ies carry about the stimulus,
as a function of the average ring rate of the y (see [10]). The average amount of
additional information that is carried by the temporal structure of the spike trains, over
the population is 45  17%. Error bars were calculated as in [8]
endowed (genetically?) with a universal or consensus codebook that allows each
individual to make sense of her own spike trains, despite the dierences from her
conspecics. Thus we want to ask how much information we lose if the identity of
the ies is hidden from us, or equivalently how much each y can gain by knowing
its own individual code.
If we observe the response of a neuron but don't know the identity of the individual
generating this response, then we are observing responses drawn from the ensemble
distributions dened above, P ens (W jt) and P ens (W ). The information that words
provide about the visual stimulus then is
I mix (W ! s(t); T ) =
* X
W
P ens (W jt) log 2
 P ens (W jt)
P ens (W )
 +
t
bits: (7)
On the other hand, if we know the identity of the y to be i, we gain the information
that its spike train conveys about the stimulus, I i (W ! s(t); T ), Eq. (6). The
average information loss is then
I avg
loss (W ! s(t); T ) =
N
X
i=1
P i I i (W ! s(t); T ) I mix (W ! s(t); T ): (8)
After some algebra it can be shown that this average information loss is related to
the information that the neural responses give about the identity of the individuals,
as dened above:
I avg
loss (W ! s(t); T ) = I(fW; tg ! identity; T )
I(W ! identity; T ): (9)
The result is that, on average, not knowing the identity of the y limits us to
extracting only 64 bits/s of information about the visual stimulus. This should be

compared with the average information rate of 92:3 bits/s in our ensemble of ies:
knowing her own identity allows the average y to extract 44% more information
from H1. Further analysis shows that each individual y gains approximately the
same relative amount of information from knowing its personal codebook.
5 Discussion
We have found that the ies use similar yet distinct set of `words' to encode informa-
tion about the stimulus. The main source of this dierence is not in the total set of
words (or spike rates) but rather in how (i.e. when) these words are used to encode
the stimulus; taking this into account the ies are discriminable on time scales of
relevance to behavior. Using their dierent codes, the ies' H1 spike trains convey
very dierent amounts of information from the same visual inputs. Nonetheless, all
the ies achieve a high and constant e∆ciency in their encoding of this information,
and the temporal structure of their spike trains adds nearly 50% more information
than that carried by the rate.
So how much is universal and how much is individual? We nd that each individual
y would lose  30% of the visual information carried by this neuron if it `knew' only
the codebook appropriate to the whole ensemble of ies. We leave the judgment
of whether this is high individuality or not to the reader, but recall that this is
the individuality in an identied neuron. Hence, we should expect that all neural
circuits|both vertebrate and invertebrate|express a degree of universality and a
degree of individuality. We hope that the methods introduced here will help to
explore this issue of individuality more generally.
This research was supported by a grant from the Ministry of Science, Israel.
References
[1] Shannon, C. E. A mathematical theory of communication, Bell Sys. Tech. J. 27,
379{423, 623{656 (1948).
[2] Cover, T. & Thomas J. Elements of information theory (Wiley, 1991).
[3] Victor, J. D. & Purpura, K. Nature and precision of temporal coding in visual cortex:
a metric{space analysis, J. Neurophysiol. 76, 1310{1326 (1996).
[4] Hausen, K. The lobular complex of the y, in Photoreception and vision in inverte-
brates (ed Ali, M.) pp. 523{559 (Plenum, 1984).
[5] Bullock, T. Structure and Function in the Nervous Systems of Invertebrates (W. H.
Freeman, San Francisco, 1965).
[6] Land, M. F. & Collett, T. S. Chasing behavior of houseies (Fannia canicularis). A
description and analysis, J. Comp. Physiol. 89, 331{357 (1974).
[7] de Ruyter van Steveninck, R. R., Lewen, G. D., Strong, S. P., Koberle, R. & W. Bialek,
Reproducibility and variability in neural spike trains, Science 275, 1805{1808, (1997).
[8] Strong, S. P., Koberle, R., de Ruyter van Steveninck, R. & Bialek, W. Entropy and
information in neural spike trains, Phys. Rev. Lett. 80, 197{200 (1998).
[9] Rieke, F., Warland, D., de Ruyter van Steveninck, R. & Bialek, W. Spikes: Exploring
the Neural Code (MIT Press, 1997).
[10] Brenner, N., Strong, S. P., Koberle, R., de Ruyter van Steveninck, R. & Bialek, W.
Synergy in a neural code, Neural Comp. 12, 1531{52 (2000).
[11] Lin, J., Divergence measures based on the Shannon entropy, IEEE Trans. Inf. Theory,
37, 145{151 (1991).
[12] El-Yaniv, R., Fine, S. & Tishby, N. Agnostic classication of Markovian sequences,
NIPS 10 pp. 465{471 (MIT Press, 1997).

