Error≠correcting Codes on a Bethe≠like Lattice
Renato Vicente David Saad
The Neural Computing Research Group
Aston University, Birmingham, B4 7ET, United Kingdom
fvicenter,saaddg@aston.ac.uk
Yoshiyuki Kabashima
Department of Computational Intelligence and Systems Science
Tokyo Institute of Technology, Yokohama 2268502, Japan
kaba@dis.titech.ac.jp
Abstract
We analyze Gallager codes by employing a simple mean≠field approxi≠
mation that distorts the model geometry and preserves important interac≠
tions between sites. The method naturally recovers the probability prop≠
agation decoding algorithm as an extremization of a proper free≠energy.
We find a thermodynamic phase transition that coincides with informa≠
tion theoretical upper≠bounds and explain the practical code performance
in terms of the free≠energy landscape.
1 Introduction
In the last years increasing interest has been devoted to the application of mean≠field tech≠
niques to inference problems. There are many different ways of building mean≠field theo≠
ries. One can make a perturbative expansion around a tractable model [1,2], or assume a
tractable structure and variationally determine the model parameters [3].
Error≠correcting codes (ECC) are particularly interesting examples of inference problems
in loopy intractable graphs [4]. Recently the focus has been directed to the state≠of≠the art
high performance turbo codes [5] and to Gallager and MN codes [6,7]. Statistical physics
has been applied to the analysis of ECCs as an alternative to information theory methods
yielding some new interesting directions and suggesting new high≠performance codes [8].
Sourlas was the first to relate error≠correcting codes to spin glass models [9], showing that
the Random≠energy Model [10] can be thought of as an ideal code capable of saturating
Shannon's bound at vanishing code rates. This work was extended recently to the case of
finite code rates [11] and has been further developed for analyzing MN codes of various
structures [12]. All of the analyzes mentioned above as well as the recent turbo codes
analysis [13] relied on the replica approach under the assumption of replica symmetry.
To date, the only model that can be analyzed exactly is the REM that corresponds to an
impractical coding scheme of a vanishing code rate.
Here we present a statistical physics treatment of non≠structured Gallager codes by em≠
ploying a mean≠field approximation based on the use of a generalized tree structure (Bethe

lattice [14]) known as Husimi cactus that is exactly solvable. The model parameters are
just assumed to be those of the model with cycles. In this framework the probability prop≠
agation decoding algorithm (PP) emerges naturally providing an alternative view to the re≠
lationship between PP decoding and mean≠field approximations already observed in [15].
Moreover, this approach has the advantage of being a slightly more controlled and easier
to understand than replica calculations.
This paper is organized as follows: in the next section we present unstructured Gallager
codes and the statistical physics framework to analyze them, in section 3 we make use of
the lattice geometry to solve the model exactly. In section 4 we analyze the typical code
performance. We summarize the results in section 5.
2 Gallager codes: statistical physics formulation
We will concentrate here on a simple communication model whereby messages are rep≠
resented by binary vectors and are communicated through a Binary Symmetric Channel
(BSC) where uncorrelated bit flips appear with probability f . A Gallager code is defined
by a binary matrix A = [C 1 j C 2 ], concatenating two very sparse matrices known to both
sender and receiver, with C 2 (of dimensionality (M N)  (M N)) being invertible ≠
the matrix C 1 is of dimensionality (M N) N .
Encoding refers to the production of an M dimensional binary code word t 2 f0; 1g M
(M > N ) from the original message  2 f0; 1g N by t = G T  (mod 2), where all
operations are performed in the field f0; 1g and are indicated by (mod 2). The generator
matrix is G = [I j C 1
2
C 1 ] (mod 2), where I is the N N identity matrix, implying that
AG T (mod 2) = 0 and that the first N bits of t are set to the message . In regular Gallager
codes the number of non≠zero elements in each row of A is chosen to be exactly K. The
number of elements per column is then C = (1 R)K, where the code rate is R = N=M
(for unbiased messages). The encoded vector t is then corrupted by noise represented by
the vector  2 f0; 1g M with components independently drawn from P () = (1 f)∆()+
f∆( 1). The received vector takes the form r = G T  +  (mod 2).
Decoding is carried out by multiplying the received message by the matrix A to produce
the syndrome vector z = Ar = A (mod 2) from which an estimate b
 for the noise
vector can be produced. An estimate for the original message is then obtained as the first
N bits of r + b
 (mod 2). The Bayes optimal estimator (also known as marginal posterior
maximizer, MPM) for the noise is defined as b  j = argmax  j
P ( j j z), where  j 2 f0; 1g.
The performance of this estimator can be measured by the probability of bit error p b =
1 1=M
P M
j=1 ∆[b j ;  j ], where ∆[; ] is Kronecker's delta. Knowing the matrices C 2 and
C 1 , the syndrome vector z and the noise level f it is possible to apply Bayes' theorem and
compute the posterior probability
P ( j z) =
1
Z  [z = A(mod 2)] P ( ); (1)
where [X ] is an indicator function providing 1 if X is true and 0 otherwise. To compute
the MPM one has to compute the marginal posterior P ( j j z) =
P
i6=j P ( j z), which
in general requires O(2 M ) operations, thus becoming impractical for long messages. To
solve this problem one can use the sparseness of A to design algorithms that require O(M)
operations to perform the same task. One of these methods is the probability propagation
algorithm (PP), also known as belief propagation or sum≠product algorithm [16].
The connection to statistical physics becomes clear when the field f0; 1g is replaced by
Ising spins f1g and mod 2 sums by products [9]. The syndrome vector acquires the form
of a multi≠spin coupling J  =
Q
j2L()  j where j = 1;    ; M and  = 1;    ; (M N).

t
k
µ
t
Figure 1: Husimi cactus with K = 3 and connectivity C = 4.
The K indices of nonzero elements in the row  of a matrix A, which is not necessarily a
concatenation of two separate matrices (therefore, defining an unstructured Gallager code),
are given by L() = fj 1 ;    ; j K g, and in a column l are given by M(l) = f 1 ;    ; C g.
The posterior (1) can be written as the Gibbs distribution [12]:
P  ( j J ) =
1
Z lim
!1
exp [ H  ( ; J )] (2)
H  ( ; J ) = 
M N
X
=1
0
@ J 
Y
j2L()
 j 1
1
A F
M
X
j=1
 j :
The external field corresponds to the prior probability over the noise and has the form
F = atanh(1 2f). Note that the Hamiltonian depends on a hyper≠parameter that has to be
set as  ! 1 for optimal decoding. The disorder is trivial and can be gauged as J  7! 1
by using  j 7!  j  j . The resulting Hamiltonian is a multi≠spin ferromagnet with finite
connectivity in a random field h j = F  j . The decoding process corresponds to finding
local magnetizations at temperature  = 1, m j = h j i =1 and calculating estimates as
b
 j = sgn(m j ).
In the f1g representation the probability of bit error, acquires the form
p b = 1
2
1
2M
M
X
j=1
 j sgn(m j ); (3)
connecting the code performance with the computation of local magnetizations.
3 Bethe≠like Lattice calculation
3.1 Generalized Bethe lattice: the Husimi cactus
A Husimi cactus with connectivity C is generated starting with a polygon of K vertices
with one Ising spin in each vertex (generation 0). All spins in a polygon interact through
a single coupling J and one of them is called the base spin. In figure 1 we show the first
step in the construction of a Husimi cactus, in a generic step the base spins of the n 1
generation polygons, numbering (C 1)(K 1), are attached to K 1 vertices of a gen≠
eration n polygon. This process is iterated until a maximum generation nmax is reached,
the graph is then completed by attaching C uncorrelated branches of nmax generations at
their base spins. In that way each spin inside the graph is connected to exactly C poly≠
gons. The local magnetization at the centre m j can be obtained by fixing boundary (initial)
conditions in the 0≠th generation and iterating recursion equations until generation nmax
is reached. Carrying out the calculation in the thermodynamic limit corresponds to having
nmax  ln M generations and M !1.
The Hamiltonian of the model has the form (2) where L() denotes the polygon  of the
lattice. Due to the tree≠like structure, local quantities far from the boundary can be cal≠

culated recursively by specifying boundary conditions. The typical decoding performance
can therefore be computed exactly without resorting to replica calculations [17].
3.2 Recursion relations: probability propagation
We adopt the approach presented in [18] where recursion relations for the probability dis≠
tribution P k ( k ) of the base spin of the polygon  is connected to (C 1)(K 1) dis≠
tributions P j ( j ), with  2 M(j) n  (all polygons linked to j but ) of polygons in the
previous generation:
P k ( k ) =
1
N Tr f j
g exp
2
4 
0
@ J  k
Y
j2L()nk
 j 1
1
A + F  k
3
5 Y
2M(j)n
Y
j2L()nk
P j ( j );
(4)
where the trace is over the spins  j such that j 2 L() n k.
The effective field b
x j on a base spin j due to neighbors in polygon  can be written as :
exp ( 2bx j ) = e 2F P j ( )
P j (+)
; (5)
Combining (4) and (5) one finds the recursion relation:
exp ( 2bx k )=
Tr f j
g exp
h
J 
Q
j2L()nk  j +
P
j2L()nk (F +
P
2M(j)n b
x j ) j
i
Tr f j g exp
h
+J 
Q
j2L()nk  j +
P
j2L()nk (F +
P
2M(j)n b
x j ) j
i
(6)
By computing the traces and taking  !1 one obtains:
b x k = atanh
2
4 J 
Y
j2L()nk
tanh(F +
X
2M(j)n
b
x j )
3
5 (7)
The effective local magnetization due to interactions with the nearest neighbors in one
branch is given by b
m j = tanh(bx j ). The effective local field on a base spin j of a polygon
 due to C 1 branches in the previous generation and due to the external field is x j =
F +
P
2M(j)n b
x j ; the effective local magnetization is, therefore, m j = tanh(x j ).
Equation (7) can then be rewritten in terms of b
m j and m j and the PP equations [7,15,16]
can be recovered:
m k = tanh
0
@ F +
X
2M(j)n
atanh ( b
m k )
1
A b
m k = J
Y
j2L()nk
m j (8)
Once the magnetizations on the boundary (0≠th generation) are assigned, the local magne≠
tization m j in the central site is determined by iterating (8) and computing :
m j = tanh
0
@ F +
X
2M(j)
atanh ( b
m j )
1
A (9)
3.3 Probability propagation as extremization of a free≠energy
The equations (8) describing PP decoding represent extrema of the following free≠energy:
F(fm k ; b
m k g) =
M N
X
=1
X
i2L
ln(1 +m i b
m i )
M N
X
=1
ln(1 + J
Y
i2L
m i ) (10)

0 0.1 0.2 0.3 0.4
f
0
0.2
0.4
0.6
0.8
1
<z◊t/M>
(a)
0 0.1 0.2 0.3 0.4 0.5
f
0
0.2
0.4
0.6
0.8
1
R
(b)
Figure 2: (a) Mean normalized overlap between the actual noise vector  and decoded
noise b
 for K = 4 and C = 3 (therefore R = 1=4). Theoretical values (2), experimental
averages over 20 runs for code word lengths M = 5000 () and M = 100 (full line).
(b) Transitions for K = 6. Shannon's bound (dashed line), information theory upper
bound (full line) and thermodynamic transition obtained numerically (∆). Theoretical (3)
and experimental (+, M = 5000 averaged over 20 runs) PP decoding transitions are also
shown. In both figures, symbols are chosen larger than the error bars.
M
X
j=1
ln
2
4 e F
Y
2M(j)
(1 + b
m j ) + e F
Y
2M(j)
(1 b
m j )
3
5
The iteration of the maps (8) is actually one out of many different methods of finding
extrema of this free≠energy (not necessarily stable) . This observation opens an alternative
way for analyzing the performance of a decoding algorithm by studying the landscape (10).
4 Typical performance
4.1 Macroscopic description
The typical macroscopic states of the system during decoding can be described by his≠
tograms of the variables m k and b
m k averaged over all possible realizations of the noise
vector . By applying the gauge transformation J  7! 1 and  j 7!  j  j , assigning the
probability distributions P 0 (x) to boundary fields and averaging over random local fields
F  one obtains from (7) the recursion relation in the space of probability distributions
P (x):
Pn (x) =
Z C 1
Y
l=1
dbx l
b
Pn 1 (bx l )
*
∆
"
x F 
C 1
X
l=1
b x l
#+

b
Pn 1 (bx) =
Z K 1
Y
j=1
dx j Pn 1 (x j ) ∆
2
4 b
x atanh
0
@ K 1
Y
j=1
tanh(x j )
1
A
3
5 ; (11)
where Pn (x) is the distribution of effective fields at the n≠th generation due to the previous
generations and external fields, in the thermodynamic limit the distribution far from the
boundary will be P1 (x) (generation n ! 1). The local field distribution at the central
site is computed by replacing C 1 by C in (11), taking into account C polygons in the
generation just before the central site, and inserting the distribution P1 (x). Equations (11)
are identical to those obtained by the replica symmetric theory as in [12].

By setting initial (boundary) conditions P 0 (x) and numerically iterating (11), for C  3
one can find, up to some noise level f s , a single stable fixed point at infinite fields, corre≠
sponding to a totally aligned state (successful decoding). At f s a bifurcation occurs and
two other fixed points appear, stable and unstable, the former corresponding to a misaligned
state (decoding failure). This situation is identical to that one observed in [12]. In terms of
the free≠energy (10), below f s the landscape is dominated by the aligned state that is the
global minimum. Above f s a sub≠optimal state, corresponding to an exponentially large
number of spurious local minima of the Hamiltonian (2), appears and convergence to the
totally aligned state becomes a difficult task. At some critical noise level the totally aligned
state loses the status of global minimum and the thermodynamic transition occurs.
The practical PP decoding is performed by setting initial conditions as m j = 1 2f ,
corresponding to the prior probabilities and iterating (8), until stationarity or a maximum
number of iterations is attained. The estimate for the noise vector is then produced by com≠
puting b  j = sign(m j ). At each decoding step the system can be described by histograms
of the variables (8), this is equivalent to iterating (11) (a similar idea was presented in [7]).
Below f s the process always converges to the successful decoding state, above f s it con≠
verges to the successful decoding only if the initial conditions are fine tuned, in general
the process converges to the failure state. In Fig.2a we show the theoretical mean overlap
between actual noise  and the estimate b  as a function of the noise level f , as well as
results obtained with PP decoding.
Information theory provides an upper bound for the maximum attainable code rate by
equalizing the maximal information contents of the syndrome vector z and of the noise
estimate b  [7]. The thermodynamic phase transition obtained by finding the stable fixed
points of (11) and their free≠energies interestingly coincides with this upper bound within
the precision of the numerical calculation. Note that the performance predicted by thermo≠
dynamics is not practical as it requires O(2 M ) operations for an exhaustive search for the
global minimum of the free≠energy. In Fig.2b we show the thermodynamic transition for
K = 6 and compare with the upper bound, Shannon's bound and the theoretical f s values.
4.2 Tree≠like approximation and the thermodynamic limit
The geometrical structure of a Gallager code defined by the matrix A can be represented
by a bipartite graph (Tanner graph) [16] with bit and check nodes. Each column j of A
represents a bit node and each row  represents a check node, A j = 1 means that there
is an edge linking bit j to check . It is possible to show that for a random ensemble of
regular codes, the probability of completing a cycle after walking l edges starting from an
arbitrary node is upper bounded by P [l; K;C;M ]  l 2 K l =M . It implies that for very large
M only cycles of at least order ln M survive. In the thermodynamic limit M ! 1 the
probability P [l; K;C;M ] ! 0 for any finite l and the bulk of the system is effectively tree≠
like. By mapping each check node to a polygon with K bit nodes as vertices, one can map
a Tanner graph into a Husimi lattice that is effectively a tree for any number of generations
of order less than ln M . It is experimentally observed that the number of iterations of (8)
required for convergence does not scale with the system size, therefore, it is expected that
the interior of a tree≠like lattice approximates a Gallager code with increasing accuracy as
the system size increases. Fig.2a shows that the approximation is fairly good even for sizes
as small as M = 100.
5 Conclusions
To summarize, we solved exactly, without resorting to the replica method, a system rep≠
resenting a Gallager code on a Husimi cactus. The results obtained are in agreement with
the replica symmetric calculation and with numerical experiments carried out in systems

of moderate size. The framework can be easily extended to MN and similar codes. New
insights on the decoding process are obtained by looking at a proper free≠energy landscape.
We believe that methods of statistical physics are complimentary to those used in the statis≠
tical inference community and can enhance our understanding of general graphical models.
Acknowledgments
We acknowledge support from EPSRC (GR/N00562), The Royal Society (RV,DS) and
from the JSPS RFTF program (YK).
References
[1] Plefka, T., (1982) Convergence condition of the TAP equation for the infinite≠ranged Ising spin
glass model. Journal of Physics A 15, 1971≠1978.
[2] Tanaka, T., Information geometry of mean field approximation. to appear in Neural Computation
[3] Saul, L.K. & , M.I. Jordan (1996) Exploiting tractable substructures in intractable. In Touretzky,
D. S. , M. C. Mozer and M. E. Hasselmo (eds.), Advances in Neural Information Processing Systems
8, pp. 486≠492. Cambridge, MA: MIT Press.
[4] Frey, B.J. & D.J.C. MacKay (1998) A revolution: belief propagation in graphs with cycles. In
Jordan, M.I., M. J. Kearns and S.A. Solla (eds.), Advances in Neural Information Processing Systems
10, pp. 479≠485 . Cambridge, MA: MIT Press.
[5] Berrou, C. & A. Glavieux (1996) Near optimum error correcting coding and decoding: Turbo≠
codes, IEEE Transactions on Communications 44, 1261≠1271.
[6] Gallager, R.G. (1963) Low≠density parity≠check codes, MIT Press, Cambridge, MA.
[7] MacKay, D.J.C. (1999) Good error≠correcting codes based on very sparse matrices, IEEE Trans≠
actions on Information Theory 45, 399≠431.
[8] Kanter, I. & D. Saad (2000) Finite≠size effects and error≠free communication in Gaussian chan≠
nels, Journal of Physics A 33, 1675≠1681.
[9] Sourlas, N. (1989) Spin≠glass models as error≠correcting codes, Nature 339, 693≠695.
[10] Derrida, B. (1981) Random≠energy model: an exactly solvable model of disordered systems,
Physical Review B 24(5), 2613≠2626.
[11] Vicente, R., D. Saad & Y. Kabashima (1999) Finite≠connectivity systems as error≠correcting
codes, Physical Review E 60(5), 5352≠5366.
[12] Kabashima, Y., T. Murayama & D.Saad (2000) Typical performance of Gallager≠type error≠
correcting codes, Physical Review Letters 84 (6), 1355≠1358.
[13] Montanari, A. & N. Sourlas (2000) The statistical mechanics of turbo codes, European Physical
Journal B 18, 107≠119.
[14] Sherrington, D. & K.Y.M. Wong (1987) Graph bipartitioning and the Bethe spin glass, Journal
of Physics A 20, L785≠L791.
[15] Kabashima, Y. & D. Saad (1998) Belief propagation vs. TAP for decoding corrupted messages,
Europhysics Letters 44 (5), 668≠674.
[16] Kschischang, F.R. & B.J. Frey, (1998) Iterative decoding of compound codes by probability
probagation in graphical models, IEEE Journal on Selected Areas in Comm. 16 (2), 153≠159.
[17] Gujrati, P.D. (1995) Bethe or Bethe≠like lattice calculations are more reliable than conventional
mean≠field calculations, Physical Review Letters 74 (5), 809≠812.
[18] Rieger, H. & T.R. Kirkpatrick (1992) Disordered p≠spin interaction models on Husimi trees,
Physical Review B 45 (17), 9772≠9777.

