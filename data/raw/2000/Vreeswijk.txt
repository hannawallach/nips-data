Whence Sparseness?
C. van Vreeswijk
Gatsby Computational Neuroscience Unit
University College London
17 Queen Square, London WC1N 3AR, United Kingdom
Abstract
It has been shown that the receptive fields of simple cells in V1 can be ex­
plained by assuming optimal encoding, provided that an extra constraint
of sparseness is added. This finding suggests that there is a reason, in­
dependent of optimal representation, for sparseness. However this work
used an ad hoc model for the noise. Here I show that, if a biologically
more plausible noise model, describing neurons as Poisson processes, is
used sparseness does not have to be added as a constraint. Thus I con­
clude that sparseness is not a feature that evolution has striven for, but is
simply the result of the evolutionary pressure towards an optimal repre­
sentation.
1 Introduction
Recently there has been an resurgence of interest in using optimal coding strategies to
`explain' the response properties of neuron in the primary sensory areas [1]. Notably this
approach was used Olshausen and Field [2] to infer the receptive field of simple cells in the
primary visual cortex. To arrive at the correct results however, they had to add sparseness
of activity as an extra constraint. Others have shown that similar results are obtained if one
assumes that the neurons represent independent components of natural stimuli [3]. The fact
that these studies need to impose an extra constraint suggests strongly that the subsequent
processing of the stimuli uses either sparseness or independence of the neuronal activity.
It is therefore highly important to determine whether these constraints are really necessary.
Here it will be argued that the necessity of the sparseness constraint in these models is due
to modeling the noise in the system incorrectly. Modeling the noise in a biologically more
plausibly way leads to a representation of the input in which the sparseness of the activity
naturally follows from the optimality of the representation.
2 Gaussian Noise
Several approaches have been used to find an output that represents the input optimally,
for example, minimizing the square difference between the input and its reconstruction. In
this paper I will concentrate on a different definition of optimality, I require that the mutual

information between the input and output is maximized. If the number of output units is
at least equal to the dimensionality of the input space a perfect reconstruction of the input
is possible, unless there is noise in the system. So for an (over)­complete representation
optimal encoding only makes sense in the presence of noise. It is important to note that
the optimal solution depends on the model of noise that is taken, even if one takes the limit
where the noise goes to zero. Thus it is important to have an adequate noise model.
Most optimal coding schemes describe the neuronal output by an input­dependent mean
to which Gaussian noise is added. This is, roughly speaking, also the implicit assumption
in an optimization procedure in which the mean square reconstruction error is minimized,
but it is also often used explicitly when the the mutual information is maximized. It is
instructive to see, in the latter case, why one needs to impose extra constraints to obtain un­
ambiguous results: Assume the input s has dimension N i and is drawn from a distribution
p(s). There are N o  N i output neurons whose rates r satisfy
r = Ws+ ; (1)
where  is a N o dimensional univariate Gaussian with zero mean, p  () =
(2) No=2 exp(  T =2) (the superscript T denotes the transpose). The task is to find
the N o  N i matrix Wm that maximizes the mutual information I M between r and s,
defined by [4]
I M (r; s) =
Z
dr
Z
dsp(r; s)flog[p(rjs)] log[
Z
ds 0 p(r; s 0 )]g: (2)
Here p(r; s) is the joint probability distribution of r and s and p(rjs) is the conditional
probability of r, given s. It is immediately clear that replacing W by cW with c > 1
increases the mutual information by effectively reducing the noise by a factor 1=c. Thus
maximal mutual information is obtained as the rates become infinite. Thus, to get sensible
results, a constraint has to be placed on the rates. A natural constraint in this framework is
a constraint on the average square rates r, < r T r >= N o R 2
0 . Here I have used <    > to
denote the average over the noise and inputs and R 2
0 >  2 is the mean square rate.
Under this constraint, however, the optimal solution is still vastly degenerate. Namely if
WM is a matrix that gives the maximum mutual information, for any unitary matrix U
(U T U = 1), UWm will also maximize I M . This is straightforward to show. For r =
Wms +  the mutual information is given by
I M (r; s; Wm ) =
Z
dr
Z
ds p(s)p 
 r Wms


log

p 
 r Wms


log
Z
ds 0 p(s 0 )p 

r Wms 0


; (3)
where I have used I M (r; s; W ) to denote the mutual information when the matrix W is
used. In the case where r satisfies r = UWms +  the mutual information is given by
equation 3, with Wm replaced by UWm . Changing variables from r to r 0 = U T r and
using j det(U)j = 1, this can be rewritten as
I M (r; s; UWm ) =
Z
dr 0
Z
dsp(s)p 

U r 0 Wms


log

p 

U r 0 Wms


log
Z
ds 0 p(s 0 )p 

U r 0 Wms 0


: (4)

Because p  () is a function of  T  only, p  (U) = p  (), and therefore I m (r; s; UWm ) =
I m (r; s; Wm ). In other words, because we have assumed a model in which the noise
is described by independent Gaussians, or generally the distribution of the noise  is a
function of  T  only, the mutual information is invariant to unitary transformations of the
output. Clearly, this degeneracy is a result of the particular choice of the noise statistics and
unlikely to survive when we try to account for biologically observed noise more accurately.
In the latter case it may well happen that the degeneracy is broken in such a way that
maximizing the mutual information with a constraint on the average rates is itself sufficient
to obtain a sparse representation.
3 Poisson Noise
To obtain a robust insight in this issue, it is important that the system can be treated analyt­
ically. The desire for biologically plausibility of the system should therefore be balanced
by the desire to keep it simple. Ubiquitous features found in electrophysiological experi­
ments likely to be of importance are (see for example [5]): i) Neurons transmit information
through spikes. ii) Consecutive inter­spike intervals are at best weakly correlated. iii) With
repeated presentation of the stimulus the variance in the number of spikes a neuron emits
over a given period varies nearly linearly with the mean number of emitted spikes.
A simple model that captures all these features of the biological system is the Poisson
process [6]. I will thus consider a system in which the neurons are described by such a pro­
cess. The general model is as follows: The inputs are given by an N i dimensional vector s
drawn from a distribution p(s). These give rise to N o inputs u into the cells, which satisfy
u = Ws, where W is the coupling matrix. The inputs u are transformed into rates through
a transfer function g, r i = g(u i ). The output of the network is observed for a time T . Opti­
mal encoding of the input is defined by the maximal mutual information between the spikes
the neurons emit and the stimulus. Let n i be the total number of spikes for neuron i and
n the N o dimensional array of spike counts, then p(njr) =
Q
i (r i T ) n i exp( r i T )=n i !.
Optimal coding is achieved by determining Wm such that
Wm = argmax W (I M (n; s; W )): (5)
As before there is need for a constraint on W so that solutions with infinite rates are ex­
cluded. Whereas with Gaussian channels fixing the mean square rates is the most natural
choice for the constraint, for Poissonian neurons it is more natural to fix the mean num­
ber of emitted spikes,
P
i < r i >= N o R 0 . By rescaling time we can, without loss of
generality, assume that R 0 = 1.
4 A Simple Example
The simplest example in which we can consider whether such systems will lead a sparse
representation is a system with a single neuron and a 1 dimensional input, which is uni­
formly distributed between 0 and 1. Assume that the unit has output rate r = 0 when the
input satisfies s < 1 p and rate 1=p if s > 1 p. Because the neuron is either `on'
or `off', maximal information about its state can be obtained by checking whether it fired
either one or more spikes or did not fire at all in the time­window over which the neuron
was observed. If the neuron is `on', the probability that it does not spike in a time T is
1 exp( T=p), otherwise it is 1. Thus the probability distribution is
p(0; s) = 1 e T=p (s 1 + p); p(1+; s) = e T=p i(s 1 + p); (6)

0
0.1
0.2
0.3
0.4
0.5
0 1 2 3 4 5
p m
T
Figure 1: pm , the value of p that maximizes the mutual information as function of the
measuring time­window T .
where I have used p(1+; s) to denote the probability of 1 or more spikes and an input s.
The mutual information satisfies
I M (n; s; p) = p(1 e T=p ) log(1 e T=p ) pe T=p log(p)
(1 p(1 e T=p )) log(1 p(1 e T=p )): (7)
Figure 1 shows pm , the value of p that maximizes the mutual information, as a function
of the time T over which the neuron is observed. For small T , pm is small, this reflects
the fact that the reliability of the neuron is increased if the rate in the `on' state (1=p) is
made maximal. For large T , pm approaches 1=2, the value for which the entropy of the
output rate r is maximized. We thus see a trade­off between the reliability which wants to
make p as small as possible, and the capacity, which pushes p to 1/2. For time intervals that
are smaller than or on the order of the mean 1: inter­spike interval the former dominates
and leads to an optimal solution in which the neuron is, with a high probability, quiet, or,
with a low probability, fires vigorously. Thus in this system the neurons fire sparsely if the
measuring time is sufficiently short.
5 A More Interesting Example
Somewhat closer to the problem of optimal encoding in V1, but still tractable, is the fol­
lowing example. A two­dimensional input s is drawn from a distribution p(s) given by
p(s 1 ; s 2 ) =
1
2

Æ(s 1 )e js2 j=2 + e js1 j=2 Æ(s 2 )

: (8)
This input is encoded by four neurons, the inputs into these neurons are given by

u 1
u 2

=
1
j cos()j + j sin()j

cos() sin()
sin() cos()

s 1
s 2

; (9)
u 3 = u 1 , and u 4 = u 2 . The rates r i satisfy r i = (u i ) +  (u i + ju i j)=2, the threshold
linear function. Due to the symmetry of the problem, rotation by a multiple of =2 leads to
the same rates, up to a permutation. Thus we can restrict ourselves to 0   < =2.
It is straightforward to show that
P
i < n i >= 4, and that sparseness of the activity, here
defined by
P
i (< n 2
i > < n i > 2 )= < n i > 2 , has its minimum for  = =4, and

0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0 0.4 0.8 1.2 1.6
I M
f
Figure 2: Mutual information I M as function of , for T = 1 (solid line), for T = 2
(dashed line), and T = 3 (dotted line).
maximum for  = 0. Some straightforward algebra shows that the mutual information is
given by
I M (n; s; ) = T + log(1 + T )
1
X
n=0
 T
1 + T
 n 
log
 n
1 + T

+
1
1 + T
 j cos()j
j cos()j + j sin()j
 n
log

1 +
    sin()
cos()
   
n 
+
1
1 + T
 j sin()j
j cos()j + j sin()j
 n
log

1 +
    cos()
sin()
   
n 
(10)
Figure 2 shows the I M as a function of  for different values of T . For all values of T the
mutual information is maximal when  = 0 and minimal for =4. For large T the angular
dependent part of I M scales as 1=T . So this dependence becomes negligible if the output is
observed for a long time. Yet as in the previous example, for relatively short time­windows,
optimal coding automatically leads to sparse coding.
6 Optimal Coding in V1
Finally we turn to optimal encoding of images in the striate cortex. To study this I consider a
system in with a large number, K, of natural images. The intensity of pixel j (1  j  N i )
of image  is given by s j (). These images induce an input u i into neuron i (1  i  N o )
given by
u i () =
X
j
W ij s j (); (11)
which lead to firing rates r i () which satisfy r i () =  1 log(1 + e u i () ). Here I have
used as smoothened version of of the threshold linear function (which is recovered in the
limit  ! 1) to ensure that its derivative with respect to W ij is continuous. The neurons
fire in a Poissonian manner, so that for image  the probability P (n; ) of observing n i
spikes for neuron i is given by
p(n; ) =
No
Y
i=1
(r i ()T ) n i
n i !
e r i ()T : (12)

We want to choose the matrix such W the mutual information I M between the image  and
the spike count for the different neurons, given by
I M (n; ; W ) =
X
n
1
K
X

p(n; ; W ) [log(p(n; ; W ) log(p(n; W ))] (13)
is maximized. Obviously an analytic solution is out of the question, but one may want to
try to approach the optimal solution by gradient assent, using
@IM (n; ; W )
@W ij
=
X
n
1
K
X

@p(n; ; W )
@W i;j
[log(p(n; ; W ) log(p(n; W ))] (14)
for the derivative of the mutual information. Here the derivative of p(n; ) is given by
@p(n; )=@W i;j = s j ()(1 e  r i () (n i =r i T )p(n; ). The constraint on the rates,
K 1
P

P
i r i () = N o is incorporated by adding this function with a Lagrange multi­
plier to the objective function.
Unfortunately the gradient assent approach is impractical, since the summation over n
scales exponentially with N o . In any case, one may want to use stochastic gradient assent
to avoid getting trapped in local minima. But to do stochastic gradient assent it is sufficient
to obtain a unbiased estimate of @IM =@W ij . Denoting this derivative by @IM =@W ij =
P
n F ij (n), where F ij has the obvious meaning, one can rewrite the derivative of the
mutual information as
@IM
@W ij
=
X
n
~
p(n)
F ij (n)
~
p(n)
(15)
provided that ~
p(n) is non­zero for every n for which p(n; W ) 6= 0. An unbiased estimate
of @IM =@W ij (denoted by @ ~
I M =@W ij ) is obtained by taking
@ ~
I M
@W ij
=
1
L
L
X
`=1
F ij (n(`))
~ p(n(`)) ; (16)
where the L vectors n(`) are drawn independently from the distribution ~
p(n). Conjectur­
ing that F ij (n) is roughly proportional to p(n; W ), I set ~
p(n) = p(n; W ) to obtain the
best estimate of @IM =@W ij for fixed L. Drawing from p(n; W ) can be done in a compu­
tationally cheap way by first randomly picking  and then draw from p(n; ; W ), which
factorizes.
In the simulation of the system I have used the natural image collection from [7]. From each
of the approximately 4000 images a 1010 patch. These were preprocessed by subtracting
the mean and whitening the image. To reduce the effects of the corners a circular region
was then extracted from the images. This resulted in an input which has 80 pixel intensities
per image. These pixel intensities were encoded by 160 neurons. The coupling matrix
was initialized by drawing tits components independently from a Gaussian distribution and
rescaling the matrix to normalize < r i >. The time­window T was chosen to be T = 0:5,
and  was gradually increased from its initial value of  = 1 to  = 10. The coupling
matrix was updated using  = 10 4 , and L = 10.
Figure 3 shows the some of the receptive fields that were obtained after the system had
approached the fixed point, e.i. the running average of the mutual information no longer
increased. These receptive fields look rather similar to those obtained from simple cells
in the striate cortex. However a more thorough analysis of these receptive field and the
sparseness of the rate distribution still has to be undertaken.

Figure 3: Forty examples of receptive fields that show clear Gabor like structure.
7 Discussion
I have shown why optimal encoding using Gaussian channels naturally leads to highly
degenerate solutions necessitating extra constraints. Using the biologically more plausible
noise model which describes the neurons by Poisson processes naturally leads to a sparse
representation, when optimal encoding is enforced, for two analytically tractable models.
For a model of the striate cortex Poisson statistics also leads to a network in which the
receptive fields of the neurons mimic those of V1 simple cells, without the need to impose
sparseness. This leads to the conclusion that sparseness is not an independent constraint
that is imposed by evolutionary pressure, but rather is a consequence of optimal encoding.
References
[1] Baddeley, R., Hancock, P., and F˜oldi’ak, P. (eds.) (2000) Information Theory and the
Brain. (Cambridge University Press, Cambridge).
[2] Olshausen, B.A. and Field, D.J. (1996) Nature 381:607; (1998) Vision Research
37:3311.
[3] Bell, A.j. and Sejnowski, T.J. (1997) Vision Res. 37:3327; van Hateren, J.H. and van
der Schaaf, A. (1998) Proc. R. Soc. Lond. 265:359.
[4] Cover, T.M. and Thomas, J.A. (1991) Information Theory (Whiley and Sons, New
York).
[5] Richmond, B.J., Optican, L.M., and Spitzer, H. (1990) J. Neurophysiol. 64:351;
Rolls, E.T., Critchley, H.D., and Treves, A. (1996) J. Neurophysiol. 75:1982; Dean,
A.F. (1981) Exp. Brain. Res. 44:437.
[6] Smith, W.L. (1951) Biometrica 46:1.
[7] van Hateren, J.H. and van der Schaaf, A. (1998) Proc.R.Soc.Lond. B 265:359­366.

