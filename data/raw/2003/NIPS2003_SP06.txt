One microphone blind dereverberation based on quasi-periodicity of speech signals

Tomohiro Nakatani, Masato Miyoshi, and Keisuke Kinoshita Speech Open Lab., NTT Communication Science Labs., NTT Corporation 2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan {nak,miyo,kinoshita}@cslab.kecl.ntt.co.jp

Abstract Speech dereverberation is desirable with a view to achieving, for example, robust speech recognition in the real world. However, it is still a challenging problem, especially when using a single microphone. Although blind equalization techniques have been exploited, they cannot deal with speech signals appropriately because their assumptions are not satisfied by speech signals. We propose a new dereverberation principle based on an inherent property of speech signals, namely quasi-periodicity. The present methods learn the dereverberation filter from a lot of speech data with no prior knowledge of the data, and can achieve high quality speech dereverberation especially when the reverberation time is long. 1 Introduction Although numerous studies have been undertaken on robust automatic speech recognition (ASR) in the real world, long reverberation is still a serious problem that severely degrades the ASR performance [1]. One simple way to overcome this problem is to dereverberate the speech signals prior to ASR, but this is also a challenging problem, especially when using a single microphone. For example, certain blind equalization methods, including independent component analysis (ICA), can estimate the inverse filter of an unknown impulse response convolved with target signals when the signals are statistically independent and identically distributed sequences [2]. However, these methods cannot appropriately deal with speech signals because speech signals have inherent properties, such as periodicity and formant structure, making their sequences statistically dependent. This approach inevitably destroys such essential properties of speech. Another approach that uses the properties of speech has also been proposed [3]. The basic idea involves adaptively detecting time regions in which signal-to-reverberation ratios become small, and attenuating speech signals in those regions. However, the precise separation of the signal and reverberation durations is difficult, therefore, this approach has achieved only moderate results so far. In this paper, we propose a new principle for estimating an inverse filter by using an essential property of speech signals, namely quasi-periodicity, as a clue. In general, voiced segments in an utterance have approximate periodicity in each local time region while the period gradually changes. Therefore, when a long reverberation is added to a speech signal, signals in different time regions with different periods are mixed, thus degrading the periodicity of the signals in local time regions. By contrast, we show that we can estimate an inverse filter for dereverberating a signal by enhancing the periodicity of the signal in each


local time region. The estimated filter can dereverberate both the periodic and non-periodic parts of speech signals with no prior knowledge of the target signals, even though only the periodic parts of the signals are used for the estimation. 2 Quasi-periodicity based dereverberation We propose two dereverberation methods, referred to as Harmonicity based dEReverBeration (HERB) methods, based on the features of quasi-periodic signals: one based on an Average Transfer Function (ATF) that transforms reverberant signals into quasi-periodic components (ATF-HERB), and the other based on the Minimum Mean Squared Error (MMSE) criterion that evaluates the quasi-periodicity of target signals (MMSE-HERB). First, we briefly explain the features of quasi-periodic signals, and then describe the two methods. 2.1 Features of quasi-periodic signals When a source signal s(n) is recorded in a reverberant room1, the obtained signal x(n) is represented as x(n) = h(n)s(n), where h(n) is the impulse response of the room and "" is a convolution operation. The goal of the dereverberation is to estimate a dereverberation filter, w(n), for -N < n < N that dereverberates x(n), and to obtain the dereverberated signal y(n) by: y(n) = w(n)  x(n) = (w(n)  h(n))  s(n) = q(n)  s(n). (1) where q(n) = w(n)  h(n) is referred to as a dereverberated impulse response. Here, we assume s(n) is a quasi-periodic signal2, which has the following features: 1. In each local time region around n0 (n0 -  < n < n0 +  for n0), s(n) is



approximately a periodic signal whose period is T(n0). 2. Outside the region (|n - n0| > ), s(n ) is also a periodic signal within its neighboring time region, but often has another period that is different from T(n0). These features make x(n) a non-periodic signal even within local time regions when h(m) contains non-zero values for |m| > . This is because more than two periodic signals, s(n) and s(n - m), that have different periods, are added to x(n) with weights of h(0) and h(m). Inversely, the goal of our dereverberation is to estimate w(n) that makes y(n) a periodic signal in each local time region. Once such a filter is obtained, q(m) must have zero values for |m| > , and thus, reverberant components longer than  are eliminated from y(n). An important additional feature of a quasi-periodic signal is that quasi-periodic components in a source signal can be enhanced by an adaptive harmonic filter. An adaptive harmonic filter is a time-varying linear filter that enhances frequency components whose frequencies correspond to multiples of the fundamental frequency (F0) of the target signal, while preserving their phases and amplitudes. The filter values are adaptively modified according to F0. For example, a filter, F (f0(n))[·], can be implemented as follows:

x(n) ^

= = F (f0(n))[x(n)], g2(n - n0)Re{x(n)  (g1(n)

n0

exp(j2kf0(n0)n/fs))},

(2) (3)

k

where n0 is the center time of each frame, f0(n0) is the fundamental frequency (F0) of the signal at the frame, k is a harmonics index, g1(n) and g2(n) are analysis window and capitalized symbols, respectively. Arguments "()" that represent the center frequencies of the discrete Fourier transformation bins are often omitted from frequency domain signals. non-periodic components in the case of speech signals.

1 In this paper, time domain and frequency domain signals are represented by non-capitalized

2 Later, this assumption is extended so that s(n) is composed of quasi-periodic components and


S() H() X() W() Y()

F(f0) ^ E(X/X)

X() ^ Figure 1: Diagram of ATF-HERB functions, and fs is the sampling frequency. Even when x(n) contains a long reverberation, the reverberant components that have different frequencies from s(n) are reduced by the harmonic filter, and thus, the quasi-periodic components can be enhanced. 2.2 ATF-HERB: average transfer function based dereverberation Figure 1 is a diagram of ATF-HERB, which uses the average transfer function from reverberant signals to quasi-periodic signals. A speech signal, S(), can be modeled by the sum of the quasi-periodic components, or voiced components, Sh(), and non-periodic components, or unvoiced components, Sn(), as eq. (4). The reverberant observed signal, X(), is then represented by the product of S and the transfer function, H(), of a room as eq. (5). The transfer function, H, can also be divided into two functions, D() and R(). The former transforms S into the direct signal, DS, and the latter into the reverberation part, RS, as shown in eq. (6). X is also represented by the sum of the direct signal of the quasi-periodic components, DSh, and the other components as eq. (7).

S() X()

= = = = Sh() + Sn(), H()S(), (D() + R())S(), DSh + (RSh + HSn). (4) (5) (6) (7)

Of these components, DSh can approximately be extracted from X by harmonic filtering. Although the frequencies of quasi-periodic components change dynamically according to the changes in their fundamental frequency (F0), their reverberation remains unchanged at the same frequency. Therefore, direct quasi-periodic components, DSh, can be enhanced by extracting frequency components located at multiples of its F0. This approximated direct signal X() can be modeled as follows: ^

X() = D()Sh() + (R()Sh() + N()), ^ ^ ^ (8)

where R()Sh() and N() are part of the reverberation^of Sh and part of the direct signal assume that all the estimation errors in X are caused by RSh and N in eq. (8). and reverberation of Sn, which unexpectedly remain in X^after the ^harmonic filtering3. We ^ The goal of ATF-HERB is to estimate O(R()) = (D() + R())/H(), referred to as ^ ^ a "dereverberation operator." This is because the signal DS + RS, which can be obtained by multiplying O(R) by X, becomes in a sense a dereverberated signal.

^

^

O(R())X() = D()S() + R()S(), ^ ^ (9)

^ ^

3

Strictly speaking, R cannot be represented as a linear transformation because the reverberation ^

included in X depends on the time pattern of X. We introduce this approximation for simplicity. ^ ^


S() H() X() W() Y()

F(f0) MMSE

X() ^ Figure 2: Diagram of MMSE-HERB where the right side of eq. (9) is composed of a direct signal, DS, and certain parts of the reverberation, RS. The rest of the reverberation included in X(= DS+RS), or (R-R)S, To estimate the dereverberation operator, we use the output of the harmonic filter, X. Sup^ pose a number of X values are obtained and X values are calculated from individual X ^ values. Then, the dereverberation operator, O(R), can be approximated as the average of ^ X/X, or W () = E(X/X). W () is shown to be a good estimate of O(R) by substitut^ ^ ^ ing E(X/X) for eqs. (4), (5) and (8) as eq. (11).

^ is eliminated by the dereverberation operator. ^

^

W ()

= = E(X/X), ^ O(R())E(1 ^

1 + Sn/Sh ) + E( 1 1 + (X - N )/N

^ ^ ),

O(R())P(|Sh()| > |Sn()|), ^

(10) (11) (12)

where P(·) is a probability function. The arguments of the two average functions in eq. (11) have the form of a complex function, f(z) = 1/(1 + z). E(f(z)) is easily proven to equal P (|z| < 1), using the residue theorem if it is assumed that the phase of z is uniformly distributed, the phases of z and |z| are independent, and |z| = 1. Based on this property, the second term of eq. (11) approximately equals zero because N is a non-periodic component ^ that the harmonic filter unexpectedly extracts and thus the magnitude of N almost always ^ has a smaller value than (Y -N) if a sufficiently long analysis window is used. Therefore, ^ W () can be approximated by eq. (12), that is, W () has the value of the dereverberation operator multiplied by the probability of the harmonic components of speech with a larger magnitude than the non-periodic components. Once the dereverberation operator is calculated from the periodic parts of speech signals for almost all the frequency ranges, it can dereverberate both the periodic and non-periodic parts of the signals because the inverse transfer function is independent of the source signal characteristics. Instead, the gain of W() tends to decrease with frequency when using our method. This is because the magnitudes of the non-periodic components relative to the periodic components tend to increase with frequency for a speech signal, and thus the P(|Sh| > |Sn|) value becomes smaller as  increases. To compensate for this decreasing gain, it may be useful to use the average attributes of speech on the probability, P (|Sh| > |Sn|). In our experiments in section 4, however, W () itself was used as the dereverberation operator without any compensation. 2.3 MMSE-HERB: minimum mean squared error criterion based dereverberation As discussed in section 2.1, quasi-periodic signals can be dereverberated simply by enhancing their quasi-periodicity. To implement this principle directly, we introduce a cost


function, referred to as the minimum mean squared error (MMSE) criterion, to evaluate the quasi-periodicity of the signals as follows:

C(w) = (y(n) - F (f0(n))[y(n)])2 =

n n

(w(n)  x(n) - F (f0(n))[w(n)  x(n)])2, (13)

where y(n) = w(n)  x(n) is a target signal that should be dereverberated by controlling w(n), and F (f0(n))[y(n)] is a signal obtained by applying a harmonic filter to y(n). When y(n) is a quasi-periodic signal, y(n) approximately equals F (f0(n))[y(n)] because of the feature of quasi-periodic signals, and thus, the above cost function is expected to have the minimum value. Inversely, the filter, w(n), that minimizes C(w) is expected to enhance the quasi-periodicity of x(n). Such filter parameters can, for example, be obtained using optimization algorithms such as a hill-climbing method using the derivatives of C(w) calculated as follows:

C(w) w(l) = 2 (y(n) - F (f0(n))[y(n)])(x(n - l) - F (f0(n))[x(n - l)]), (14)

n

where F(f0(n))[x(n - l)]) is a signal obtained by applying the adaptive harmonic filter to x(n - l)4. There are, however, several problems involved in directly using eq. (13) as the cost function. 1. As discussed in section 2.1, the values of the dereverberated impulse response, q(n), are expected to become zero using this method where |n| > , however, the values are not specifically determined where |n| < . This may cause unexpected spectral modification of the dereverberated signal. Additional constraints are required in order to specify these values. 2. The cost function has a self-evident solution, that is, w(l) = 0 for all l values. This solution means that the signal, y(n), is always zero instead of being dereverber-

ated, and therefore, should be excluded. Some constraints, such as may be useful for solving this problem. l

w(l)2 = 1,

3. The complexity of the computing needed to minimize the cost function based on repetitive estimation increases as the dereverberation filter becomes longer. The longer the reverberation becomes, the longer the dereverberation filter should be. To overcome these problems, we simplify the cost function in this paper. The new cost function is defined as follows:

C(W ()) = E((Y () - X())2) = E((W ()X() - X())2), ^ ^ (15)

where Y (), X(), and X() are discrete Fourier transformations of y(n), x(n), and ^ F (f0(n))[x(n)], respectively. The new cost function evaluates the quasi-periodicity not in the time domain but in the frequency domain, and uses a fixed quasi-periodic signal X() ^ as the desired signal, instead of using the non-fixed quasi-periodic signal, F(f0(n))[y(n)]. This modification allows us to solve the above problems. The use of the fixed desired signals specifically provides the dereverberated impulse response, q(n), with the desired values, even in the time region, |n| < . In addition, the self-evident solution, w(l) = 0, can no longer be optimal in terms of the cost function. Furthermore, the computing complexity is greatly reduced because the solution can be given analytically as follows:

W () = ^ E(X()X()). E(X()X())

(16)

A diagram of this simplified MMSE-HERB is shown in Fig. 2. x(n) is time-shifted with l-points while f0(n) of the adaptive harmonic filter is not time-shifted.

4 F (f0(n))[x(n - l)]) is not the same signal as x(n - l). When calculating F (f0(n))[x(n - l)], ^


STEP1:

Input X F0 estimation

X F0 Adaptive harmonics filter

X ^ X1 ^ O(R1) ^ X2

Dereverberation operator estimation

X ^ O(R1) ^ O(R1) ^ O(R2)

Dereverbe-

ration

by

^

O(R1)

^ O(R1) X

STEP2:

^ O(R1)

^ O(R1)

X F0 estimation

F0

X Adaptive harmonics filter X X

Dereverberation operator estimation

Dereverbe-

ration

by

^

O(R2)

^ ^ O(R2)O(R1) X

Figure 3: Processing flow of dereverberation. When we assume the model of X in eq. (8), and E(ShSn) = E(SnSh) = E(NSh) = 0, it is shown that the resulting W in eq. (16) again approaches the dereverberation operator, O(R), presented in section 2.2: ^

^   ^ 

W () =

O(R())E ^ O(R())E ^

E(ShSh) (ShSh) + E(SnSn)





(ShSh) + E(SnSn) . E(ShSh) 



+ H E(ShSh) + E(SnSn),  1 ^ E(NSn)

(17) (18)

Because N represents non-periodic components that are included unexpectedly and at ran^ dom in the output of the harmonic filter, the absolute value of the second term in eq. (17) is expected to be sufficiently small compared with that of the first term, therefore, we disregard this term. Then, W() in eq. (16) becomes the dereverberation operator multiplied by the ratio of the expected power of the quasi-periodic components in the signals to that of whole signals. As with the speech signals discussed in section 2.2, the E(ShSh)/(E(ShSh) + E(SnSn)) value becomes smaller as  increases, and thus, the

 

gain of W() tends to decrease. Therefore, the same frequency compensation scenario as found in section 2.2 may again be useful for the MMSE based dereverberation scheme. 3 Processing flow Based on the above two methods, we constructed a dereverberation algorithm composed of two steps as shown in Fig. 3. Both methods are implemented in the same processing flow except that the methods used to calculate the dereverberation operator are different. The flow is summarized as follows: 1. In the first step, F0 is estimated from the reverberant signal, X. Then the harmonic components included in X are estimated as X1 based on adaptive harmonic fil^ tering. The dereverberation operator O(R1) is then calculated by ATF-HERB or MMSE-HERB for a number of reverberant speech signals. Finally, the dereverberated signal is obtained by multiplying O(R1) by X. ^ 2. The second step employs almost the same procedures as the first step except that the speech data dereverberated by the first step are used as the input signal. The use of this dereverberated input signal means that reverberant components, R2X2, ^ inevitably included in eq. (8) can be attenuated. Therefore, a more effective dereverberation can be achieved in step 2. In our preliminary experiments, however, repeating STEP 2 did not always improve the quality of the dereverberated signals. This is because the estimation error of the dereverberation operators accumulates in the dereverberated signals when the signals are multiplied by more than one dereverberation operator. Therefore, in our experiments, we used STEP 2 only once. A more detailed explanation of these processing steps is also presented in [4].

^


0 0

rtime=1.0 sec. rtime=0.5 sec.

-20 -20 (dB) (dB)

Power -40 Power -40

-60 0 0 0.2 0.4 Time (sec.) 0.6 0.8 -60 0 0 0.2 0.4 Time (sec.) 0.6 0.8

rtime=0.2 sec. rtime=0.1 sec.

-20 -20 (dB) (dB)

Power -40 Power -40

-60 0 0.2 0.4 Time (sec.) 0.6 0.8 -60 0 0.2 0.4 Time (sec.) 0.6 0.8

Figure 4: Reverberation curves of the original impulse responses (thin line) and dereverberated impulse responses (male: thick dashed line, female: thick solid line) for different reverberation times (rtime). Accurate F0 estimation is very important in terms of achieving effective dereverberation with our methods in this processing flow. However, this is a difficult task, especially for speech with a long reverberation using existing F0 estimators. To cope with this problem, we designed a simple filter that attenuates a signal that continues at the same frequency, and used it as a preprocessor for the F0 estimation [5]. In addition, the dereverberation operator, O(R1), itself is a very effective preprocessor for an F0 estimator because the reverberation ^ of the speech can be directly reduced by the operator. This mechanism is already included in step 2 of the dereverberation procedure, that is, F0 estimation is applied to O(R1)X.

^

Therefore, more accurate F0 can be obtained in step 2 than in step 1. 4 Experimental results

We examined the performance of the proposed dereverberation methods. Almost the same results were obtained with the two methods, and so we only describe those obtained with ATF-HERB. We used 5240 Japanese word utterances provided by a male and a female speaker (MAU and FKM, 12 kHz sampling) included in the ATR database as source signals, S(). We used four impulse responses measured in a reverberant room whose reverberation times were about 0.1, 0.2, 0.5, and 1.0 sec, respectively. Reverberant signals, X(), were obtained by convolving S() with the impulse responses. Figure 4 depicts the reverberation curves5 of the original impulse responses and the dereverberated impulse responses obtained with ATF-HERB. The figure shows that the proposed methods could effectively reduce the reverberation in the impulse responses for the female speaker when the reverberation time (rtime) was longer than 0.1 sec. For the male speaker, the reverberation effect in the lower time region was also effectively reduced. This means that strong reverberant components were eliminated, and we can expect the intelligibility of the signals to be improved [6]. Figure 5 shows spectrograms of reverberant and dereverberated speech signals when rtime was 1.0 sec. As shown in the figure, the reverberation of the signal was effectively reduced, and the formant structure of the signal was restored. Similar spectrogram features were observed under other reverberation conditions, and an improvement in sound quality could clearly be recognized by listening to the dereverberated signals [7]. We also evaluated the quality of the dereverberated speech in terms of speaker dependent word recognition rates

5

[6].

The reverberation curve shows the reduction in the energy of a room impulse response with time


2 2

(kHz) (kHz)

1 1

Frequency Frequency

0 0 0.4 0.8 Time (sec.) 1.2 0 0 0.4 0.8 Time (sec.) 1.2

Figure 5: Spectrogram of reverberant (left) and dereverberated (right) speech of a male speaker uttering "ba-ku-da-i".

with an ASR system, and could achieve more than 95 % recognition rates under all the reverberation conditions with acoustic models trained using dereverberated speech signals. Detailed information on the ASR experiments is also provided in [4]. 5 Conclusion A new blind dereverberation principle based on the quasi-periodicity of speech signals was proposed. We presented two types of dereverberation method, referred to as harmonicity based dereverberation (HERB) method: one estimates the average filter function that transforms reverberant signals into quasi-periodic signals (ATF-HERB) and the other minimizes the MMSE criterion that evaluates the quasi-periodicity of signals (MMSE-HERB). We showed that ATF-HERB and a simplified version of MMSE-HERB are both capable of learning the dereverberation operator that can reduce reverberant components in speech signals. Experimental results showed that a dereverberation operator trained with 5240 Japanese word utterances could achieve very high quality speech dereverberation. Future work will include an investigation of how such high quality speech dereverberation can be achieved with fewer speech data. References [1] Baba, A., Lee, A., Saruwatari, H., and Shikano, K., "Speech recognition by reverberation adapted acoustic model," Proc. of ASJ general meeting, pp. 27­28, Akita, Japan, Sep., 2002. [2] Amari, S., Douglas, S. C., Cichocki, A., and Yang, H. H., "Multichannel blind deconvolution and equalization using the natural gradient," Proc. IEEE Workshop on Signal Processing Advances in Wireless Communications, Paris, pp. 101-104, April 1997. [3] Yegnanarayana, B., and Murthy, P. S., "Enhancement of reverberant speech using LP residual signal," IEEE Trans. SAP vol. 8, no. 3, pp. 267­281, 2000. [4] Nakatani, T., Miyoshi, M., and Kinoshita, K., "Implementation and effects of single channel dereverberation based on the harmonic structure of speech," Proc. IWAENC2003, Sep., 2003. [5] Nakatani, T., and Miyoshi, M., "Blind dereverberation of single channel speech signal based on harmonic structure," Proc. ICASSP-2003, vol. 1, pp. 92­95, Apr., 2003. [6] Yegnanarayana, B., and Ramakrishna, B. S., "Intelligibility of speech under nonexponential decay conditions," JASA, vol. 58, pp. 853­857, Oct. 1975. [7] http://www.kecl.ntt.co.jp/icl/signal/nakatani/sound-demos/dm/derev-demos.html


