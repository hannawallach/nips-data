Learning Bounds for a Generalized Family of Bayesian Posterior Distributions

Tong Zhang IBM T.J. Watson Research Center Yorktown Heights, NY 10598 tzhang@watson.ibm.com

Abstract In this paper we obtain convergence bounds for the concentration of Bayesian posterior distributions (around the true distribution) using a novel method that simplifies and enhances previous results. Based on the analysis, we also introduce a generalized family of Bayesian posteriors, and show that the convergence behavior of these generalized posteriors is completely determined by the local prior structure around the true distribution. This important and surprising robustness property does not hold for the standard Bayesian posterior in that it may not concentrate when there exist "bad" prior structures even at places far away from the true distribution.

1 Introduction Consider a sample space X and a measure  on X (with respect to some -field). In statistical inference, the nature picks a probability measure Q on X which is unknown. We assume that Q has a density q with respect to . In the Bayesian paradigm, the statistician considers a set of probability densities p(·|) (with respect to  on X) indexed by   , and makes an assumption1 that the true density q can be represented as p(·|) with  randomly picked from  according to a prior distribution  on . Throughout the paper, all quantities appearing in the derivations are assumed to be measurable. Given a set of samples X = {X1,...,Xn}  Xn, where each Xi independently drawn from (the unknown distribution) Q, the optimal Bayesian method can be derived as the optimal inference with respect to the posterior distribution. Although a Bayesian procedure is optimal only when the nature picks the same prior as the statistician (which is very unlikely), it is known that procedures with desirable properties from the frequentist point of view (such minimaxity and admissibility) are often Bayesian [6]. From a theoretical point of view, it is necessary to understand the behavior of Bayesian methods without the assumption that the nature picks the same prior as the statistician. In this respect, the most fundamental issue in Bayesian analysis is whether the Bayesian inference based on the posterior distribution will converge to the corresponding inference of the true (but

1 In this paper, we view the Bayesian paradigm as a method to generate statistical inferencing

procedures, and thus don't assume that the Bayesian prior assumption has to be true. In particular, we do not even assume that q  {p(·|) :   }.


unknown) distribution when the number of observations approach infinity. A more general question is whether the Bayesian posterior distribution will be concentrated around the true underlying distribution when the sample size is large. This is often referred to as the consistency of Bayesian posterior distribution, which is certainly the most fundamental issue for understanding the behavior of Bayesian methods. This problem has drawn considerable attention in statistics. The classical results include average consistency results such as Doob's consistency theorem and asymptotic convergence results such as the Bernstein-von Mises theorem for parametric problems. For infinite-dimensional problems, one has to choose the prior very carefully, or the Bayesian posterior may not concentrate around the true underlying distribution, which leads to inconsistency [1, 2]. In [1], the authors also gave conditions that guarantee the consistency of Bayesian posterior distributions, although convergence rates were not obtained. The convergence rates were studied in two recent works [3, 8] by using heavy machineries from the empirical process theory. The purpose of this paper is to develop finite-sample convergence bounds for Bayesian posterior distributions using a novel approach that not only simplifies the analysis given in [3, 8], but also leads to tighter bounds. At the heart of our approach are some new posterior averaging bounds that are related to the PAC Bayes analysis appeared in some recent machine learning works. These new bounds are of independent interests (though we cannot fully explore their consequences here) since they can be used to obtain correct convergence rates for other statistical estimation problems such as least squares regression. Motivated by our learning bounds, we introduce a generalized family of Bayesian methods, and show that their convergence behavior relies only on the prior mass in a small neighborhood around the true distribution. This is rather surprising when we consider the example given in [1], which shows that for the (standard) Bayesian method, even if one puts a positive prior mass around the true distribution, one may still get an inconsistent posterior when there exist undesirable prior structures far away from the true distribution. 2 The regularization formulation of Bayesian posterior measure Assume we observe n-samples X = {X1,...,Xn}  Xn, independently drawn from the true underlying distribution Q. We shall call any probability density wX() with respect to ^  that depends on the observation X (and measurable on Xn × ) a posterior distribution.   (0,1], we define a generalized Bayesian posterior (·|X) with respect to  as:

p(Xi|)

(|X) =

n i=1

. n (1)

p(Xi|)d() 

i=1

We call  the -Bayesian posterior. The standard Bayesian posterior is denoted as (·|X) = 1(·|X). Given a probability density w(·) on  with respect to , we define the KL-divergence KL(wd||d) as: KL(wd||d) = w()lnw()d().



Consider a real-valued function f() on , we denote by Ef() the expectation of f(·) with respect to . Similarly, consider a real-valued function (x) on X, we denote by Eq (x) the expectation of (·) with respect the true underlying distribution q. We also use EX to denote the expectation with respect to the observation X. The key starting point of our analysis is the following simple observation that relates the Bayesian posterior to the solution of an entropy regularized density (with respect to ) estimation. Under this formulation, techniques for analyzing regularized risk minimization problems, such as those recently investigated by the author, can be applied to obtain sample


complexity bound for Bayesian posterior distributions. The proof of the following regularization formulation is straight-forward, which we shall skip due to the space limitation. Proposition 2.1 For any density w on  with respect to , let

n 1

RX(w) = n ^ E w()ln q(Xi) p(Xi|) + 1 n KL(wd||d).

i=1

Then RX((·|X)) = infw RX(w). The above Proposition indicates that the generalized Bayesian posterior minimizes the regularized empirical risk RX(w) among all possible densities w with respect to the prior . ^ We thus only need to study the behavior of this regularized empirical risk minimization problem. One may define the true risk of w by replacing the empirical expectation EX ^ with the expectation with respect to the true underlying distribution q:

Rq (w) = E w()KL(q||p(·|)) +

where KL(q||p) = Eq ln q(x) p(x)



1 n KL(wd||d), (2)

^ ^

is the KL-divergence between q and p, which is always a

non-negative number. This quantity is widely used to measure the closeness of two distributions p and q. Clearly the Bayesian posterior is an approximate solution to (2) using empirical expectation. The first term of Rq (w) measures the average KL-divergence of q



and p under the w-density. Since both the first term and the second term are non-negative, we know immediately that if Rq (w)  0, then the distribution w is concentrated around q. 

Using empirical process techniques, one would typically expect to bound Rq (w) in term of RX(w). Unfortunately, it does not work in our case since KL(q||p) is not well-defined ^ for all p. This implies that as long as w has non-zero concentration around a density p with KL(q||p) = +, then Rq (w) = +. Therefore we may have Rq ((·|X)) = + with

 

non-zero probability even when the sample size approaches infinity. A remedy is to consider a distance function that is always well-defined. In statistics, one often considers the -divergence for   (0, 1), which is defined as:



D(q||p) = 1 (1 - ) Eq 1 - p(x) q(x) . (3)



This divergence is always well-defined and KL(q||p) = lim 0 D(q||p). In the statistical

literature, the convergence results were often specified under the Hellinger distance ( = 0.5). We would also like to mention that our learning bound derived later will become trivial when   0. This is consistent with the above discussion since Rq (corresponding



to  = 0) may not converge at all. However, under additional assumptions, such as the boundedness of q/p, KL(q||p) exists and can be bounded using the -divergence D(q||p). 3 Posterior averaging bounds under entropy regularization The following inequality follows directly from a well-known convex duality. For example, see [5, 7] for an explanation. Proposition 3.1 Assume that f() is a measurable real-valued function on , and w() is a density with respect to , we have E w()f()  KL(wd||d) + lnE exp(f()).


The main technical result which forms the basis of the paper is given by the following lemma, where we assume that wX() is a posterior (density with respect to  that depends ^ on X and measurable on Xn × ). Lemma 3.1 Consider any posterior wX(). The following inequality holds for all mea^ surable real-valued functions LX() on Xn × : EX exp EwX()(LX() - lnEXeLX( ) - KL(wXd||d)  1, where EX is the expectation with respect to the observation X. Proof. From Proposition 3.1, we obtain L(X) =EwX()(LX() - lnEXeLX( ) - KL(wXd||d) lnE exp(LX() - lnEXeLX( ).

^ ) ^

^ ^ ) ^

)

Now applying the Fubini's theorem to interchange the order of integration, we have:

EXeL^( X)  EXEeLX( )-ln EX exp(LX()) = EEXeLX( )-ln EX exp(LX()) = 1.

2 The following corollary is a straight-forward consequence of Lemma 3.1. Note that for the

Bayesian method, the loss  (x) has a form of (p(x|)).

Theorem 3.1 (Posterior Averaging Bounds) Under the notation of Lemma 3.1. Let X = {X1,...,Xn} be n-samples that are independently drawn from q. Consider a measurable

function  (x) :  × X  R. Then t > 0 and real number , the following event holds

with probability at least 1 - exp(-t): - EwX()lnEq exp(- (x))) 

^   n i=1 E wX() (Xi) + KL(wXd||d) + t n ^  ^ .

Moreover, we have the following expected risk bound:

 n i=1

E wX() (Xi) + KL(wXd||d) n ^  ^ -EXEwX()lnEq exp(- (x)))  EX ^

 .

Proof Sketch. The first bound is a direct consequence of Markov inequality. The second bound can be obtained by using the fact EX exp(X)  exp(EXX), which follows from the Jensen's inequality. 2 The above bounds are immediately applicable to Bayesian posterior distribution. The first leads to an exponential tail inequality, and the second leads to an expected risk bound. Before analyzing Bayesian methods in detail in the next section, we shall briefly compare the above results to the so-called PAC-Bayes bounds, which can be obtained by estimating the left-hand side using the Hoeffding's inequality with an appropriately chosen . However, in the following, we shall estimate the left-hand side using a Bernstein style bound, which is much more useful for general statistical estimation problems: Corollary 3.1 Under the notation of Theorem 3.1, and assume that sup,x1,x2 | (x1) -



 (x2)|  1. Then t, > 0, with probability of at least 1 - exp(-t):

n

EwX()Eq (x) - ()EwX()Varq (x)  ^  ^  1 n

EwX() (Xi) KL(wXd||d) + t, n 

i=1

+

^ ^

where (x) = (exp(x) - x - 1)/x2 and Varq (x) = Eq( (x) - Eq (x))2.   


Proof Sketch. We follow one of the standard derivations of Bernstein inequality outlined below: it is well known that (x) is non-decreasing in x, which in turn implies that ln Eq exp(- (x)))  -Eq (x) + 2()Eq( (x) - Eq (x))2.

   

Now applying this bound to the left hand side of Theorem 3.1, we finish the proof. 2 One may use the simple bound Varq (x)  1/4 and obtain2.



n

EwX()Eq (x)  EwX() ^  ^  (Xi) n + () 4 + KL(wXd||d) + t ^ n . (4)

i=1

This inequality holds for any data-independent choice of . However, one may easily turn it into a bound which allows  to depend on the data using well-known techniques (see [5], for example). After we optimize , the resulting bound becomes similar to the PAC-Bayes

bound [4]. Typically the optimal  is in the order of KL(wXd||d)/n, and hence the ^

rate of convergence given on the right-hand side is no better than O( more interesting case is when there exists a constant b  0 such that Eq( (x) - Eq (x))2  bEq (x).

  

1/n). However, the (5)

This condition appears in the theoretical analysis of many statistical estimation problems, such as least squares regression, and when the loss function is non-negative (such as classification). It also appears in some analysis of maximum-likelihood estimation (log-loss), though as we shall see, log-loss can be much more directly handled in our framework using Theorem 3.1. A modified version of this condition also occurs in some recent analysis of classification problems even when the problem is not separable. We shall now assume that (5) holds. It follows from Corollary 3.1 that  > 0 such that ()  1/b, we have

EwX() ^ n i=1  (Xi) + KL(wXd||d) + t ^

EwX()Eq (x)  ^  . (6)

(1 - b())n

Again the above inequality holds for any data-independent , but we can easily turn it into a bound that allows  to depend on X using standard techniques. However we shall not list the final result here since this is not the purpose of the paper. The parameter  can be optimized, and it is not hard to check that the resulting bound is significantly better than (4) retical analysis of many statistical estimation problems. To obtain the correct convergence behavior in such cases (including the Bayesian method which we are interested in here), inequality (4) is inadequate, and it is essential to use a Bernstein-type bound such as (6). It is also useful to point out that to analyze such problems, one actually only needs (6) with an appropriately chosen data-independent , which will lead to the correct (minimax) rate of convergence. Note that if we choose  to be a constant, then it is possible to achieve a bound that converges as fast as O(1/n). We shall point out that in [7], a KL-divergence version of the PAC-Bayes bound was developed for the 0-1 loss using related techniques, which can lead to a rate as fast as O(ln n/n) if we make near zero errors. However, the Bernstein style bound given here is more generally applicable and is necessary for more complicated statistical estimation problems such as least squares regression. 4 Convergence bounds for Bayesian posterior distributions We shall now analyze the finite sample convergence behavior of Bayesian posterior distributions using Theorem 3.1. Although the exponential tail inequality provides more detailed information, our discussion will be based on the expected risk bound for simplicity.

when EwX() ^ n i=1  0. The "self-bounding" condition (5) holds in the theo (Xi) n

2 In this case, slightly tighter results can be obtained by applying the Hoeffding's exponential

inequality directly to the left-hand side of Theorem 3.1, instead of the method used in Corollary 3.1.


To analyze the Bayesian method, we let



(x) = ln(q(x)/p(x|)) in Theorem 3.1. Con-

sider   (0, 1). We also let wX() be the Bayesian posterior (|X) with parameter ^   [,1] defined in (1). Consider an arbitrary data-independent density w() with respect to , using (3), we can obtain from Theorem 3.1 the following chain of equations:

EXE(|X)ln 1 1 - (1 - )D(q||p(·|))

= - EXE(|X) ln Eq exp - ln

n

EX E (|X)

i=1 n

1 n

q(x) p(x|)

+ KL((|X)d||d) n ln q(Xi) p(Xi|)

n

EX E w() 1 n

ln

q(Xi) p(Xi|)

n

ln

+ KL(wd||d) n +  -  n

EX sup



ln p(Xi|) q(Xi)

i=1 i=1

=R(w) + q  -  n

EX sup



p(Xi|), q(Xi)

i=1

where Rq (w) is defined in (2). Note that the first inequality follows from Theorem 3.1, and the second inequality follows from Proposition 2.1. The empirical process bound in the second term can be improved using a more precise bounding method, but we shall skip it here due to the lack of space. It is not difficult to see (also see Proposition 2.1 and Proposition 3.1) that (we skip the derivation due to the space limitation): inf Rq (w) = -n ln E exp(-nKL(q||p(·|))).

1 

w

Using the fact - ln(1 - x)  x to simplify the left-hand side, we thus obtain: EXE(|X)D(q||p(·|))

-lnEe-n KL(q||p(·|)) n i=1 ln

 + ( - )EX sup (1 - )n p(Xi|) q(Xi)

.



(7)

In the following, we shall compare our analysis with previous results. To be consistent with the concept used in these previous studies, we shall consider the following quantity: m,(X, ) = E(|X)1(D(q||p(·|))  ),



where 1 is the set indicator function. Intuitively m,(X, ) is the probability mass of the



-Bayesian posterior (·|X) in the region of p(·|) that is at least -distance away from q in D-divergence. Using Markov inequality, we immediately obtain from (7) the following bound for m,(X):

-lnEe-n KL(q||p(·|)) ln EXm,(X, ) 



+ ( - )EX sup (1 - )n n i=1 p(Xi|) q(Xi)

. (8)

Next we would like to estimate the right-hand side of (8). Due to the limitation of space, we shall only consider a simple truncation estimation, which leads to the correct convergence rate for non-parametric problems but yields an unnecessary ln n factor for parametric problems (which can be correctly handled with a more precise estimation). We introduce the following notation, which is essentially the prior measure of an -radius KL-ball around q: M ( ) = (KL(q||p(·|))  ) = E1(KL(q||p(·|))  ).

KL


Using this definition, we have Ee-n KL(q||p(·|))  M ( )e-n . In addition, we shall KL

define the -upper bracketing of  (introduced in [1]), denoted by N(, ), as the minimum number of non-negative functions {fi} on X with respect to  such that Eq(fi/q) = 1 + , and   , i such that p(x|)  fi(x) a.e. []. We have

n N(, )

1 n ln

EX sup



ln p(Xi|) q(Xi) n i=1 e fj(Xi) q(Xi)

i=1

1  EX ln n 1  ln n

j=1 N(, )

EXe n i=1 ln

fj(Xi) q(Xi)

= ln N(, ) n + ln(1 + ).

j=1

Therefore we obtain from (8) that s > 0:

(1 - )sEXm,(X,s )   -  1 n KL ln M ( ) + ( - ) ln N(, ) + n n .

The above bound immediately implies the following consistency and convergence rate theorem for Bayesian posterior distribution: Theorem 4.1 Consider a sequence of Bayesian prior distributions n on a parameter space n, which may be different for different sample sizes. Consider a sequence of positive numbers { } such that

n

-1

n n

sup ln Mn ( ) < , then sn > 0 such that sn  , and   (0, 1), m,(X,sn )  0 in probability. Moreover, if n

n

n n

ln N(n, ) n

n n

sup < , then sn > 0 such that sn  , and   (0, 1), m1n (X,sn )  0 in probability.

n

, n

KL (9)

(10)

The first claim implies that for all  < 1, the -Bayesian posterior  is concentrated in

an

n

n ball around q in D divergence, and the rate of convergence is Op( ). Note that n

is determined only by the local property of n around the true distribution q. It also

immediately implies that as long as Mn ( ) > 0 for all

KL

> 0, the -Bayesian method

with  < 1 is consistent. The second claim applies to the standard Bayesian method. Its consistency requires an additional assumption (10), which depends on global properties of the prior n. This may seem somewhat surprising at first, but the condition is necessary. In fact, the counterexample given in [1] shows that the standard Bayesian method can be inconsistent even under the condition Mn ( ) > 0 for all > 0. Therefore a standard Bayesian procedure

KL

can be ill-behaved even if we put a sufficient amount of prior around the true distribution. The consistency theorem given in [1] also relies on the upper entropy number N(, ). However, no convergence rates were established. Here we obtained a rate of convergence result for the standard Bayesian method using their covering definitions. Other definitions of covering (e.g. Hellinger covering) were used in more recent works to obtain rate of convergence for non-parametric Bayesian methods [3, 8]. Although it is possible to derive bounds using those different covering definitions in our analysis, we shall not work out the details here. However, we shall point out that these works made assumptions not completely necessary. For example, in [3], the definition of M ( ) requires additional

KL

assumptions that Eq ln(q/p(·|))2  . This stronger condition is not needed in our analysis. Finally we shall mention that the bound of the form in Theorem 4.1 is known to produce optimal convergence rates for non-parametric problems (see [3, 8] for examples). 2


5 Conclusion In this paper, we formulated an extended family of Bayesian algorithms as empirical logrisk minimization under entropy regularization. We then derived general posterior averaging bounds under entropy regularization that are suitable for analyzing Bayesian methods. These new bounds are of independent interests since they lead to Bernstein style exponential inequalities, which are crucial for obtaining the correct convergence behavior for many statistical estimation problems such as least squares regression. Using the posterior averaging bounds, we obtain new convergence results for a generalized family of Bayesian posterior distributions. Our results imply that the -Bayesian method with  < 1 is more robust than the standard Bayesian method since its convergence behavior is completely determined by the local prior density around the true distribution. Although the standard Bayesian method is "optimal" in a certain averaging sense, its behavior is heavily dependent on the regularity of the prior distribution globally. What happens is that the standard Bayesian method can put too much emphasis on the difficult part of the prior distribution, which degrades the estimation quality in the easier parts where we are actually more interested in. Therefore even if one is able to guess the true distribution by putting a large prior mass around its neighborhood, the Bayesian method can still illbehave if one accidentally makes bad choices elsewhere. It is thus difficult to design good Bayesian priors. The new theoretical insights obtained here imply that unless one completely understands the impact of the prior, it is much safer to use an -Bayesian method. Acknowledgments The author would like to thank Andrew Barron, Ron Meir, and Matthias Seeger for helpful discussions and comments. References [1] Andrew Barron, Mark J. Schervish, and Larry Wasserman. The consistency of posterior distributions in nonparametric problems. Ann. Statist., 27(2):536­561, 1999. [2] Persi Diaconis and David Freedman. On the consistency of Bayes estimates. Ann. Statist., 14(1):1­67, 1986. With a discussion and a rejoinder by the authors. [3] Subhashis Ghosal, Jayanta K. Ghosh, and Aad W. van der Vaart. Convergence rates of posterior distributions. Ann. Statist., 28(2):500­531, 2000. [4] D. McAllester. PAC-Bayesian stochastic model selection. Machine Learning, 51(1):5­ 21, 2003. [5] Ron Meir and Tong Zhang. Generalization error bounds for Bayesian mixture algorithms. Journal of Machine Learning Research, 4:839­860, 2003. [6] C. P. Robert. The Bayesian Choice: A Decision Theoretic Motivation. Springer Verlag, New York, 1994. [7] M. Seeger. PAC-Bayesian generalization error bounds for Gaussian process classification. JMLR, 3:233­269, 2002. [8] Xiaotong Shen and Larry Wasserman. Rates of convergence of posterior distributions. Ann. Statist., 29(3):687­714, 2001.


