A Nonlinear Predictive State Representation

Matthew R. Rudary and Satinder Singh Computer Science and Engineering University of Michigan Ann Arbor, MI 48109 {mrudary,baveja}@umich.edu

Abstract Predictive state representations (PSRs) use predictions of a set of tests to represent the state of controlled dynamical systems. One reason why this representation is exciting as an alternative to partially observable Markov decision processes (POMDPs) is that PSR models of dynamical systems may be much more compact than POMDP models. Empirical work on PSRs to date has focused on linear PSRs, which have not allowed for compression relative to POMDPs. We introduce a new notion of tests which allows us to define a new type of PSR that is nonlinear in general and allows for exponential compression in some deterministic dynamical systems. These new tests, called e-tests, are related to the tests used by Rivest and Schapire [1] in their work with the diversity representation, but our PSR avoids some of the pitfalls of their representation--in particular, its potential to be exponentially larger than the equivalent POMDP. 1 Introduction A predictive state representation, or PSR, captures the state of a controlled dynamical system not as a memory of past observations (as do history-window approaches), nor as a distribution over hidden states (as do partially observable Markov decision process or POMDP approaches), but as predictions for a set of tests that can be done on the system. A test is a sequence of action-observation pairs and the prediction for a test is the probability of the test-observations happening if the test-actions are executed. Littman et al. [2] showed that PSRs are as flexible a representation as POMDPs and are a more powerful representation than fixed-length history-window approaches. PSRs are potentially significant for two main reasons: 1) they are expressed entirely in terms of observable quantities and this may allow the development of methods for learning PSR models from observation data that behave and scale better than do existing methods for learning POMDP models from observation data, and 2) they may be much more compact than POMDP representations. It is the latter potential advantage that we focus on in this paper. All PSRs studied to date have been linear, in the sense that the probability of any sequence of k observations given a sequence of k actions can be expressed as a linear function of the predictions of a core set of tests. We introduce a new type of test, the e-test, and present the first nonlinear PSR that can be applied to a general class of dynamical systems. In particular, in the first such result for PSRs we show that there exist controlled dynamical systems whose PSR representation is exponentially smaller than its POMDP representation.


To arrive at this result, we briefly review PSRs, introduce e-tests and an algorithm to generate a core set of e-tests given a POMDP, show that a representation built using e-tests is a PSR and that it can be exponentially smaller than the equivalent POMDP, and conclude with example problems and a look at future work in this area. 2 Models of Dynamical Systems A model of a controlled dynamical system defines a probability distribution over sequences of observations one would get for any sequence of actions one could execute in the system. Equivalently, given any history of interaction with the dynamical system so far, a model defines the distribution over sequences of future observations for all sequences of future actions. The state of such a model must be a sufficient statistic of the observed history; that is, it must encode all the information conveyed by the history. POMDPs [3, 4] and PSRs [2] both model controlled dynamical systems. In POMDPs, a belief state is used to encode historical information; in PSRs, probabilities of particular future outcomes are used. Here we describe both models and relate them to one another. POMDPs A POMDP model is defined by a tuple S, A, O, T, O, b0 , where S, A, and O are, respectively, sets of (unobservable) hypothetical underlying-system states, actions that can be taken, and observations that may be issued by the system. T is a set of matrices of dimension |S| О |S|, one for each a  A, such that Tij is the probability that the next

a

state is j given that the current state is i and action a is taken. O is a set of |S| О |S|

a,o

diagonal matrices, one for each action-observation pair, such that Oii is the probability of observing o after arriving in state i by taking action a. Finally, b0 is the initial belief state, a |S| О 1 vector whose ith element is the probability of the system starting in state i. The belief state at history h is b(S|h) = [prob(1|h) prob(2|h) . . . prob(|S||h)], where prob(i|h) is the probability of the unobserved state being i at history h. After taking an action a in history h and observing o, the belief state can be updated as follows:

bT(S|hao) = bT(S|h)TaOa,o bT(S|h)TaOa,o1|S| (1|S| is the |S| О 1 vector consisting of all 1's)

PSRs Littman et al. [2] (inspired by the work of Rivest and Schapire [1] and Jaeger [5]) introduced PSRs to represent the state of a controlled dynamical system using predictions of the outcomes of tests. They define a test t as a sequence of actions and observations t = a1o1a2o2 иии akok; we shall call this type of test a sequence test, or s-test in short. An s-test succeeds iff, when the sequence of actions a1a2 иии ak is executed, the system issues the observation sequence o1o2 иии ok. The prediction p(t|h) is the probability that the s-test t succeeds from observed history h (of length n w.l.o.g.); that is

p(t|h) = prob(on +1 = o1, . . . , on +k = ok|h, an +1 = a1, . . . , an +k = ak) (1)

where ai and oi denote the action taken and the observation, respectively, at time i. In the rest of this paper, we will abbreviate expressions like the right-hand side of Equation 1 by prob(o1o2 иии ok|ha1a2 иии ak). A set of s-tests Q = {q1q2 . . . q|Q } is said to be a core set if it constitutes a PSR, i.e.,

|

if its vector of predictions, p(Q|h) = [p(q1|h) p(q2|h) . . . p(q|Q |h)], is a sufficient |

statistic for any history h. Equivalently, if Q is a core set, then for any s-test t, there exists a function ft such that p(t|h) = ft(p(Q|h)) for all h. The prediction vector p(Q|h) in PSR models corresponds to belief state b(S|h) in POMDP models. The PSRs discussed by Littman et al. [2] are linear PSRs in the sense that for any s-test t, ft is a linear function of the predictions of the core s-tests; equivalently, the following equation s-tests t  a weight vectorwt,s.t. p(t|h) = pT(Q|h)wt (2)


defines what it means for Q to constitute a linear PSR. Upon taking action a in history h and observing o, the prediction vector can be updated as follows:

p(qi|hao) = p(aoqi|h) p(ao|h) = faoqi(p(Q|h)) fao(p(Q|h)) = pT(Q|h)maoqi pT(Q|h)mao (3)

where the final right-hand side is only valid for linear PSRs. Thus a linear PSR model is specified by Q and by the weight vectors in the above equation maoq for all a  A, o  O,q  Q   (where  is the null sequence). It is pertinent to ask what sort of dynamical systems can be modeled by a PSR and how many core tests are required to model a system. In fact, Littman et al. [2] answered these questions with the following result: Lemma 1 (Littman et al. [2]) For any dynamical system that can be represented by a finite POMDP model, there exists a linear PSR model of size (|Q|) no more than the size (|S|) of the POMDP model. Littman et al. prove this result by providing an algorithm for constructing a linear PSR model from a POMDP model. The algorithm they present depends on the insight that s-tests are differentiated by their outcome vectors. An outcome vector u(t) for an s-test t = a1o1a2o2 . . . akok is a |S| О 1 vector; the ith component of the vector is the probability of t succeeding given that the system is in the hidden state i, i.e., u(t) = the states in S and whose columns are the outcome vectors for all possible s-tests. Let Q denote the set of s-tests associated with the maximal set of linearly independent columns of U; clearly |Q|  |S|. Littman et al. showed that Q is a core set for a linear PSR model by the following logic. Let U(Q) denote the submatrix consisting of the columns of U corresponding to the s-tests  Q. Clearly, for any s-test t, u(t) = U(Q)wt for some vector of weights wt. Therefore, p(t|h) = bT (S|h)u(t) = bT (S|h)U(Q)wt = p(Q|h)wt which is exactly the requirement for a linear PSR (cf. Equation 2). We will reuse the concept of linear independence of outcome vectors with a new type of test to derive a PSR that is nonlinear in general. This is the first nonlinear PSR that can be used to represent a general class of problems. In addition, this type of PSR in some cases requires a number of core tests that is exponentially smaller than the number of states in the minimal POMDP or the number of core tests in the linear PSR. 3 A new notion of tests In order to formulate a PSR that requires fewer core tests, we look to a new kind of test-- the end test, or e-test in short. An e-test is defined by a sequence of actions and a single ending observation. An e-test e = a1a2 иии akok succeeds if, after the sequence of actions a1a2 иии ak is executed, ok is observed. This type of test is inspired by Rivest and Schapire's [1] notion of tests in their work on modeling deterministic dynamical systems. 3.1 PSRs with e-tests Just as Littman et al. considered the problem of constructing s-test-based PSRs from POMDP models, here we consider how to construct a e-test-based PSR, or EPSR, from a POMDP model and will derive properties of EPSRs from the resulting construction. The |S| О 1 outcome vector for an e-test e = a1a2 . . . akok is

Ta Oa 1 1 1 o Ta Oa 2 2 2 o . . . Ta Oa n k k o 1|S|. Consider the matrix U whose rows correspond to

v(e) = Ta Ta . . . Ta Oa 1 2 k k k o 1|S|. (4)

Note that we are using v's to denote outcome vectors for e-tests and u's to denote outcome vectors for s-tests. Consider the matrix V whose rows correspond to S whose columns are


done  false; i  0; L  {} do until done done  true N  generate all one-action extensions of length-i tests in L for each t  N if v(t) is linearly independent of V (L) then L  L  {t}; done  false end for i  i + 1 end do QV  L Figure 1: Our search algorithm to find a set of core e-tests given the outcome vectors.

the outcome vectors for all possible e-tests. Let QV denote the set of e-tests associated with a maximal set of linearly independent columns of matrix V ; clearly |QV |  |S|. Note that QV is not uniquely defined; there are many such sets. The hope is that the set QV is a core set for an EPSR model of the dynamical system represented by the POMDP model. But before we consider this hope, let us consider how we would find QV given a POMDP model. We can compute the outcome vector for any e-test from the POMDP parameters using Equation 4. So we could compute the columns of V one by one and check to see how many linearly independent columns we find. If we ever find |S| linearly independent columns, we know we can stop, because we will not find any more. However, if |QV | < |S|, then how would we know when to stop? In Figure 1, we present a search algorithm that finds a set QV in polynomial time. Our algorithm is adapted from Littman et al.'s algorithm for finding core s-tests. The algorithm starts with all e-tests of length one and maintains a set L of currently known linearly independent e-tests. At each iteration it searches for new linearly independent e-tests among all one-action extensions of the e-tests it added to L at the last iteration and stops when an iteration does not add to the set L. Lemma 2 The search algorithm of Figure 1 computes the set QV in time polynomial in the size of the POMDP. Proof Computing the outcome vector for an e-test using Equation 4 is polynomial in the number of states and the length of the e-test. There cannot be more than |S| e-tests in the set L maintained by the search algorithm algorithm and only one-action extensions of the e-tests in L  O are ever considered. Each extension length considered must add an e-test else the algorithm stops, and so the maximal length of each e-test in QV is upper bounded by the number of states. Therefore, our algorithm returns QV in polynomial time. Note that this algorithm is only practical if the outcome vectors have been found; this only makes sense if the POMDP model is already known, as outcome vectors map POMDP states to outcomes. We will address learning these models from observations in future work [6]. Next we show that the prediction of any e-test can be computed linearly from the prediction vector for the e-tests in QV . Lemma 3 For any history h and any e-test e, the prediction p(e|h) is some linear function of prediction vector p(QV |h), i.e., p(e|h) = p(QV |h)we for some weight vector we. Proof Let V (QV ) be the submatrix of V containing the columns corresponding to QV . By the definition of QV , for any e-test e, v(e) = V (QV )we, for some weight vector we. Furthermore, for any history h, p(e|h) = b(S|h)v(e) = b(S|h)V (QV )we = p(QV |h)we.


Note that Lemma 3 does not imply that QV constitutes a PSR, let alone a linear PSR, for the definition of a PSR requires that the prediction of all s-tests be computable from the core test predictions. Next we turn to the crucial question: does QV constitute a PSR? Theorem 1 If V (QV ), defined as above with respect to some POMDP model of a dynamical system, is a square matrix, i.e., the number of e-tests in QV is the number of states |S| (in that POMDP model), then QV constitutes a linear EPSR for that dynamical system. Proof For any history h, pT (QV |h) = bT (S|h)V (QV ). If V (QV ) is square then it is invertible because by construction it has full rank, and hence for any history h, bT (S|h) =

pT(QV |h)V

-1

(QV ). For any s-test t = a1o1a2o2 иии akok,

pT(t|h) = bT(S|h)Ta Oa

= pT (QV |h)V -1

1 1 ,o1 a2 a2,o2 T O k k k иииTa Oa ,o 1S (by first-principles definition)

k k k

иииTa Oa ,o 1S = pT (QV |h)wt (QV )Ta Oa 1 1 ,o1 a2 a2,o2 T O

for some weight vector wt. Thus, QV constitutes a linear EPSR as per the definition in Equation 2.

We note that the product Ta Oa 1 1 ,o1 иииTa Oa k k k ,o

1S appears often in association with an

s-test t = a1o1 иии akok, and abbreviate the product z(t). We similarly define z(e) =

Ta Ta2 иии Ta Oa 1 k k k ,o 1S for the e-test e = a1a2 иии akok.

Staying with the linear EPSR case for now, we can define an update function for p(QV |h) as follows: (remembering that V (QV ) is invertible for this case)

p(QV |h)V -1 (QV )z(aoei)

p(ei|hao) = p(aoei|h) p(ao|h) = b(S|h)TaOa,oz(ei) p(Q|h)mao = =

p(QV |h)mao

p(QV |h)maoei p(QV |h)mao (5)

where we used the fact that the test ao in the denominator is an e-test. (The form of the linear EPSR update equation is identical to the form of the update in linear PSRs with s-tests given in Equation 3). Thus, a linear EPSR model is defined by QV and the set of weight vectors, maoe for all a  A, o  O, e  {QV  }, used in Equation 5. Now, let us turn to the case when the number of e-tests in QV is less than |S|, i.e., when V (QV ) is not a square matrix. Lemma 4 In general, if the number of e-tests in QV is less than |S|, then QV is not guaranteed to be a linear EPSR. Proof (Sketch) To prove this lemma, we must only find an example of a dynamical system that is an EPSR but not a linear EPSR. In Section 4.3 we present a k-bit register as an example of such a problem. We show in that section that the state space size is 2k and the number of s-tests in the core set of a linear s-test-based PSR model is also 2k, but the number of e-tests in QV is only k + 1. Note that this means that the rank of the U matrix for s-tests is 2k while the rank of the V matrix for e-tests is k +1. This must mean that QV is not a linear EPSR. We skip these details for lack of space. Lemma 4 leaves open the possibility that if |QV | < |S| then QV constitutes a nonlinear EPSR. We were unable, thus far, to evaluate this possibility for general POMDPs but we did obtain an interesting and positive answer, presented in the next section, for the class of deterministic POMDPs. 4 A Nonlinear PSR for Deterministic Dynamical Systems In deterministic dynamical systems, the predictions of both e-tests and s-tests are binary and it is this basic fact that allows us to prove the following result.


Theorem 2 For deterministic dynamical systems the set of e-tests QV is always an EPSR and in general it is a nonlinear EPSR. Proof For an arbitrary s-test t = a1o1a2o2 иии akok, and some arbitrary history h that is realizable (i.e., p(h) = 1), and for some vectors wa1o1, wa1o1a2o2, ..., wa1o1a2o2иииakok of length |QV |, we have prob(o1o2 иии ok|ha1a2 иии ak) =

= prob(o1|ha1)prob(o2|ha1o1a2) иии prob(ok|ha1o1a2o2 иии ak o -1 k-1 k a )

= prob(o1|ha1)prob(o2|ha1a2) иии prob(ok|ha1a2 иии ak) = (pT (QV |h)wa1o1)(pT (QV |h)wa1o1a2o2) иии (pT (QV |h)wa1o1иииakok) = ft(p(QV |h)) In going from the second line to the third, we eliminate observations from the conditions by noting that in a deterministic system, the observation emitted depends only on the sequence of actions executed. In going from the third line to the fourth, we use the result of Lemma 3 that regardless of the size of QV , the predictions for all e-tests for any history h are linear functions of p(QV |h). This shows that for deterministic dynamical systems, QV , regardless of its size, constitutes an EPSR. Update Function: Since predictions are binary in deterministic EPSRs, p(ao|h) must be 1 if o is observed after taking action a in history h: p(ei|hao) = p(aoei|h)/p(ao|h) = p(aei|h) = p(QV |h)maei where the second equality from the left comes about because p(ao|h) = 1 and, because o must be observed when a is executed, p(aoei|h) = p(aei|h), and the last equality used the fact that aei is just some other e-test and so from Lemma 3 must be a linear function of p(QV |h). It is rather interesting that even though the EPSR formed through QV is nonlinear (as seen in Theorem 2), the update function is in fact linear. 4.1 Diversity and e-tests Rivest and Schapire's [1] diversity representation, the inspiration for e-tests, applies only to deterministic systems and can be explained using the binary outcome matrix V defined at the beginning of Section 3.1. Diversity also uses the predictions of a set of e-tests as its representation of state; it uses as many e-tests as there are distinct columns in the matrix V . Clearly, at most there can be 2|S| distinct columns and they show that there have to be at least log2(|S|) distinct columns and that these bounds are tight. Thus the size of the diversity representation can be exponentially smaller or exponentially bigger than the size of a POMDP representation. While we use the same notion of tests as the diversity representation, our use of linear independence of outcome vectors instead of equivalence classes based on equality of outcome vectors allows us to use e-tests on stochastic systems. Next we show through an example that EPSR models in deterministic dynamic systems can lead to exponential compression over POMDP models in some cases while avoiding the exponential blowup possible in Rivest and Schapire's [1] diversity representation. 4.2 EPSRs can be Exponentially Smaller than Diversity This first example shows a case in which the size of the EPSR representation is exponentially smaller than the size of the diversity representation. The hit register (see Figure 2a) is a k-bit register (these are the value bits) with an additional special hit bit. There are 2k + 1 states in the POMDP describing this system--one state in which the hit bit is 1 and 2k states in which the hit bit is 0 and the value bits take on different combinations of


a) k bits (value bits) b) k bits

... 0 ... 1

hit 0

1 1 1

Figure 2: The two example systems. a) The k-bit hit register. There are k value bits and the special hit bit. The value of the hit bit determines the observation and k + 2 actions alter the value of the bits; this is fully specified in Section 4.2. b) The k-bit rotate register. The value of the leftmost bit is observed; this bit can be flipped, and the register can be rotated either to the right or to the left. This is described in greater detail in Section 4.3.

values. There are k + 2 actions: a flip action Fi for each value bit i that inverts bit i if the hit bit is not set, a set action Sh that sets the hit bit if all the value bits are 0, and a clear action Ch that clears the hit bit. There are two observations: Oh if the hit bit is set and Om otherwise. Rivest and Schapire [1] present a similar problem (their version has no Ch action). The diversity representation requires O(22 ) equivalence classes and thus tests,

k

whereas an EPSR has only 2k + 1 core e-tests (see Table 1 for the core e-tests and update function when k = 2).

Table 1: Core e-tests and update functions for the 2-bit hit register problem. update function for action

test F1Oh ShOh F1ShOh F2ShOh F2F1ShOh F1 p(F1Oh) p(F1ShOh) p(ShOh) p(F2F1ShOh) p(F2ShOh) F2 p(F1Oh) p(F2ShOh) p(F2F1ShOh) p(ShOh) p(F1ShOh)

Sh p(ShOh) p(ShOh) p(ShOh)-p(F1Oh)+ p(F1ShOh) p(ShOh)-p(F1Oh)+ p(F2ShOh) p(ShOh)-p(F1Oh)+ p(F2F1ShOh) Ch 0 p(ShOh) p(F1ShOh) - p(F1Oh) p(F2ShOh) - p(F1Oh) p(F2F1ShOh)- p(F1Oh)

Lemma 5 For deterministic dynamical systems, the size of the EPSR representation is always upper-bounded by the minimum of the size of the diversity representation and the size of the POMDP representation. Proof The size of the EPSR representation, |QV |, is upper-bounded by |S| by construction of QV . The number of e-tests used by diversity representation is the number of distinct columns in the binary V matrix of Section 3.1, while the number of e-tests used by the EPSR representation is the number of linearly independent columns in V . Clearly the latter is upper-bounded by the former. As a quick example, consider the case of 2-bit binary vectors: There are 4 distinct vectors but only 2 linearly independent ones. 4.3 EPSRs can be Exponentially Smaller than POMDPs and the Original PSRs This second example shows a case in which the EPSR representation uses exponentially fewer tests than the number of states in the POMDP representation as well as the original linear PSR representation. The rotate register illustrated in Figure 2b is a k-bit shift-register.


Table 2: Core e-tests and update function for the 4 bit rotate register problem. update function for action

test FO1 RO1 LO1 FFO1 RRO1 R p(FO1) + p(FFO1) - p(RO1) p(RRO1) p(FFO1) p(RO1) p(LO1) L p(FO1) + p(FFO1) - p(LO1) p(FFO1) p(RRO1) p(LO1) p(RO1) F p(FFO1) p(RO1) p(LO1) p(FO1) p(RRO1)

There are two observations: O1 is observed if the leftmost bit is 1 and O0 is observed when the leftmost bit is 0. The three actions are R, which shifts the register one place to the right with wraparound, L, which does the opposite, and F, which flips the leftmost bit. This problem is also presented by Rivest and Schapire as an example of a system whose diversity is exponentially smaller than the number of states in the minimal POMDP, which is 2k. This is also the number of core s-tests in the equivalent linear PSR (we computed these 2k s-tests but do not report them here). The diversity is 2k. However, the EPSR that models this system has only k + 1 core e-tests. The tests and update function for the 4-bit rotate register are shown in Table 2. 5 Conclusions and Future Work In this paper we have used a new type of test, the e-test, to specify a nonlinear PSR for deterministic controlled dynamical systems. This is the first nonlinear PSR for any general class of systems. We proved that in some deterministic systems our new PSR models are exponentially smaller than both the original PSR models as well as POMDP models. Similarly, compared to the size of Rivest & Schapire's diversity representation (the inspiration for the notion of e-tests) we proved that our PSR models are never bigger but sometimes exponentially smaller. This work has primarily been an attempt to understand the representational implications of using e-tests; as future work, we will explore the computational implications of switching to e-tests. Acknowledgments Matt Rudary and Satinder Singh were supported by a grant from the Intel Research Council. References [1] Ronald L. Rivest and Robert E. Schapire. Diversity-based inference of finite automata. Journal of the ACM, 41(3):555Г589, May 1994. [2] Michael L. Littman, Richard S. Sutton, and Satinder Singh. Predictive representations of state. In Advances In Neural Information Processing Systems 14, 2001. [3] William S. Lovejoy. A survey of algorithmic methods for partially observed markov decision processes. Annals of Operations Research, 28(1):47Г65, 1991. [4] Michael L. Littman. Algorithms for Sequential Decision Making. PhD thesis, Brown University, 1996. [5] Herbert Jaeger. Observable operator models for discrete stochastic time series. Neural Computation, 12(6):1371Г1398, 2000. [6] Satinder Singh, Michael L. Littman, Nicholas E. Jong, David Pardoe, and Peter Stone. Learning predictive state representations. In The Twentieth International Conference on Machine Learning (ICML-2003), 2003. To appear.


